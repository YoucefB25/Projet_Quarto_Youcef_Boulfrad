{
  "hash": "1e3a294a43a50e9d9a48a34f52241ad8",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Random Forest - ForÃªt AlÃ©atoire\"\n---\n\n\n\n\n\n\n## ThÃ©orie\n\nLa **forÃªt alÃ©atoire** est un algorithme d'apprentissage supervisÃ© basÃ© sur un **ensemble d'arbres de dÃ©cision**. Il fonctionne en combinant plusieurs arbres pour **amÃ©liorer la prÃ©cision** et **rÃ©duire le risque de surapprentissage**.\n\n## HyperparamÃ¨tre utilisÃ©\n\nNous allons optimiser :\n\n- **Nombre d'arbres (`n_estimators`)** : sÃ©lectionnÃ© en fonction de la prÃ©cision sur lâ€™ensemble de validation.\n\n## MÃ©triques dâ€™Ã©valuation\n\nNous afficherons :\n\n- **Matrice de confusion** : rÃ©capitulant les erreurs de classification.\n- **Taux de bien classÃ©s sur lâ€™Ã©chantillon de validation** avec le meilleur hyperparamÃ¨tre.\n- **Taux de bien classÃ©s sur lâ€™Ã©chantillon de test** avec ce mÃªme hyperparamÃ¨tre.\n- **Taux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test**.\n\n## Recherche du meilleur `n_estimators` et Ã©valuation\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport warnings\n\n# ğŸ”‡ Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ğŸ”„ Chargement des ensembles de donnÃ©es\ntrain_data = pd.read_csv('../data/covertype_train.csv')\nval_data = pd.read_csv('../data/covertype_val.csv')\ntest_data = pd.read_csv('../data/covertype_test.csv')\n\n# ğŸ“Š PrÃ©paration des donnÃ©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# ğŸ¯ Recherche du meilleur hyperparamÃ¨tre n_estimators\nn_estimators_range = range(50, 1000, 50)\nval_accuracies = []\n\nfor n in n_estimators_range:\n    rf = RandomForestClassifier(n_estimators=n, random_state=42, n_jobs=-1)\n    rf.fit(X_train, y_train)\n    acc = accuracy_score(y_val, rf.predict(X_val))\n    val_accuracies.append((n, acc))\n\n# SÃ©lection du meilleur nombre d'arbres\nbest_n, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# ğŸ“ˆ Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(n_estimators_range, [acc for n, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Nombre d'arbres\")\nplt.ylabel(\"PrÃ©cision sur validation\")\nplt.title(\"Impact du nombre d'arbres sur la performance de Random Forest\")\nplt.legend()\nplt.show()\n\n# ğŸ† ModÃ¨le final avec le meilleur nombre d'arbres\nfinal_model = RandomForestClassifier(n_estimators=best_n, random_state=42, n_jobs=-1)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# ğŸ“Š Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# ğŸ“ˆ Calcul des taux de bien classÃ©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# ğŸ“ Affichage des rÃ©sultats\nprint(f\"\\nğŸ”¹ Meilleur nombre d'arbres sur lâ€™Ã©chantillon de validation : {best_n}\")\nprint(f\"Taux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec cet hyperparamÃ¨tre : {best_val_acc:.2%}\")\nprint(\"\\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nprint(conf_matrix)\n\nprint(\"\\nğŸ“ˆ Taux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nğŸ”¹ Taux de bien classÃ©s sur lâ€™Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : {overall_test_accuracy:.2%}\")\n```\n\n::: {.cell-output .cell-output-display}\n![](foret_aleatoire_files/figure-pdf/cell-2-output-1.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nğŸ”¹ Meilleur nombre d'arbres sur lâ€™Ã©chantillon de validation : 450\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec cet hyperparamÃ¨tre : 86.25%\n\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\n[[1753  312    0    0    5    2   47]\n [ 247 2490   40    1   20   31    4]\n [   0   15 1352   11    1   51    0]\n [   0    0   37   71    0    2    0]\n [   3   86   16    0  273    2    0]\n [   1   17  128    2    0  546    0]\n [  43    4    0    0    0    0  774]]\n\nğŸ“ˆ Taux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\nClasse 1 : 82.73%\nClasse 2 : 87.89%\nClasse 3 : 94.55%\nClasse 4 : 64.55%\nClasse 5 : 71.84%\nClasse 6 : 78.67%\nClasse 7 : 94.28%\n\nğŸ”¹ Taux de bien classÃ©s sur lâ€™Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : 86.55%\n```\n:::\n:::\n\n\n",
    "supporting": [
      "foret_aleatoire_files/figure-pdf"
    ],
    "filters": []
  }
}