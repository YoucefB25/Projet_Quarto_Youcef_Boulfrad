{
  "hash": "cadc0eeadb1aea5591caba07441cd60a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"T√©l√©chargement et Pr√©paration du Dataset Covertype\"\nformat: html\n---\n\n# Pr√©sentation de la Base de Donn√©es Covertype\n\nLa base de donn√©es **Covertype** provient de l'[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Covertype). Elle est utilis√©e pour **classer les types de couvert forestier** √† partir de mesures cartographiques (sol, altitude, pente, distance aux points d'eau, etc.).\n\n## Caract√©ristiques du Dataset\n\n- **Nombre d'observations** : 581 012\n- **Nombre de variables** : 54 (features continues et binaires)\n- **Nombre de classes** : 7 types de couverture foresti√®re (1 √† 7)\n- **Probl√®me √† r√©soudre** : Classification supervis√©e\n\nLes classes ne sont **pas √©quilibr√©es**, ce qui peut influencer la performance des mod√®les de classification. Les proportions des classes dans l‚Äôensemble original sont les suivantes :\n\n| Classe | Type de for√™t                   | Effectif | Proportion (%) |\n|--------|---------------------------------|-----------|---------------|\n| 1      | √âpic√©a                          | 211 840   | 36.5          |\n| 2      | Pin                             | 283 301   | 48.8          |\n| 3      | Peuplier                        | 35 754    | 6.2           |\n| 4      | Bouleau                         | 2 747     | 0.5           |\n| 5      | √ârable                          | 9 493     | 1.6           |\n| 6      | H√™tre                           | 17 367    | 3.0           |\n| 7      | M√©l√®ze                          | 18 510    | 3.2           |\n\n---\n\n## Objectif de l'√âchantillonnage\n\n### Pourquoi r√©duire la taille du dataset ?\nLe dataset **Covertype est tr√®s grand** (581 012 individus). En raison du **temps de calcul important**, nous avons d√©cid√© d'utiliser un **√©chantillon plus petit**, tout en conservant la distribution des classes.\n\n### Comment g√©rer le d√©s√©quilibre des classes ?\nCertaines classes sont **tr√®s majoritaires** (ex : **Pin et √âpic√©a** repr√©sentent √† eux seuls **85% des donn√©es**), tandis que d'autres sont **tr√®s minoritaires** (ex : **Bouleau** √† seulement **0.5%**).  \nNous avons appliqu√© un **√©chantillonnage diff√©renci√©** :\n\n- **Sous-√©chantillonnage des classes majoritaires** (√âpic√©a et Pin) ‚Üí **5% de leurs effectifs d'origine**\n- **Sur-√©chantillonnage relatif des classes minoritaires** (Peuplier, Bouleau, √ârable, H√™tre, M√©l√®ze) ‚Üí **20% de leurs effectifs d'origine**\n\n**Nous ne supprimons pas totalement le d√©s√©quilibre**, car nous souhaitons **tester nos mod√®les dans des conditions r√©alistes**, o√π certaines classes restent plus rares que d'autres.\n\nL'√©chantillon obtenu comptera un peu plus de 40 000 individus, dont 60% seront r√©serv√©s √† l'entrainement des mod√®les, 20% √† la validation des hyperparam√®tres, et 20% aux tests.\n\n---\n\n## T√©l√©chargement et Pr√©paration des Donn√©es\n\n::: {#fce982f3 .cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# üìÇ Correction du chemin d'acc√®s au fichier dataset\nfile_path = \"../data/covertype.gz\"  # On remonte d'un dossier pour atteindre data/\n\nif not os.path.exists(file_path):\n    raise FileNotFoundError(f\"‚ùå Le fichier {file_path} est introuvable. V√©rifiez son emplacement.\")\n\n# üîÑ Chargement des donn√©es\ncolumn_names = [f'Feature_{i}' for i in range(1, 55)] + ['Cover_Type']\ndata = pd.read_csv(file_path, header=None, names=column_names, compression='gzip')\n\n# üî¢ √âchantillonnage diff√©renci√©\nsampling_rates = {1: 0.05, 2: 0.05, 3: 0.2, 4: 0.2, 5: 0.2, 6: 0.2, 7: 0.2}\nsampled_data = pd.concat([\n    data[data['Cover_Type'] == cls].sample(frac=sampling_rates[cls], random_state=42)\n    for cls in data['Cover_Type'].unique()\n]).reset_index(drop=True)\n\n# üìä Division en train/val/test\ntrain_data, temp_data = train_test_split(sampled_data, test_size=0.4, random_state=42, stratify=sampled_data['Cover_Type'])\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data['Cover_Type'])\n\n# üìÇ Sauvegarde des fichiers dans data/\ntrain_data.to_csv(\"../data/covertype_train.csv\", index=False)\nval_data.to_csv(\"../data/covertype_val.csv\", index=False)\ntest_data.to_csv(\"../data/covertype_test.csv\", index=False)\n\nprint(\"‚úÖ Fichiers covertype_train.csv, covertype_val.csv et covertype_test.csv cr√©√©s avec succ√®s dans data/\")\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n‚úÖ Fichiers covertype_train.csv, covertype_val.csv et covertype_test.csv cr√©√©s avec succ√®s dans data/\n```\n:::\n:::\n\n\n",
    "supporting": [
      "donnees_files"
    ],
    "filters": [],
    "includes": {}
  }
}