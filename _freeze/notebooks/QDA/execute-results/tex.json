{
  "hash": "06ae4ef05c1f90092c369ba92ab11cd6",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Analyse Discriminante Quadratique (QDA) - Multiclasse\"\n---\n\n\n\n\n\n\n## ThÃ©orie\n\nL'**Analyse Discriminante Quadratique (QDA)** est une technique de classification qui, contrairement Ã  LDA, permet aux classes d'avoir des **matrices de covariance diffÃ©rentes**. Cela le rend plus flexible mais peut aussi augmenter le risque de sur-apprentissage.\n\nContrairement Ã  d'autres modÃ¨les initialement conÃ§us pour des problÃ¨mes binaires et adaptÃ©s aux cas multiclasse via OVA ou OVO, **QDA est intrinsÃ¨quement multiclasse**. Il attribue directement une observation Ã  lâ€™une des classes disponibles en estimant des distributions normales multivariÃ©es et en utilisant la rÃ¨gle de Bayes.\n\n## HyperparamÃ¨tre utilisÃ©\n\nNous allons optimiser :\n\n- **RÃ©gularisation (`reg_param`)** : contrÃ´le la variance de la covariance estimÃ©e et est sÃ©lectionnÃ©e en fonction de la prÃ©cision sur l'ensemble de validation.\n\n## MÃ©triques dâ€™Ã©valuation\n\nNous afficherons :\n\n- **Matrice de confusion** : montrant les erreurs de classification sur l'Ã©chantillon de test.\n- **Taux de bien classÃ©s sur l'Ã©chantillon de validation** avec le meilleur hyperparamÃ¨tre.\n- **Taux de bien classÃ©s sur l'Ã©chantillon de test** avec ce mÃªme hyperparamÃ¨tre.\n- **Taux de bien classÃ©s par classe sur l'Ã©chantillon de test** pour observer la prÃ©cision sur chaque classe.\n\n## Recherche du meilleur `reg_param` et Ã©valuation\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# ğŸ”‡ Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ğŸ”„ Chargement des ensembles de donnÃ©es\ntrain_data = pd.read_csv('../data/covertype_train.csv')\nval_data = pd.read_csv('../data/covertype_val.csv')\ntest_data = pd.read_csv('../data/covertype_test.csv')\n\n# ğŸ“Š PrÃ©paration des donnÃ©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# ğŸ”¢ Normalisation des donnÃ©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# ğŸ¯ Recherche du meilleur hyperparamÃ¨tre reg_param\nreg_params = np.linspace(0, 1, 10)\nval_accuracies = []\n\nfor reg_param in reg_params:\n    qda = QuadraticDiscriminantAnalysis(reg_param=reg_param)\n    qda.fit(X_train, y_train)\n    acc = accuracy_score(y_val, qda.predict(X_val))\n    val_accuracies.append((reg_param, acc))\n\n# SÃ©lection du meilleur hyperparamÃ¨tre\nbest_reg_param, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n# ğŸ“ˆ Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(reg_params, [acc for reg_param, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"RÃ©gularisation (reg_param)\")\nplt.ylabel(\"PrÃ©cision sur validation\")\nplt.title(\"Impact de la rÃ©gularisation sur la performance de QDA\")\nplt.legend()\nplt.show()\n\n# ğŸ† ModÃ¨le final avec le meilleur hyperparamÃ¨tre\nfinal_model = QuadraticDiscriminantAnalysis(reg_param=best_reg_param)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# ğŸ“Š Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# ğŸ“ˆ Calcul des taux de bien classÃ©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# ğŸ“ Affichage des rÃ©sultats\nprint(f\"\\nğŸ”¹ Meilleur hyperparamÃ¨tre reg_param sur l'Ã©chantillon de validation : {best_reg_param:.2f}\")\nprint(f\"Taux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : {best_val_acc:.2%}\")\nprint(\"\\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nprint(conf_matrix)\n\nprint(\"\\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : {overall_test_accuracy:.2%}\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 2 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 3 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 4 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 5 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 6 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n  warnings.warn(\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](QDA_files/figure-pdf/cell-2-output-2.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nğŸ”¹ Meilleur hyperparamÃ¨tre reg_param sur l'Ã©chantillon de validation : 0.89\nTaux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : 58.73%\n\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\n[[1163  626    1    1   89   14  225]\n [ 650 1561   51   27  402  125   17]\n [   0    7  948  136   50  289    0]\n [   0    0   45   53    0   12    0]\n [  28  103   27   19  191   12    0]\n [  11   34  230   53   31  335    0]\n [ 103   35    3    0   16    0  664]]\n\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\nClasse 1 : 54.88%\nClasse 2 : 55.10%\nClasse 3 : 66.29%\nClasse 4 : 48.18%\nClasse 5 : 50.26%\nClasse 6 : 48.27%\nClasse 7 : 80.88%\n\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : 58.60%\n```\n:::\n:::\n\n\n",
    "supporting": [
      "QDA_files/figure-pdf"
    ],
    "filters": []
  }
}