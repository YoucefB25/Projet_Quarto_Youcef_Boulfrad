[
  {
    "objectID": "notebooks/regression_logistique_ovo.html",
    "href": "notebooks/regression_logistique_ovo.html",
    "title": "R√©gression Logistique Binomiale - One-Versus-One (OVO)",
    "section": "",
    "text": "La r√©gression logistique binomiale est utilis√©e pour la classification binaire, mais elle peut √™tre adapt√©e aux probl√®mes multiclasse via l‚Äôapproche One-Versus-One (OVO). Ici, un mod√®le est entra√Æn√© pour chaque paire de classes, ce qui peut am√©liorer la pr√©cision lorsque les classes sont bien s√©par√©es."
  },
  {
    "objectID": "notebooks/regression_logistique_ovo.html#th√©orie",
    "href": "notebooks/regression_logistique_ovo.html#th√©orie",
    "title": "R√©gression Logistique Binomiale - One-Versus-One (OVO)",
    "section": "",
    "text": "La r√©gression logistique binomiale est utilis√©e pour la classification binaire, mais elle peut √™tre adapt√©e aux probl√®mes multiclasse via l‚Äôapproche One-Versus-One (OVO). Ici, un mod√®le est entra√Æn√© pour chaque paire de classes, ce qui peut am√©liorer la pr√©cision lorsque les classes sont bien s√©par√©es."
  },
  {
    "objectID": "notebooks/regression_logistique_ovo.html#hyperparam√®tre-utilis√©",
    "href": "notebooks/regression_logistique_ovo.html#hyperparam√®tre-utilis√©",
    "title": "R√©gression Logistique Binomiale - One-Versus-One (OVO)",
    "section": "Hyperparam√®tre utilis√©",
    "text": "Hyperparam√®tre utilis√©\nNous allons optimiser :\n\nParam√®tre de r√©gularisation (C) : qui contr√¥le la complexit√© du mod√®le et est s√©lectionn√© en fonction de la pr√©cision sur l‚Äôensemble de validation."
  },
  {
    "objectID": "notebooks/regression_logistique_ovo.html#m√©triques-d√©valuation",
    "href": "notebooks/regression_logistique_ovo.html#m√©triques-d√©valuation",
    "title": "R√©gression Logistique Binomiale - One-Versus-One (OVO)",
    "section": "M√©triques d‚Äô√©valuation",
    "text": "M√©triques d‚Äô√©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur l‚Äô√©chantillon de test.\nTaux de bien class√©s sur l‚Äô√©chantillon de validation avec le meilleur hyperparam√®tre.\nTaux de bien class√©s sur l‚Äô√©chantillon de test avec ce m√™me hyperparam√®tre.\nTaux de bien class√©s par classe sur l‚Äô√©chantillon de test pour observer la pr√©cision sur chaque classe."
  },
  {
    "objectID": "notebooks/regression_logistique_ovo.html#recherche-du-meilleur-c-et-√©valuation",
    "href": "notebooks/regression_logistique_ovo.html#recherche-du-meilleur-c-et-√©valuation",
    "title": "R√©gression Logistique Binomiale - One-Versus-One (OVO)",
    "section": "Recherche du meilleur C et √©valuation",
    "text": "Recherche du meilleur C et √©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# üîá Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# üîÑ Chargement des ensembles de donn√©es\ntrain_data = pd.read_csv('../data/covertype_train.csv')\nval_data = pd.read_csv('../data/covertype_val.csv')\ntest_data = pd.read_csv('../data/covertype_test.csv')\n\n# üìä Pr√©paration des donn√©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# üî¢ Normalisation des donn√©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# üéØ Recherche du meilleur hyperparam√®tre C\nC_values = np.arange(0.1, 1.1, 0.1)\nval_accuracies = []\n\nfor C in C_values:\n    model = OneVsOneClassifier(LogisticRegression(solver='saga', C=C, penalty='l2', max_iter=500))\n    model.fit(X_train, y_train)\n    acc = accuracy_score(y_val, model.predict(X_val))\n    val_accuracies.append((C, acc))\n\n# S√©lection du meilleur hyperparam√®tre\nbest_C, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# üìà Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(C_values, [acc for C, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Param√®tre de r√©gularisation (C)\")\nplt.ylabel(\"Pr√©cision sur validation\")\nplt.title(\"Impact de la r√©gularisation sur la performance de la r√©gression logistique (OVO)\")\nplt.legend()\nplt.show()\n\n# üèÜ Mod√®le final avec le meilleur hyperparam√®tre\nfinal_model = OneVsOneClassifier(LogisticRegression(solver='saga', C=best_C, penalty='l2', max_iter=500))\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# üìä Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# üìà Calcul des taux de bien class√©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# üìù Affichage des r√©sultats\nprint(f\"\\nüîπ Meilleur hyperparam√®tre C sur l'√©chantillon de validation : {best_C:.2f}\")\nprint(f\"Taux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : {best_val_acc:.2%}\")\nprint(\"\\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\")\nprint(conf_matrix)\n\nprint(\"\\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nüîπ Meilleur hyperparam√®tre C sur l'√©chantillon de validation : 0.30\nTaux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : 69.53%\n\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\n[[1419  584    1    0    6    1  108]\n [ 517 2136   85    1   36   50    8]\n [   0   44 1241   35    4  106    0]\n [   0    0   56   38    0   16    0]\n [   2  254   21    0   98    5    0]\n [   0   53  359    2    2  278    0]\n [ 158    1    2    0    0    0  660]]\n\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre  :\nClasse 1 : 66.97%\nClasse 2 : 75.40%\nClasse 3 : 86.78%\nClasse 4 : 34.55%\nClasse 5 : 25.79%\nClasse 6 : 40.06%\nClasse 7 : 80.39%\n\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : 69.99%"
  },
  {
    "objectID": "notebooks/regression_multinomiale.html",
    "href": "notebooks/regression_multinomiale.html",
    "title": "R√©gression Multinomiale (Softmax Regression)",
    "section": "",
    "text": "La r√©gression multinomiale, aussi appel√©e r√©gression logistique multinomiale, est une extension de la r√©gression logistique qui permet de g√©rer plusieurs classes. Elle utilise une fonction Softmax en sortie pour assigner une probabilit√© √† chaque classe."
  },
  {
    "objectID": "notebooks/regression_multinomiale.html#th√©orie",
    "href": "notebooks/regression_multinomiale.html#th√©orie",
    "title": "R√©gression Multinomiale (Softmax Regression)",
    "section": "",
    "text": "La r√©gression multinomiale, aussi appel√©e r√©gression logistique multinomiale, est une extension de la r√©gression logistique qui permet de g√©rer plusieurs classes. Elle utilise une fonction Softmax en sortie pour assigner une probabilit√© √† chaque classe."
  },
  {
    "objectID": "notebooks/regression_multinomiale.html#hyperparam√®tre-utilis√©",
    "href": "notebooks/regression_multinomiale.html#hyperparam√®tre-utilis√©",
    "title": "R√©gression Multinomiale (Softmax Regression)",
    "section": "Hyperparam√®tre utilis√©",
    "text": "Hyperparam√®tre utilis√©\nNous allons optimiser :\n\nParam√®tre de r√©gularisation (C) : contr√¥le la p√©nalisation de la complexit√© du mod√®le et est s√©lectionn√© en fonction de la pr√©cision sur l‚Äôensemble de validation."
  },
  {
    "objectID": "notebooks/regression_multinomiale.html#m√©triques-d√©valuation",
    "href": "notebooks/regression_multinomiale.html#m√©triques-d√©valuation",
    "title": "R√©gression Multinomiale (Softmax Regression)",
    "section": "M√©triques d‚Äô√©valuation",
    "text": "M√©triques d‚Äô√©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur l‚Äô√©chantillon de test.\nTaux de bien class√©s sur l‚Äô√©chantillon de validation avec le meilleur hyperparam√®tre.\nTaux de bien class√©s sur l‚Äô√©chantillon de test avec ce m√™me hyperparam√®tre.\nTaux de bien class√©s par classe sur l‚Äô√©chantillon de test pour observer la pr√©cision sur chaque classe."
  },
  {
    "objectID": "notebooks/regression_multinomiale.html#recherche-du-meilleur-c-et-√©valuation",
    "href": "notebooks/regression_multinomiale.html#recherche-du-meilleur-c-et-√©valuation",
    "title": "R√©gression Multinomiale (Softmax Regression)",
    "section": "Recherche du meilleur C et √©valuation",
    "text": "Recherche du meilleur C et √©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# üîá Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# üîÑ Chargement des ensembles de donn√©es\ntrain_data = pd.read_csv('../data/covertype_train.csv')\nval_data = pd.read_csv('../data/covertype_val.csv')\ntest_data = pd.read_csv('../data/covertype_test.csv')\n\n# üìä Pr√©paration des donn√©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# üî¢ Normalisation des donn√©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# üéØ Recherche du meilleur hyperparam√®tre C\nC_values = np.arange(0.1, 1.1, 0.1)\nval_accuracies = []\n\nfor C in C_values:\n    model = LogisticRegression(multi_class='multinomial', solver='saga', C=C, penalty='l2', max_iter=500)\n    model.fit(X_train, y_train)\n    acc = accuracy_score(y_val, model.predict(X_val))\n    val_accuracies.append((C, acc))\n\n# S√©lection du meilleur hyperparam√®tre\nbest_C, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# üìà Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(C_values, [acc for C, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Param√®tre de r√©gularisation (C)\")\nplt.ylabel(\"Pr√©cision sur validation\")\nplt.title(\"Impact de la r√©gularisation sur la performance de la r√©gression multinomiale\")\nplt.legend()\nplt.show()\n\n# üèÜ Mod√®le final avec le meilleur hyperparam√®tre\nfinal_model = LogisticRegression(multi_class='multinomial', solver='saga', C=best_C, penalty='l2', max_iter=500)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# üìä Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# üìà Calcul des taux de bien class√©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# üìù Affichage des r√©sultats\nprint(f\"\\nüîπ Meilleur hyperparam√®tre C sur l'√©chantillon de validation : {best_C:.2f}\")\nprint(f\"Taux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : {best_val_acc:.2%}\")\nprint(\"\\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\")\nprint(conf_matrix)\n\nprint(\"\\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : {overall_test_accuracy:.2%}\")\n\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n\n\n\nüîπ Meilleur hyperparam√®tre C sur l'√©chantillon de validation : 0.10\nTaux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : 69.14%\n\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\n[[1416  583    1    0    6    1  112]\n [ 511 2142   87    1   40   44    8]\n [   0   48 1249   38    8   87    0]\n [   0    0   61   34    0   15    0]\n [   2  257   24    0   92    5    0]\n [   0   64  374    3    8  245    0]\n [ 163    1    3    0    0    0  654]]\n\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre  :\nClasse 1 : 66.82%\nClasse 2 : 75.61%\nClasse 3 : 87.34%\nClasse 4 : 30.91%\nClasse 5 : 24.21%\nClasse 6 : 35.30%\nClasse 7 : 79.66%\n\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : 69.54%"
  },
  {
    "objectID": "notebooks/presentation.html",
    "href": "notebooks/presentation.html",
    "title": "Pr√©sentation des techniques de classification supervis√©e utilis√©es",
    "section": "",
    "text": "En classification supervis√©e, les algorithmes peuvent √™tre divis√©s en m√©thodes param√©triques et m√©thodes non-param√©triques. Cette distinction repose sur la mani√®re dont les mod√®les apprennent et g√©n√©ralisent les donn√©es.\n\n\nLes mod√®les param√©triques supposent l‚Äôexistence d‚Äôune distribution sous-jacente aux donn√©es et estiment ses param√®tres √† partir des donn√©es d‚Äôentrainement.\n\n\n\nR√©gression Logistique (OVA et OVO)\nR√©gression Multinomiale (Softmax Regression)\nAnalyse Discriminante Lin√©aire (LDA)\nAnalyse Discriminante Quadratique (QDA)\nClassifieur Bay√©sien Na√Øf\n\n\n\n\n\nLes mod√®les non-param√©triques ne supposent pas l‚Äôexistence d‚Äôune distribution sous-jacente aux donn√©es. Ils estiment les limites entre les classes de fa√ßon ‚Äúgloutonne‚Äù en maximisant les diff√©rences inter-classes et minisant les diff√©rences intra-classes sur les donn√©es d‚Äôentrainement.\n\n\n\nArbre de D√©cision (CART)\nFor√™t Al√©atoire (Random Forest)\nK-Nearest Neighbors (KNN)\nMachines √† Vecteurs de Support (SVM - OVA et OVO)\nR√©seau de Neurones (MLP avec sortie Softmax)"
  },
  {
    "objectID": "notebooks/presentation.html#classification-param√©trique-vs-non-param√©trique",
    "href": "notebooks/presentation.html#classification-param√©trique-vs-non-param√©trique",
    "title": "Pr√©sentation des techniques de classification supervis√©e utilis√©es",
    "section": "",
    "text": "En classification supervis√©e, les algorithmes peuvent √™tre divis√©s en m√©thodes param√©triques et m√©thodes non-param√©triques. Cette distinction repose sur la mani√®re dont les mod√®les apprennent et g√©n√©ralisent les donn√©es.\n\n\nLes mod√®les param√©triques supposent l‚Äôexistence d‚Äôune distribution sous-jacente aux donn√©es et estiment ses param√®tres √† partir des donn√©es d‚Äôentrainement.\n\n\n\nR√©gression Logistique (OVA et OVO)\nR√©gression Multinomiale (Softmax Regression)\nAnalyse Discriminante Lin√©aire (LDA)\nAnalyse Discriminante Quadratique (QDA)\nClassifieur Bay√©sien Na√Øf\n\n\n\n\n\nLes mod√®les non-param√©triques ne supposent pas l‚Äôexistence d‚Äôune distribution sous-jacente aux donn√©es. Ils estiment les limites entre les classes de fa√ßon ‚Äúgloutonne‚Äù en maximisant les diff√©rences inter-classes et minisant les diff√©rences intra-classes sur les donn√©es d‚Äôentrainement.\n\n\n\nArbre de D√©cision (CART)\nFor√™t Al√©atoire (Random Forest)\nK-Nearest Neighbors (KNN)\nMachines √† Vecteurs de Support (SVM - OVA et OVO)\nR√©seau de Neurones (MLP avec sortie Softmax)"
  },
  {
    "objectID": "notebooks/presentation.html#classifieurs-multiclasses-natifs-vs-classifieurs-binaires-adapt√©s",
    "href": "notebooks/presentation.html#classifieurs-multiclasses-natifs-vs-classifieurs-binaires-adapt√©s",
    "title": "Pr√©sentation des techniques de classification supervis√©e utilis√©es",
    "section": "Classifieurs Multiclasses Natifs vs Classifieurs Binaires Adapt√©s",
    "text": "Classifieurs Multiclasses Natifs vs Classifieurs Binaires Adapt√©s\nCertains classifieurs sont con√ßus pour g√©rer directement plusieurs classes (classifieurs multiclasses natifs), tandis que d‚Äôautres sont con√ßus pour distinguer uniquement deux classes et doivent √™tre adapt√©s pour des probl√®mes multiclasses.\n\n1. Classifieurs Multiclasses Natifs\nCes classifieurs peuvent traiter directement un probl√®me √† plusieurs classes sans n√©cessiter de transformation :\n\nR√©gression Multinomiale (Softmax Regression)\nAnalyse Discriminante Lin√©aire (LDA)\nAnalyse Discriminante Quadratique (QDA)\nClassifieur Bay√©sien Na√Øf\nArbre de D√©cision (CART)\nFor√™t Al√©atoire (Random Forest)\nR√©seau de Neurones (MLP avec sortie Softmax)\nK-Nearest Neighbors (KNN)\n\n\n\n2. Classifieurs Binaires Adapt√©s\nLes classifieurs binaires doivent √™tre transform√©s pour g√©rer plusieurs classes en utilisant des approches comme One-Versus-All (OVA) ou One-Versus-One (OVO) :\n\nR√©gression Logistique (adapt√©e en OVA et OVO)\nSupport Vector Machines (SVM) (adapt√©es en OVA et OVO)"
  },
  {
    "objectID": "notebooks/presentation.html#one-versus-all-ova-vs-one-versus-one-ovo",
    "href": "notebooks/presentation.html#one-versus-all-ova-vs-one-versus-one-ovo",
    "title": "Pr√©sentation des techniques de classification supervis√©e utilis√©es",
    "section": "One-Versus-All (OVA) vs One-Versus-One (OVO)",
    "text": "One-Versus-All (OVA) vs One-Versus-One (OVO)\nLes approches OVA et OVO permettent d‚Äôadapter des classifieurs binaires aux probl√®mes multiclasses.\n\n1. One-Versus-All (OVA)\nAvec cette approche, un mod√®le binaire est entra√Æn√© pour chaque classe en la comparant √† toutes les autres classes regroup√©es. Pour une classification √† N classes, N mod√®les binaires sont entra√Æn√©s.\nAvantages : - Moins de mod√®les √† entra√Æner (N contre N(N-1)/2 en OVO), soit 7 mod√®les pour 7 classes. - Plus efficace pour les jeux de donn√©es avec un grand nombre de classes.\nInconv√©nients : - Les classes d√©s√©quilibr√©es peuvent poser probl√®me car le mod√®le doit distinguer une classe contre un ensemble de classes plus nombreuses. - Peut g√©n√©rer des scores de confiance biais√©s si les classes sont tr√®s d√©s√©quilibr√©es.\nExemples de classifieurs utilisant OVA :\n\nR√©gression Logistique (OVA)\nSVM (OVA)\n\n\n\n2. One-Versus-One (OVO)\nAvec l‚Äôapproche OVO, un mod√®le est entra√Æn√© pour chaque paire de classes. Pour une classification √† N classes, N(N-1)/2 mod√®les binaires sont entra√Æn√©s, soit 21 mod√®les pour 7 classes.\nAvantages : - Meilleure s√©paration entre classes si elles sont bien distinctes. - Moins sensible aux classes d√©s√©quilibr√©es car chaque mod√®le compare seulement deux classes √† la fois.\nInconv√©nients : - Temps d‚Äôentra√Ænement plus long √† cause du grand nombre de mod√®les. - Peut n√©cessiter plus de ressources pour l‚Äôinf√©rence.\nExemples de classifieurs utilisant OVO :\n\nR√©gression Logistique (OVO)\nSVM (OVO)"
  },
  {
    "objectID": "notebooks/LDA.html",
    "href": "notebooks/LDA.html",
    "title": "Analyse Discriminante Lin√©aire (LDA) - Multiclasse",
    "section": "",
    "text": "L‚ÄôAnalyse Discriminante Lin√©aire (LDA) est une technique de classification qui cherche √† trouver une combinaison lin√©aire de caract√©ristiques maximisant la s√©paration entre plusieurs classes.\nContrairement √† d‚Äôautres mod√®les initialement con√ßus pour des probl√®mes binaires et adapt√©s aux cas multiclasse via OVA ou OVO, LDA est intrins√®quement multiclasse. Il attribue directement une observation √† l‚Äôune des classes disponibles en estimant des distributions normales multivari√©es et en utilisant la r√®gle de Bayes."
  },
  {
    "objectID": "notebooks/LDA.html#th√©orie",
    "href": "notebooks/LDA.html#th√©orie",
    "title": "Analyse Discriminante Lin√©aire (LDA) - Multiclasse",
    "section": "",
    "text": "L‚ÄôAnalyse Discriminante Lin√©aire (LDA) est une technique de classification qui cherche √† trouver une combinaison lin√©aire de caract√©ristiques maximisant la s√©paration entre plusieurs classes.\nContrairement √† d‚Äôautres mod√®les initialement con√ßus pour des probl√®mes binaires et adapt√©s aux cas multiclasse via OVA ou OVO, LDA est intrins√®quement multiclasse. Il attribue directement une observation √† l‚Äôune des classes disponibles en estimant des distributions normales multivari√©es et en utilisant la r√®gle de Bayes."
  },
  {
    "objectID": "notebooks/LDA.html#hyperparam√®tre-utilis√©",
    "href": "notebooks/LDA.html#hyperparam√®tre-utilis√©",
    "title": "Analyse Discriminante Lin√©aire (LDA) - Multiclasse",
    "section": "Hyperparam√®tre utilis√©",
    "text": "Hyperparam√®tre utilis√©\nNous allons optimiser :\n\nR√©gularisation (shrinkage) : contr√¥le la variance de la covariance estim√©e et est s√©lectionn√©e en fonction de la pr√©cision sur l‚Äôensemble de validation."
  },
  {
    "objectID": "notebooks/LDA.html#m√©triques-d√©valuation",
    "href": "notebooks/LDA.html#m√©triques-d√©valuation",
    "title": "Analyse Discriminante Lin√©aire (LDA) - Multiclasse",
    "section": "M√©triques d‚Äô√©valuation",
    "text": "M√©triques d‚Äô√©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur l‚Äô√©chantillon de test.\nTaux de bien class√©s sur l‚Äô√©chantillon de validation avec le meilleur hyperparam√®tre.\nTaux de bien class√©s sur l‚Äô√©chantillon de test avec ce m√™me hyperparam√®tre.\nTaux de bien class√©s par classe sur l‚Äô√©chantillon de test pour observer la pr√©cision sur chaque classe."
  },
  {
    "objectID": "notebooks/LDA.html#recherche-du-meilleur-shrinkage-et-√©valuation",
    "href": "notebooks/LDA.html#recherche-du-meilleur-shrinkage-et-√©valuation",
    "title": "Analyse Discriminante Lin√©aire (LDA) - Multiclasse",
    "section": "Recherche du meilleur shrinkage et √©valuation",
    "text": "Recherche du meilleur shrinkage et √©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# üîá Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# üîÑ Chargement des ensembles de donn√©es\ntrain_data = pd.read_csv('../data/covertype_train.csv')\nval_data = pd.read_csv('../data/covertype_val.csv')\ntest_data = pd.read_csv('../data/covertype_test.csv')\n\n# üìä Pr√©paration des donn√©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# üî¢ Normalisation des donn√©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# üéØ Recherche du meilleur hyperparam√®tre shrinkage\nshrinkage_values = np.linspace(0, 1, 10)\nval_accuracies = []\n\nfor shrinkage in shrinkage_values:\n    lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage=shrinkage)\n    lda.fit(X_train, y_train)\n    acc = accuracy_score(y_val, lda.predict(X_val))\n    val_accuracies.append((shrinkage, acc))\n\n# S√©lection du meilleur hyperparam√®tre\nbest_shrinkage, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n# üìà Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(shrinkage_values, [acc for shrinkage, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Shrinkage\")\nplt.ylabel(\"Pr√©cision sur validation\")\nplt.title(\"Impact du shrinkage sur la performance de LDA\")\nplt.legend()\nplt.show()\n\n# üèÜ Mod√®le final avec le meilleur hyperparam√®tre\nfinal_model = LinearDiscriminantAnalysis(solver='lsqr', shrinkage=best_shrinkage)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# üìä Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# üìà Calcul des taux de bien class√©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# üìù Affichage des r√©sultats\nprint(f\"\\nüîπ Meilleur hyperparam√®tre shrinkage sur l'√©chantillon de validation : {best_shrinkage:.2f}\")\nprint(f\"Taux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : {best_val_acc:.2%}\")\nprint(\"\\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\")\nprint(conf_matrix)\n\nprint(\"\\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nüîπ Meilleur hyperparam√®tre shrinkage sur l'√©chantillon de validation : 0.00\nTaux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : 63.37%\n\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\n[[1344  520    1    0   27    2  225]\n [ 548 1865   48   17  218  124   13]\n [   0   29  902  130   32  337    0]\n [   0    0   44   53    0   13    0]\n [   2  160   27    0  179   12    0]\n [   0   53  210   25   42  364    0]\n [ 154    0    3    0    0    0  664]]\n\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\nClasse 1 : 63.43%\nClasse 2 : 65.83%\nClasse 3 : 63.08%\nClasse 4 : 48.18%\nClasse 5 : 47.11%\nClasse 6 : 52.45%\nClasse 7 : 80.88%\n\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : 64.04%"
  },
  {
    "objectID": "notebooks/arbre_decision.html",
    "href": "notebooks/arbre_decision.html",
    "title": "Arbre de D√©cision - CART",
    "section": "",
    "text": "L‚Äôalgorithme CART (Classification and Regression Trees) est un mod√®le d‚Äôapprentissage supervis√© qui construit un arbre de d√©cision en divisant l‚Äôespace des caract√©ristiques en sous-ensembles homog√®nes."
  },
  {
    "objectID": "notebooks/arbre_decision.html#th√©orie",
    "href": "notebooks/arbre_decision.html#th√©orie",
    "title": "Arbre de D√©cision - CART",
    "section": "",
    "text": "L‚Äôalgorithme CART (Classification and Regression Trees) est un mod√®le d‚Äôapprentissage supervis√© qui construit un arbre de d√©cision en divisant l‚Äôespace des caract√©ristiques en sous-ensembles homog√®nes."
  },
  {
    "objectID": "notebooks/arbre_decision.html#hyperparam√®tre-utilis√©",
    "href": "notebooks/arbre_decision.html#hyperparam√®tre-utilis√©",
    "title": "Arbre de D√©cision - CART",
    "section": "Hyperparam√®tre utilis√©",
    "text": "Hyperparam√®tre utilis√©\nNous allons optimiser :\n\nProfondeur maximale de l‚Äôarbre (max_depth) : s√©lectionn√©e en fonction de la pr√©cision sur l‚Äôensemble de validation."
  },
  {
    "objectID": "notebooks/arbre_decision.html#m√©triques-d√©valuation",
    "href": "notebooks/arbre_decision.html#m√©triques-d√©valuation",
    "title": "Arbre de D√©cision - CART",
    "section": "M√©triques d‚Äô√©valuation",
    "text": "M√©triques d‚Äô√©valuation\nNous afficherons :\n\nMatrice de confusion : r√©capitulant les erreurs de classification.\nTaux de bien class√©s sur l‚Äô√©chantillon de validation avec le meilleur hyperparam√®tre.\nTaux de bien class√©s sur l‚Äô√©chantillon de test avec ce m√™me hyperparam√®tre.\nTaux de bien class√©s par classe sur l‚Äô√©chantillon de test."
  },
  {
    "objectID": "notebooks/arbre_decision.html#recherche-de-la-meilleure-max_depth-et-√©valuation",
    "href": "notebooks/arbre_decision.html#recherche-de-la-meilleure-max_depth-et-√©valuation",
    "title": "Arbre de D√©cision - CART",
    "section": "Recherche de la meilleure max_depth et √©valuation",
    "text": "Recherche de la meilleure max_depth et √©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport warnings\n\n# üîá Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# üîÑ Chargement des ensembles de donn√©es\ntrain_data = pd.read_csv('../data/covertype_train.csv')\nval_data = pd.read_csv('../data/covertype_val.csv')\ntest_data = pd.read_csv('../data/covertype_test.csv')\n\n# üìä Pr√©paration des donn√©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# üéØ Recherche du meilleur hyperparam√®tre max_depth\ndepth_range = range(1, 30)\nval_accuracies = []\n\nfor depth in depth_range:\n    tree = DecisionTreeClassifier(max_depth=depth, random_state=42)\n    tree.fit(X_train, y_train)\n    acc = accuracy_score(y_val, tree.predict(X_val))\n    val_accuracies.append((depth, acc))\n\n# S√©lection de la meilleure profondeur d'arbre\nbest_depth, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# üìà Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(depth_range, [acc for depth, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Profondeur de l'arbre\")\nplt.ylabel(\"Pr√©cision sur validation\")\nplt.title(\"Impact de la profondeur de l'arbre sur la performance de CART\")\nplt.legend()\nplt.show()\n\n# üèÜ Mod√®le final avec la meilleure profondeur\nfinal_model = DecisionTreeClassifier(max_depth=best_depth, random_state=42)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# üìä Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# üìà Calcul des taux de bien class√©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# üìù Affichage des r√©sultats\nprint(f\"\\nüîπ Meilleure profondeur de l'arbre sur l‚Äô√©chantillon de validation : {best_depth}\")\nprint(f\"Taux de bien class√©s sur l‚Äô√©chantillon de validation avec cet hyperparam√®tre : {best_val_acc:.2%}\")\nprint(\"\\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\")\nprint(conf_matrix)\n\nprint(\"\\nüìà Taux de bien class√©s par classe sur l‚Äô√©chantillon de test, avec le meilleur hyperparam√®tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nüîπ Taux de bien class√©s sur l‚Äô√©chantillon de test avec le meilleur hyperparam√®tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nüîπ Meilleure profondeur de l'arbre sur l‚Äô√©chantillon de validation : 25\nTaux de bien class√©s sur l‚Äô√©chantillon de validation avec cet hyperparam√®tre : 78.43%\n\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\n[[1581  449    1    0   11    1   76]\n [ 459 2177   43    1   93   52    8]\n [   2   46 1216   24   13  129    0]\n [   0    0   23   74    0   13    0]\n [  10   83   13    0  263   11    0]\n [   4   40  128    4    4  514    0]\n [  61   14    0    0    0    0  746]]\n\nüìà Taux de bien class√©s par classe sur l‚Äô√©chantillon de test, avec le meilleur hyperparam√®tre  :\nClasse 1 : 74.61%\nClasse 2 : 76.84%\nClasse 3 : 85.03%\nClasse 4 : 67.27%\nClasse 5 : 69.21%\nClasse 6 : 74.06%\nClasse 7 : 90.86%\n\nüîπ Taux de bien class√©s sur l‚Äô√©chantillon de test avec le meilleur hyperparam√®tre : 78.35%"
  },
  {
    "objectID": "notebooks/svm_ovo.html",
    "href": "notebooks/svm_ovo.html",
    "title": "Support Vector Machines (SVM) - One-Versus-One (OVO)",
    "section": "",
    "text": "Les machines √† vecteurs de support (SVM) sont des mod√®les de classification supervis√©s qui cherchent √† maximiser la marge de s√©paration entre les classes. Pour un probl√®me multiclasse, l‚Äôapproche One-Versus-One (OVO) entra√Æne un SVM pour chaque paire de classes, ce qui permet une meilleure s√©paration lorsque les classes sont bien distinctes."
  },
  {
    "objectID": "notebooks/svm_ovo.html#th√©orie",
    "href": "notebooks/svm_ovo.html#th√©orie",
    "title": "Support Vector Machines (SVM) - One-Versus-One (OVO)",
    "section": "",
    "text": "Les machines √† vecteurs de support (SVM) sont des mod√®les de classification supervis√©s qui cherchent √† maximiser la marge de s√©paration entre les classes. Pour un probl√®me multiclasse, l‚Äôapproche One-Versus-One (OVO) entra√Æne un SVM pour chaque paire de classes, ce qui permet une meilleure s√©paration lorsque les classes sont bien distinctes."
  },
  {
    "objectID": "notebooks/svm_ovo.html#hyperparam√®tre-utilis√©",
    "href": "notebooks/svm_ovo.html#hyperparam√®tre-utilis√©",
    "title": "Support Vector Machines (SVM) - One-Versus-One (OVO)",
    "section": "Hyperparam√®tre utilis√©",
    "text": "Hyperparam√®tre utilis√©\nNous allons optimiser :\n\nParam√®tre de r√©gularisation (C) : contr√¥le la p√©nalisation des erreurs de classification et est s√©lectionn√© en fonction de la pr√©cision sur l‚Äôensemble de validation."
  },
  {
    "objectID": "notebooks/svm_ovo.html#m√©triques-d√©valuation",
    "href": "notebooks/svm_ovo.html#m√©triques-d√©valuation",
    "title": "Support Vector Machines (SVM) - One-Versus-One (OVO)",
    "section": "M√©triques d‚Äô√©valuation",
    "text": "M√©triques d‚Äô√©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur l‚Äô√©chantillon de test.\nTaux de bien class√©s sur l‚Äô√©chantillon de validation avec le meilleur hyperparam√®tre.\nTaux de bien class√©s sur l‚Äô√©chantillon de test avec ce m√™me hyperparam√®tre.\nTaux de bien class√©s par classe sur l‚Äô√©chantillon de test pour observer la pr√©cision sur chaque classe."
  },
  {
    "objectID": "notebooks/svm_ovo.html#recherche-du-meilleur-c-et-√©valuation",
    "href": "notebooks/svm_ovo.html#recherche-du-meilleur-c-et-√©valuation",
    "title": "Support Vector Machines (SVM) - One-Versus-One (OVO)",
    "section": "Recherche du meilleur C et √©valuation",
    "text": "Recherche du meilleur C et √©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# üîá Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# üîÑ Chargement des ensembles de donn√©es\ntrain_data = pd.read_csv('../data/covertype_train.csv')\nval_data = pd.read_csv('../data/covertype_val.csv')\ntest_data = pd.read_csv('../data/covertype_test.csv')\n\n# üìä Pr√©paration des donn√©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# üî¢ Normalisation des donn√©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# üéØ Recherche du meilleur hyperparam√®tre C\nC_values = np.arange(0.1, 1.1, 0.1)\nval_accuracies = []\n\nfor C in C_values:\n    model = OneVsOneClassifier(SVC(kernel='rbf', C=C))\n    model.fit(X_train, y_train)\n    acc = accuracy_score(y_val, model.predict(X_val))\n    val_accuracies.append((C, acc))\n\n# S√©lection du meilleur hyperparam√®tre\nbest_C, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# üìà Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(C_values, [acc for C, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Param√®tre de r√©gularisation (C)\")\nplt.ylabel(\"Pr√©cision sur validation\")\nplt.title(\"Impact de la r√©gularisation sur la performance du SVM (OVO)\")\nplt.legend()\nplt.show()\n\n# üèÜ Mod√®le final avec le meilleur hyperparam√®tre\nfinal_model = OneVsOneClassifier(SVC(kernel='rbf', C=best_C))\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# üìä Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# üìà Calcul des taux de bien class√©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# üìù Affichage des r√©sultats\nprint(f\"\\nüîπ Meilleur hyperparam√®tre C sur l'√©chantillon de validation : {best_C:.2f}\")\nprint(f\"Taux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : {best_val_acc:.2%}\")\nprint(\"\\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\")\nprint(conf_matrix)\n\nprint(\"\\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nüîπ Meilleur hyperparam√®tre C sur l'√©chantillon de validation : 1.00\nTaux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : 72.54%\n\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\n[[1495  519    1    0    5    5   94]\n [ 433 2227   85    1   36   47    4]\n [   0   53 1292   18    4   63    0]\n [   0    0   79   24    0    7    0]\n [   1  212   25    0  131   11    0]\n [   0   45  377    3    1  268    0]\n [ 144    8    0    0    0    0  669]]\n\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre  :\nClasse 1 : 70.55%\nClasse 2 : 78.61%\nClasse 3 : 90.35%\nClasse 4 : 21.82%\nClasse 5 : 34.47%\nClasse 6 : 38.62%\nClasse 7 : 81.49%\n\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : 72.80%"
  },
  {
    "objectID": "notebooks/QDA.html",
    "href": "notebooks/QDA.html",
    "title": "Analyse Discriminante Quadratique (QDA) - Multiclasse",
    "section": "",
    "text": "L‚ÄôAnalyse Discriminante Quadratique (QDA) est une technique de classification qui, contrairement √† LDA, permet aux classes d‚Äôavoir des matrices de covariance diff√©rentes. Cela le rend plus flexible mais peut aussi augmenter le risque de sur-apprentissage.\nContrairement √† d‚Äôautres mod√®les initialement con√ßus pour des probl√®mes binaires et adapt√©s aux cas multiclasse via OVA ou OVO, QDA est intrins√®quement multiclasse. Il attribue directement une observation √† l‚Äôune des classes disponibles en estimant des distributions normales multivari√©es et en utilisant la r√®gle de Bayes."
  },
  {
    "objectID": "notebooks/QDA.html#th√©orie",
    "href": "notebooks/QDA.html#th√©orie",
    "title": "Analyse Discriminante Quadratique (QDA) - Multiclasse",
    "section": "",
    "text": "L‚ÄôAnalyse Discriminante Quadratique (QDA) est une technique de classification qui, contrairement √† LDA, permet aux classes d‚Äôavoir des matrices de covariance diff√©rentes. Cela le rend plus flexible mais peut aussi augmenter le risque de sur-apprentissage.\nContrairement √† d‚Äôautres mod√®les initialement con√ßus pour des probl√®mes binaires et adapt√©s aux cas multiclasse via OVA ou OVO, QDA est intrins√®quement multiclasse. Il attribue directement une observation √† l‚Äôune des classes disponibles en estimant des distributions normales multivari√©es et en utilisant la r√®gle de Bayes."
  },
  {
    "objectID": "notebooks/QDA.html#hyperparam√®tre-utilis√©",
    "href": "notebooks/QDA.html#hyperparam√®tre-utilis√©",
    "title": "Analyse Discriminante Quadratique (QDA) - Multiclasse",
    "section": "Hyperparam√®tre utilis√©",
    "text": "Hyperparam√®tre utilis√©\nNous allons optimiser :\n\nR√©gularisation (reg_param) : contr√¥le la variance de la covariance estim√©e et est s√©lectionn√©e en fonction de la pr√©cision sur l‚Äôensemble de validation."
  },
  {
    "objectID": "notebooks/QDA.html#m√©triques-d√©valuation",
    "href": "notebooks/QDA.html#m√©triques-d√©valuation",
    "title": "Analyse Discriminante Quadratique (QDA) - Multiclasse",
    "section": "M√©triques d‚Äô√©valuation",
    "text": "M√©triques d‚Äô√©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur l‚Äô√©chantillon de test.\nTaux de bien class√©s sur l‚Äô√©chantillon de validation avec le meilleur hyperparam√®tre.\nTaux de bien class√©s sur l‚Äô√©chantillon de test avec ce m√™me hyperparam√®tre.\nTaux de bien class√©s par classe sur l‚Äô√©chantillon de test pour observer la pr√©cision sur chaque classe."
  },
  {
    "objectID": "notebooks/QDA.html#recherche-du-meilleur-reg_param-et-√©valuation",
    "href": "notebooks/QDA.html#recherche-du-meilleur-reg_param-et-√©valuation",
    "title": "Analyse Discriminante Quadratique (QDA) - Multiclasse",
    "section": "Recherche du meilleur reg_param et √©valuation",
    "text": "Recherche du meilleur reg_param et √©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# üîá Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# üîÑ Chargement des ensembles de donn√©es\ntrain_data = pd.read_csv('../data/covertype_train.csv')\nval_data = pd.read_csv('../data/covertype_val.csv')\ntest_data = pd.read_csv('../data/covertype_test.csv')\n\n# üìä Pr√©paration des donn√©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# üî¢ Normalisation des donn√©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# üéØ Recherche du meilleur hyperparam√®tre reg_param\nreg_params = np.linspace(0, 1, 10)\nval_accuracies = []\n\nfor reg_param in reg_params:\n    qda = QuadraticDiscriminantAnalysis(reg_param=reg_param)\n    qda.fit(X_train, y_train)\n    acc = accuracy_score(y_val, qda.predict(X_val))\n    val_accuracies.append((reg_param, acc))\n\n# S√©lection du meilleur hyperparam√®tre\nbest_reg_param, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n# üìà Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(reg_params, [acc for reg_param, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"R√©gularisation (reg_param)\")\nplt.ylabel(\"Pr√©cision sur validation\")\nplt.title(\"Impact de la r√©gularisation sur la performance de QDA\")\nplt.legend()\nplt.show()\n\n# üèÜ Mod√®le final avec le meilleur hyperparam√®tre\nfinal_model = QuadraticDiscriminantAnalysis(reg_param=best_reg_param)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# üìä Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# üìà Calcul des taux de bien class√©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# üìù Affichage des r√©sultats\nprint(f\"\\nüîπ Meilleur hyperparam√®tre reg_param sur l'√©chantillon de validation : {best_reg_param:.2f}\")\nprint(f\"Taux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : {best_val_acc:.2%}\")\nprint(\"\\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\")\nprint(conf_matrix)\n\nprint(\"\\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : {overall_test_accuracy:.2%}\")\n\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 2 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 3 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 4 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 5 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n  warnings.warn(\n/home/ensai/.local/share/virtualenvs/postagram_ensai-i0XV5lHB/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 6 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\n\nüîπ Meilleur hyperparam√®tre reg_param sur l'√©chantillon de validation : 0.89\nTaux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : 58.73%\n\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\n[[1163  626    1    1   89   14  225]\n [ 650 1561   51   27  402  125   17]\n [   0    7  948  136   50  289    0]\n [   0    0   45   53    0   12    0]\n [  28  103   27   19  191   12    0]\n [  11   34  230   53   31  335    0]\n [ 103   35    3    0   16    0  664]]\n\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\nClasse 1 : 54.88%\nClasse 2 : 55.10%\nClasse 3 : 66.29%\nClasse 4 : 48.18%\nClasse 5 : 50.26%\nClasse 6 : 48.27%\nClasse 7 : 80.88%\n\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : 58.60%"
  },
  {
    "objectID": "notebooks/index.html",
    "href": "notebooks/index.html",
    "title": "Bienvenue !",
    "section": "",
    "text": "Ce cours explore diff√©rentes m√©thodes de Machine Learning pour la classification supervis√©e, c‚Äôest-√†-dire l‚Äôaffectation d‚Äôindividus √† des cat√©gories discr√®tes (targets) en fonction de variables explicatives (features), qu‚Äôelles soient continues ou cat√©gorielles.\nL‚Äôobjectif est de comparer les performances de ces m√©thodes en √©valuant :"
  },
  {
    "objectID": "notebooks/index.html#le-dataset-utilis√©-covertype",
    "href": "notebooks/index.html#le-dataset-utilis√©-covertype",
    "title": "Bienvenue !",
    "section": "Le dataset utilis√© : Covertype",
    "text": "Le dataset utilis√© : Covertype\nNous utilisons le dataset Covertype, issu de l‚ÄôUCI Machine Learning Repository. Ce jeu de donn√©es comprend :\n- 581 012 observations\n- 54 variables explicatives\n- 7 classes diff√©rentes repr√©sentant des types de couvertures foresti√®res\nLes classes sont fortement d√©s√©quilibr√©es num√©riquement, ce qui constitue un d√©fi suppl√©mentaire pour les mod√®les de classification."
  },
  {
    "objectID": "notebooks/index.html#objectifs-du-cours",
    "href": "notebooks/index.html#objectifs-du-cours",
    "title": "Bienvenue !",
    "section": "Objectifs du cours",
    "text": "Objectifs du cours\nNous exp√©rimenterons plusieurs approches, notamment :\n- M√©thodes param√©triques : r√©gression logistique, LDA, QDA‚Ä¶\n- M√©thodes non-param√©triques : KNN, arbres de d√©cision, for√™ts al√©atoires‚Ä¶\n- Mod√®les √† base de r√©seaux de neurones\n- Strat√©gies One-Versus-All (OVA) et One-Versus-One (OVO) pour les mod√®les binaires\nCe cours vise ainsi √† comparer l‚Äôefficacit√© de ces diff√©rentes m√©thodes et √† identifier celles qui offrent les meilleurs compromis en termes de pr√©cision, robustesse et adaptation aux d√©s√©quilibres de classe."
  },
  {
    "objectID": "notebooks/bayesien_naif.html",
    "href": "notebooks/bayesien_naif.html",
    "title": "Classifieur Bay√©sien Na√Øf",
    "section": "",
    "text": "Le classificateur Bay√©sien Na√Øf repose sur le th√©or√®me de Bayes et l‚Äôhypoth√®se d‚Äôind√©pendance conditionnelle entre les variables explicatives. Il est particuli√®rement efficace pour les probl√®mes de classification textuelle et fonctionne bien m√™me avec peu de donn√©es d‚Äôentra√Ænement."
  },
  {
    "objectID": "notebooks/bayesien_naif.html#th√©orie",
    "href": "notebooks/bayesien_naif.html#th√©orie",
    "title": "Classifieur Bay√©sien Na√Øf",
    "section": "",
    "text": "Le classificateur Bay√©sien Na√Øf repose sur le th√©or√®me de Bayes et l‚Äôhypoth√®se d‚Äôind√©pendance conditionnelle entre les variables explicatives. Il est particuli√®rement efficace pour les probl√®mes de classification textuelle et fonctionne bien m√™me avec peu de donn√©es d‚Äôentra√Ænement."
  },
  {
    "objectID": "notebooks/bayesien_naif.html#hyperparam√®tre-utilis√©",
    "href": "notebooks/bayesien_naif.html#hyperparam√®tre-utilis√©",
    "title": "Classifieur Bay√©sien Na√Øf",
    "section": "Hyperparam√®tre utilis√©",
    "text": "Hyperparam√®tre utilis√©\nNous allons optimiser :\n\nvar_smoothing : Ce param√®tre permet d‚Äôajouter un lissage aux variances estim√©es pour √©viter les divisions par z√©ro. Il est s√©lectionn√© en fonction de la pr√©cision sur l‚Äôensemble de validation."
  },
  {
    "objectID": "notebooks/bayesien_naif.html#m√©triques-d√©valuation",
    "href": "notebooks/bayesien_naif.html#m√©triques-d√©valuation",
    "title": "Classifieur Bay√©sien Na√Øf",
    "section": "M√©triques d‚Äô√©valuation",
    "text": "M√©triques d‚Äô√©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur l‚Äô√©chantillon de test.\nTaux de bien class√©s sur l‚Äô√©chantillon de validation avec le meilleur hyperparam√®tre.\nTaux de bien class√©s sur l‚Äô√©chantillon de test avec ce m√™me hyperparam√®tre.\nTaux de bien class√©s par classe sur l‚Äô√©chantillon de test pour observer la pr√©cision sur chaque classe."
  },
  {
    "objectID": "notebooks/bayesien_naif.html#recherche-du-meilleur-var_smoothing-et-√©valuation",
    "href": "notebooks/bayesien_naif.html#recherche-du-meilleur-var_smoothing-et-√©valuation",
    "title": "Classifieur Bay√©sien Na√Øf",
    "section": "Recherche du meilleur var_smoothing et √©valuation",
    "text": "Recherche du meilleur var_smoothing et √©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport warnings\n\n# üîá Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# üîÑ Chargement des ensembles de donn√©es\ntrain_data = pd.read_csv('../data/covertype_train.csv')\nval_data = pd.read_csv('../data/covertype_val.csv')\ntest_data = pd.read_csv('../data/covertype_test.csv')\n\n# üìä Pr√©paration des donn√©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# üéØ Recherche du meilleur hyperparam√®tre var_smoothing\nvar_smoothing_values = np.logspace(-9, 0, 10)\nval_accuracies = []\n\nfor smoothing in var_smoothing_values:\n    gnb = GaussianNB(var_smoothing=smoothing)\n    gnb.fit(X_train, y_train)\n    acc = accuracy_score(y_val, gnb.predict(X_val))\n    val_accuracies.append((smoothing, acc))\n\n# S√©lection du meilleur hyperparam√®tre\nbest_smoothing, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# üìà Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(var_smoothing_values, [acc for smoothing, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xscale('log')\nplt.xlabel(\"Valeur de var_smoothing\")\nplt.ylabel(\"Pr√©cision sur validation\")\nplt.title(\"Optimisation du param√®tre var_smoothing pour GaussianNB\")\nplt.legend()\nplt.show()\n\n# üèÜ Mod√®le final avec le meilleur hyperparam√®tre\nfinal_model = GaussianNB(var_smoothing=best_smoothing)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# üìä Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# üìà Calcul des taux de bien class√©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# üìù Affichage des r√©sultats\nprint(f\"\\nüîπ Meilleur var_smoothing sur l'√©chantillon de validation : {best_smoothing:.1e}\")\nprint(f\"Taux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : {best_val_acc:.2%}\")\nprint(\"\\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\")\nprint(conf_matrix)\n\nprint(\"\\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nüîπ Meilleur var_smoothing sur l'√©chantillon de validation : 1.0e-07\nTaux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : 61.23%\n\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\n[[1300  475   12    0   57    9  266]\n [ 615 1732  101    1  222   89   73]\n [   0   72  939  151   72  196    0]\n [   0    0   33   66    0   11    0]\n [   2  179    4    0  176   19    0]\n [   0   66  271   34   12  311    0]\n [ 162    2    3    0    3    0  651]]\n\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre  :\nClasse 1 : 61.35%\nClasse 2 : 61.14%\nClasse 3 : 65.66%\nClasse 4 : 60.00%\nClasse 5 : 46.32%\nClasse 6 : 44.81%\nClasse 7 : 79.29%\n\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : 61.70%"
  },
  {
    "objectID": "notebooks/regression_logistique_ova.html",
    "href": "notebooks/regression_logistique_ova.html",
    "title": "R√©gression Logistique Binomiale - One-Versus-All (OVA)",
    "section": "",
    "text": "La r√©gression logistique binomiale est utilis√©e pour la classification binaire, mais elle peut √™tre adapt√©e aux probl√®mes multiclasse via l‚Äôapproche One-Versus-All (OVA). Ici, un mod√®le est entra√Æn√© pour chaque classe contre toutes les autres combin√©es."
  },
  {
    "objectID": "notebooks/regression_logistique_ova.html#th√©orie",
    "href": "notebooks/regression_logistique_ova.html#th√©orie",
    "title": "R√©gression Logistique Binomiale - One-Versus-All (OVA)",
    "section": "",
    "text": "La r√©gression logistique binomiale est utilis√©e pour la classification binaire, mais elle peut √™tre adapt√©e aux probl√®mes multiclasse via l‚Äôapproche One-Versus-All (OVA). Ici, un mod√®le est entra√Æn√© pour chaque classe contre toutes les autres combin√©es."
  },
  {
    "objectID": "notebooks/regression_logistique_ova.html#hyperparam√®tre-utilis√©",
    "href": "notebooks/regression_logistique_ova.html#hyperparam√®tre-utilis√©",
    "title": "R√©gression Logistique Binomiale - One-Versus-All (OVA)",
    "section": "Hyperparam√®tre utilis√©",
    "text": "Hyperparam√®tre utilis√©\nNous allons optimiser :\n\nParam√®tre de r√©gularisation (C) : qui contr√¥le la complexit√© du mod√®le et est s√©lectionn√© en fonction de la pr√©cision sur l‚Äôensemble de validation."
  },
  {
    "objectID": "notebooks/regression_logistique_ova.html#m√©triques-d√©valuation",
    "href": "notebooks/regression_logistique_ova.html#m√©triques-d√©valuation",
    "title": "R√©gression Logistique Binomiale - One-Versus-All (OVA)",
    "section": "M√©triques d‚Äô√©valuation",
    "text": "M√©triques d‚Äô√©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur l‚Äô√©chantillon de test.\nTaux de bien class√©s sur l‚Äô√©chantillon de validation avec le meilleur hyperparam√®tre.\nTaux de bien class√©s sur l‚Äô√©chantillon de test avec ce m√™me hyperparam√®tre.\nTaux de bien class√©s par classe sur l‚Äô√©chantillon de test pour observer la pr√©cision sur chaque classe."
  },
  {
    "objectID": "notebooks/regression_logistique_ova.html#recherche-du-meilleur-c-et-√©valuation",
    "href": "notebooks/regression_logistique_ova.html#recherche-du-meilleur-c-et-√©valuation",
    "title": "R√©gression Logistique Binomiale - One-Versus-All (OVA)",
    "section": "Recherche du meilleur C et √©valuation",
    "text": "Recherche du meilleur C et √©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# üîá Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# üîÑ Chargement des ensembles de donn√©es\ntrain_data = pd.read_csv('../data/covertype_train.csv')\nval_data = pd.read_csv('../data/covertype_val.csv')\ntest_data = pd.read_csv('../data/covertype_test.csv')\n\n# üìä Pr√©paration des donn√©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# üî¢ Normalisation des donn√©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# üéØ Recherche du meilleur hyperparam√®tre C\nC_values = np.arange(0.1, 1.1, 0.1)\nval_accuracies = []\n\nfor C in C_values:\n    model = OneVsRestClassifier(LogisticRegression(solver='saga', C=C, penalty='l2', max_iter=500))\n    model.fit(X_train, y_train)\n    acc = accuracy_score(y_val, model.predict(X_val))\n    val_accuracies.append((C, acc))\n\n# S√©lection du meilleur hyperparam√®tre\nbest_C, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# üìà Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(C_values, [acc for C, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Param√®tre de r√©gularisation (C)\")\nplt.ylabel(\"Pr√©cision sur validation\")\nplt.title(\"Impact de la r√©gularisation sur la performance de la r√©gression logistique (OVA)\")\nplt.legend()\nplt.show()\n\n# üèÜ Mod√®le final avec le meilleur hyperparam√®tre\nfinal_model = OneVsRestClassifier(LogisticRegression(solver='saga', C=best_C, penalty='l2', max_iter=500))\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# üìä Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# üìà Calcul des taux de bien class√©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# üìù Affichage des r√©sultats\nprint(f\"\\nüîπ Meilleur hyperparam√®tre C sur l'√©chantillon de validation : {best_C:.2f}\")\nprint(f\"Taux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : {best_val_acc:.2%}\")\nprint(\"\\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\")\nprint(conf_matrix)\n\nprint(\"\\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nüîπ Meilleur hyperparam√®tre C sur l'√©chantillon de validation : 0.80\nTaux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : 67.71%\n\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\n[[1337  610    1    0    5    1  165]\n [ 495 2150  107    1   21   51    8]\n [   0   65 1270   20    8   67    0]\n [   0    0   70   29    0   11    0]\n [   2  273   27    0   63   15    0]\n [   0   92  386    3   21  192    0]\n [ 143    7    3    0    0    0  668]]\n\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre  :\nClasse 1 : 63.10%\nClasse 2 : 75.89%\nClasse 3 : 88.81%\nClasse 4 : 26.36%\nClasse 5 : 16.58%\nClasse 6 : 27.67%\nClasse 7 : 81.36%\n\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : 68.07%"
  },
  {
    "objectID": "notebooks/donnees.html",
    "href": "notebooks/donnees.html",
    "title": "T√©l√©chargement et Pr√©paration du Dataset Covertype",
    "section": "",
    "text": "La base de donn√©es Covertype provient de l‚ÄôUCI Machine Learning Repository. Elle est utilis√©e pour classer les types de couvert forestier √† partir de mesures cartographiques (sol, altitude, pente, distance aux points d‚Äôeau, etc.).\n\n\n\nNombre d‚Äôobservations : 581 012\nNombre de variables : 54 (features continues et binaires)\nNombre de classes : 7 types de couverture foresti√®re (1 √† 7)\nProbl√®me √† r√©soudre : Classification supervis√©e\n\nLes classes ne sont pas √©quilibr√©es, ce qui peut influencer la performance des mod√®les de classification. Les proportions des classes dans l‚Äôensemble original sont les suivantes :\n\n\n\nClasse\nType de for√™t\nEffectif\nProportion (%)\n\n\n\n\n1\n√âpic√©a\n211 840\n36.5\n\n\n2\nPin\n283 301\n48.8\n\n\n3\nPeuplier\n35 754\n6.2\n\n\n4\nBouleau\n2 747\n0.5\n\n\n5\n√ârable\n9 493\n1.6\n\n\n6\nH√™tre\n17 367\n3.0\n\n\n7\nM√©l√®ze\n18 510\n3.2\n\n\n\n\n\n\n\n\n\nLe dataset Covertype est tr√®s grand (581 012 individus). En raison du temps de calcul important, nous avons d√©cid√© d‚Äôutiliser un √©chantillon plus petit, tout en conservant la distribution des classes.\n\n\n\nCertaines classes sont tr√®s majoritaires (ex : Pin et √âpic√©a repr√©sentent √† eux seuls 85% des donn√©es), tandis que d‚Äôautres sont tr√®s minoritaires (ex : Bouleau √† seulement 0.5%).\nNous avons appliqu√© un √©chantillonnage diff√©renci√© :\n\nSous-√©chantillonnage des classes majoritaires (√âpic√©a et Pin) ‚Üí 5% de leurs effectifs d‚Äôorigine\nSur-√©chantillonnage relatif des classes minoritaires (Peuplier, Bouleau, √ârable, H√™tre, M√©l√®ze) ‚Üí 20% de leurs effectifs d‚Äôorigine\n\nNous ne supprimons pas totalement le d√©s√©quilibre, car nous souhaitons tester nos mod√®les dans des conditions r√©alistes, o√π certaines classes restent plus rares que d‚Äôautres.\nL‚Äô√©chantillon obtenu comptera un peu plus de 40 000 individus, dont 60% seront r√©serv√©s √† l‚Äôentrainement des mod√®les, 20% √† la validation des hyperparam√®tres, et 20% aux tests.\n\n\n\n\n\n\nimport os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# üìÇ Correction du chemin d'acc√®s au fichier dataset\nfile_path = \"../data/covertype.gz\"  # On remonte d'un dossier pour atteindre data/\n\nif not os.path.exists(file_path):\n    raise FileNotFoundError(f\"‚ùå Le fichier {file_path} est introuvable. V√©rifiez son emplacement.\")\n\n# üîÑ Chargement des donn√©es\ncolumn_names = [f'Feature_{i}' for i in range(1, 55)] + ['Cover_Type']\ndata = pd.read_csv(file_path, header=None, names=column_names, compression='gzip')\n\n# üî¢ √âchantillonnage diff√©renci√©\nsampling_rates = {1: 0.05, 2: 0.05, 3: 0.2, 4: 0.2, 5: 0.2, 6: 0.2, 7: 0.2}\nsampled_data = pd.concat([\n    data[data['Cover_Type'] == cls].sample(frac=sampling_rates[cls], random_state=42)\n    for cls in data['Cover_Type'].unique()\n]).reset_index(drop=True)\n\n# üìä Division en train/val/test\ntrain_data, temp_data = train_test_split(sampled_data, test_size=0.4, random_state=42, stratify=sampled_data['Cover_Type'])\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data['Cover_Type'])\n\n# üìÇ Sauvegarde des fichiers dans data/\ntrain_data.to_csv(\"../data/covertype_train.csv\", index=False)\nval_data.to_csv(\"../data/covertype_val.csv\", index=False)\ntest_data.to_csv(\"../data/covertype_test.csv\", index=False)\n\nprint(\"‚úÖ Fichiers covertype_train.csv, covertype_val.csv et covertype_test.csv cr√©√©s avec succ√®s dans data/\")\n\n‚úÖ Fichiers covertype_train.csv, covertype_val.csv et covertype_test.csv cr√©√©s avec succ√®s dans data/"
  },
  {
    "objectID": "notebooks/donnees.html#caract√©ristiques-du-dataset",
    "href": "notebooks/donnees.html#caract√©ristiques-du-dataset",
    "title": "T√©l√©chargement et Pr√©paration du Dataset Covertype",
    "section": "",
    "text": "Nombre d‚Äôobservations : 581 012\nNombre de variables : 54 (features continues et binaires)\nNombre de classes : 7 types de couverture foresti√®re (1 √† 7)\nProbl√®me √† r√©soudre : Classification supervis√©e\n\nLes classes ne sont pas √©quilibr√©es, ce qui peut influencer la performance des mod√®les de classification. Les proportions des classes dans l‚Äôensemble original sont les suivantes :\n\n\n\nClasse\nType de for√™t\nEffectif\nProportion (%)\n\n\n\n\n1\n√âpic√©a\n211 840\n36.5\n\n\n2\nPin\n283 301\n48.8\n\n\n3\nPeuplier\n35 754\n6.2\n\n\n4\nBouleau\n2 747\n0.5\n\n\n5\n√ârable\n9 493\n1.6\n\n\n6\nH√™tre\n17 367\n3.0\n\n\n7\nM√©l√®ze\n18 510\n3.2"
  },
  {
    "objectID": "notebooks/donnees.html#objectif-de-l√©chantillonnage",
    "href": "notebooks/donnees.html#objectif-de-l√©chantillonnage",
    "title": "T√©l√©chargement et Pr√©paration du Dataset Covertype",
    "section": "",
    "text": "Le dataset Covertype est tr√®s grand (581 012 individus). En raison du temps de calcul important, nous avons d√©cid√© d‚Äôutiliser un √©chantillon plus petit, tout en conservant la distribution des classes.\n\n\n\nCertaines classes sont tr√®s majoritaires (ex : Pin et √âpic√©a repr√©sentent √† eux seuls 85% des donn√©es), tandis que d‚Äôautres sont tr√®s minoritaires (ex : Bouleau √† seulement 0.5%).\nNous avons appliqu√© un √©chantillonnage diff√©renci√© :\n\nSous-√©chantillonnage des classes majoritaires (√âpic√©a et Pin) ‚Üí 5% de leurs effectifs d‚Äôorigine\nSur-√©chantillonnage relatif des classes minoritaires (Peuplier, Bouleau, √ârable, H√™tre, M√©l√®ze) ‚Üí 20% de leurs effectifs d‚Äôorigine\n\nNous ne supprimons pas totalement le d√©s√©quilibre, car nous souhaitons tester nos mod√®les dans des conditions r√©alistes, o√π certaines classes restent plus rares que d‚Äôautres.\nL‚Äô√©chantillon obtenu comptera un peu plus de 40 000 individus, dont 60% seront r√©serv√©s √† l‚Äôentrainement des mod√®les, 20% √† la validation des hyperparam√®tres, et 20% aux tests."
  },
  {
    "objectID": "notebooks/donnees.html#t√©l√©chargement-et-pr√©paration-des-donn√©es",
    "href": "notebooks/donnees.html#t√©l√©chargement-et-pr√©paration-des-donn√©es",
    "title": "T√©l√©chargement et Pr√©paration du Dataset Covertype",
    "section": "",
    "text": "import os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# üìÇ Correction du chemin d'acc√®s au fichier dataset\nfile_path = \"../data/covertype.gz\"  # On remonte d'un dossier pour atteindre data/\n\nif not os.path.exists(file_path):\n    raise FileNotFoundError(f\"‚ùå Le fichier {file_path} est introuvable. V√©rifiez son emplacement.\")\n\n# üîÑ Chargement des donn√©es\ncolumn_names = [f'Feature_{i}' for i in range(1, 55)] + ['Cover_Type']\ndata = pd.read_csv(file_path, header=None, names=column_names, compression='gzip')\n\n# üî¢ √âchantillonnage diff√©renci√©\nsampling_rates = {1: 0.05, 2: 0.05, 3: 0.2, 4: 0.2, 5: 0.2, 6: 0.2, 7: 0.2}\nsampled_data = pd.concat([\n    data[data['Cover_Type'] == cls].sample(frac=sampling_rates[cls], random_state=42)\n    for cls in data['Cover_Type'].unique()\n]).reset_index(drop=True)\n\n# üìä Division en train/val/test\ntrain_data, temp_data = train_test_split(sampled_data, test_size=0.4, random_state=42, stratify=sampled_data['Cover_Type'])\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data['Cover_Type'])\n\n# üìÇ Sauvegarde des fichiers dans data/\ntrain_data.to_csv(\"../data/covertype_train.csv\", index=False)\nval_data.to_csv(\"../data/covertype_val.csv\", index=False)\ntest_data.to_csv(\"../data/covertype_test.csv\", index=False)\n\nprint(\"‚úÖ Fichiers covertype_train.csv, covertype_val.csv et covertype_test.csv cr√©√©s avec succ√®s dans data/\")\n\n‚úÖ Fichiers covertype_train.csv, covertype_val.csv et covertype_test.csv cr√©√©s avec succ√®s dans data/"
  },
  {
    "objectID": "notebooks/KNN.html",
    "href": "notebooks/KNN.html",
    "title": "KNN - K-Nearest Neighbors",
    "section": "",
    "text": "Le K-Nearest Neighbors (KNN) est un algorithme de classification bas√© sur la proximit√© des donn√©es dans un espace multidimensionnel. Il attribue une classe √† un point en fonction des K voisins les plus proches."
  },
  {
    "objectID": "notebooks/KNN.html#th√©orie",
    "href": "notebooks/KNN.html#th√©orie",
    "title": "KNN - K-Nearest Neighbors",
    "section": "",
    "text": "Le K-Nearest Neighbors (KNN) est un algorithme de classification bas√© sur la proximit√© des donn√©es dans un espace multidimensionnel. Il attribue une classe √† un point en fonction des K voisins les plus proches."
  },
  {
    "objectID": "notebooks/KNN.html#hyperparam√®tre-utilis√©",
    "href": "notebooks/KNN.html#hyperparam√®tre-utilis√©",
    "title": "KNN - K-Nearest Neighbors",
    "section": "Hyperparam√®tre utilis√©",
    "text": "Hyperparam√®tre utilis√©\nNous allons optimiser :\n\nNombre de voisins (k) : d√©termin√© en fonction de la pr√©cision sur l‚Äôensemble de validation."
  },
  {
    "objectID": "notebooks/KNN.html#m√©triques-d√©valuation",
    "href": "notebooks/KNN.html#m√©triques-d√©valuation",
    "title": "KNN - K-Nearest Neighbors",
    "section": "M√©triques d‚Äô√©valuation",
    "text": "M√©triques d‚Äô√©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur l‚Äô√©chantillon de test.\nTaux de bien class√©s sur l‚Äô√©chantillon de validation avec le meilleur hyperparam√®tre.\nTaux de bien class√©s sur l‚Äô√©chantillon de test avec ce m√™me hyperparam√®tre.\nTaux de bien class√©s par classe sur l‚Äô√©chantillon de test pour observer la pr√©cision sur chaque classe."
  },
  {
    "objectID": "notebooks/KNN.html#recherche-du-meilleur-k-et-√©valuation",
    "href": "notebooks/KNN.html#recherche-du-meilleur-k-et-√©valuation",
    "title": "KNN - K-Nearest Neighbors",
    "section": "Recherche du meilleur k et √©valuation",
    "text": "Recherche du meilleur k et √©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# üîá Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# üîÑ Chargement des ensembles de donn√©es\ntrain_data = pd.read_csv('../data/covertype_train.csv')\nval_data = pd.read_csv('../data/covertype_val.csv')\ntest_data = pd.read_csv('../data/covertype_test.csv')\n\n# üìä Pr√©paration des donn√©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# üî¢ Normalisation des donn√©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# üéØ Recherche du meilleur hyperparam√®tre k\nk_values = range(1, 51, 2)\nval_accuracies = []\n\nfor k in k_values:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    acc = accuracy_score(y_val, knn.predict(X_val))\n    val_accuracies.append((k, acc))\n\n# S√©lection du meilleur hyperparam√®tre\nbest_k, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# üìà Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(k_values, [acc for k, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Nombre de voisins (k)\")\nplt.ylabel(\"Pr√©cision sur validation\")\nplt.title(\"Impact du nombre de voisins sur la performance de KNN\")\nplt.legend()\nplt.show()\n\n# üèÜ Mod√®le final avec le meilleur hyperparam√®tre\nfinal_model = KNeighborsClassifier(n_neighbors=best_k)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# üìä Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# üìà Calcul des taux de bien class√©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# üìù Affichage des r√©sultats\nprint(f\"\\nüîπ Meilleur nombre de voisins (k) sur l'√©chantillon de validation : {best_k}\")\nprint(f\"Taux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : {best_val_acc:.2%}\")\nprint(\"\\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\")\nprint(conf_matrix)\n\nprint(\"\\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nüîπ Meilleur nombre de voisins (k) sur l'√©chantillon de validation : 1\nTaux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : 81.40%\n\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\n[[1663  352    1    0   14    5   84]\n [ 370 2288   37    0   80   49    9]\n [   1   29 1235   20    4  141    0]\n [   0    3   29   70    0    8    0]\n [  13   53   10    0  296    8    0]\n [   3   31  142   11    0  507    0]\n [  40   10    0    0    1    0  770]]\n\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre  :\nClasse 1 : 78.48%\nClasse 2 : 80.76%\nClasse 3 : 86.36%\nClasse 4 : 63.64%\nClasse 5 : 77.89%\nClasse 6 : 73.05%\nClasse 7 : 93.79%\n\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : 81.42%"
  },
  {
    "objectID": "notebooks/reseau_neurones.html",
    "href": "notebooks/reseau_neurones.html",
    "title": "R√©seau de Neurones (MLP) avec sortie Softmax",
    "section": "",
    "text": "Un r√©seau de neurones multi-couches (MLP - Multi-Layer Perceptron) est un mod√®le d‚Äôapprentissage supervis√© bas√© sur des couches de neurones artificiels. Il est particuli√®rement efficace pour la classification non lin√©aire.\nDans notre cas, nous utilisons une couche de sortie Softmax, qui permet de normaliser les sorties du r√©seau en probabilit√©s pour une classification multiclasses."
  },
  {
    "objectID": "notebooks/reseau_neurones.html#th√©orie",
    "href": "notebooks/reseau_neurones.html#th√©orie",
    "title": "R√©seau de Neurones (MLP) avec sortie Softmax",
    "section": "",
    "text": "Un r√©seau de neurones multi-couches (MLP - Multi-Layer Perceptron) est un mod√®le d‚Äôapprentissage supervis√© bas√© sur des couches de neurones artificiels. Il est particuli√®rement efficace pour la classification non lin√©aire.\nDans notre cas, nous utilisons une couche de sortie Softmax, qui permet de normaliser les sorties du r√©seau en probabilit√©s pour une classification multiclasses."
  },
  {
    "objectID": "notebooks/reseau_neurones.html#hyperparam√®tre-utilis√©",
    "href": "notebooks/reseau_neurones.html#hyperparam√®tre-utilis√©",
    "title": "R√©seau de Neurones (MLP) avec sortie Softmax",
    "section": "Hyperparam√®tre utilis√©",
    "text": "Hyperparam√®tre utilis√©\nNous allons optimiser :\n\nNombre d‚Äô√©poques (epochs) : s√©lectionn√© en fonction de la pr√©cision sur l‚Äôensemble de validation.\n\nNous utilisons √©galement : - Optimiseur Adam avec un taux d‚Äôapprentissage adaptatif. - Taille du batch (batch_size) fix√© √† 32."
  },
  {
    "objectID": "notebooks/reseau_neurones.html#m√©triques-d√©valuation",
    "href": "notebooks/reseau_neurones.html#m√©triques-d√©valuation",
    "title": "R√©seau de Neurones (MLP) avec sortie Softmax",
    "section": "M√©triques d‚Äô√©valuation",
    "text": "M√©triques d‚Äô√©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur l‚Äô√©chantillon de test.\nTaux de bien class√©s sur l‚Äô√©chantillon de validation avec le meilleur nombre d‚Äô√©poques.\nTaux de bien class√©s sur l‚Äô√©chantillon de test avec ce m√™me hyperparam√®tre.\nTaux de bien class√©s par classe sur l‚Äô√©chantillon de test pour observer la pr√©cision sur chaque classe."
  },
  {
    "objectID": "notebooks/reseau_neurones.html#recherche-du-meilleur-nombre-d√©poques-et-√©valuation",
    "href": "notebooks/reseau_neurones.html#recherche-du-meilleur-nombre-d√©poques-et-√©valuation",
    "title": "R√©seau de Neurones (MLP) avec sortie Softmax",
    "section": "Recherche du meilleur nombre d‚Äô√©poques et √©valuation",
    "text": "Recherche du meilleur nombre d‚Äô√©poques et √©valuation\n\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# üîá Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# üîå Utilisation du CPU uniquement (d√©sactivation GPU)\ndevice = torch.device(\"cpu\")\ntorch.backends.cudnn.enabled = False\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n\n# üîÑ Chargement des ensembles de donn√©es\ntrain_data = pd.read_csv('../data/covertype_train.csv')\nval_data = pd.read_csv('../data/covertype_val.csv')\ntest_data = pd.read_csv('../data/covertype_test.csv')\n\n# üìä Pr√©paration des donn√©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1).values, train_data['Cover_Type'].values - 1\nX_val, y_val = val_data.drop('Cover_Type', axis=1).values, val_data['Cover_Type'].values - 1\nX_test, y_test = test_data.drop('Cover_Type', axis=1).values, test_data['Cover_Type'].values - 1\n\n# üî¢ Normalisation des donn√©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# üì¶ Conversion en tenseurs PyTorch\nX_train_torch = torch.tensor(X_train, dtype=torch.float32, device=device)\ny_train_torch = torch.tensor(y_train, dtype=torch.long, device=device)\nX_val_torch = torch.tensor(X_val, dtype=torch.float32, device=device)\ny_val_torch = torch.tensor(y_val, dtype=torch.long, device=device)\nX_test_torch = torch.tensor(X_test, dtype=torch.float32, device=device)\ny_test_torch = torch.tensor(y_test, dtype=torch.long, device=device)\n\n# üìö Cr√©ation des DataLoaders\nbatch_size = 32\ntrain_loader = DataLoader(TensorDataset(X_train_torch, y_train_torch), batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(TensorDataset(X_val_torch, y_val_torch), batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(TensorDataset(X_test_torch, y_test_torch), batch_size=batch_size, shuffle=False)\n\n# üèó D√©finition du mod√®le PyTorch (MLP)\nclass MLP(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super(MLP, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 128)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(128, 64)\n        self.relu2 = nn.ReLU()\n        self.fc3 = nn.Linear(64, num_classes)\n\n    def forward(self, x):\n        x = self.relu1(self.fc1(x))\n        x = self.relu2(self.fc2(x))\n        return self.fc3(x)  # Pas de softmax ici (inclus dans CrossEntropyLoss)\n\n# üéØ Initialisation du mod√®le\nnum_features, num_classes = X_train.shape[1], len(set(y_train))\nmodel = MLP(num_features, num_classes).to(device)\n\n# üöÄ Optimiseur et fonction de perte\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters())\n\n# üìà Entra√Ænement du mod√®le avec s√©lection du meilleur nombre d'√©poques\nnum_epochs = 100\ntrain_acc_list, val_acc_list = [], []\nbest_val_acc, best_epoch = 0, 0\n\nfor epoch in range(num_epochs):\n    # üîÑ Mode entra√Ænement\n    model.train()\n    correct_train, total_train = 0, 0\n\n    for X_batch, y_batch in train_loader:\n        optimizer.zero_grad()\n        outputs = model(X_batch)\n        loss = criterion(outputs, y_batch)\n        loss.backward()\n        optimizer.step()\n\n        # üéØ Calcul de l'accuracy sur l'entra√Ænement\n        _, predicted = torch.max(outputs, 1)\n        correct_train += (predicted == y_batch).sum().item()\n        total_train += y_batch.size(0)\n\n    train_acc_list.append(correct_train / total_train)\n\n    # üîÑ Mode validation\n    model.eval()\n    correct_val, total_val = 0, 0\n\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            outputs = model(X_batch)\n            _, predicted = torch.max(outputs, 1)\n            correct_val += (predicted == y_batch).sum().item()\n            total_val += y_batch.size(0)\n\n    val_accuracy = correct_val / total_val\n    val_acc_list.append(val_accuracy)\n\n    # üéØ Sauvegarde de la meilleure √©poque\n    if val_accuracy &gt; best_val_acc:\n        best_val_acc, best_epoch = val_accuracy, epoch + 1\n\n# üìâ Affichage des courbes d'entra√Ænement\nplt.figure(figsize=(8, 6))\nplt.plot(range(1, num_epochs + 1), train_acc_list, label='Train Accuracy')\nplt.plot(range(1, num_epochs + 1), val_acc_list, label='Validation Accuracy')\nplt.axvline(best_epoch, color='r', linestyle='--', label=f'Best Epoch: {best_epoch}')\nplt.xlabel(\"√âpoques\")\nplt.ylabel(\"Taux de bonnes pr√©dictions\")\nplt.title(\"Optimisation du mod√®le de r√©seau de neurones (PyTorch)\")\nplt.legend()\nplt.show()\n\n# üîÑ R√©-entra√Æner le mod√®le avec le meilleur nombre d'√©poques\nmodel.train()\nfor epoch in range(best_epoch):\n    for X_batch, y_batch in train_loader:\n        optimizer.zero_grad()\n        outputs = model(X_batch)\n        loss = criterion(outputs, y_batch)\n        loss.backward()\n        optimizer.step()\n\n# üéØ √âvaluation sur l'ensemble de test\nmodel.eval()\ncorrect_test, total_test = 0, 0\ny_test_pred_classes = []\n\nwith torch.no_grad():\n    for X_batch, y_batch in test_loader:\n        outputs = model(X_batch)\n        _, predicted = torch.max(outputs, 1)\n        y_test_pred_classes.extend(predicted.cpu().numpy())\n        correct_test += (predicted == y_batch).sum().item()\n        total_test += y_batch.size(0)\n\ntest_accuracy = correct_test / total_test\n\n# üìå Affichage de la matrice de confusion et des m√©triques finales\nconf_matrix = confusion_matrix(y_test, y_test_pred_classes)\nprint(f\"\\nüîπ Meilleure √©poque : {best_epoch} avec une pr√©cision de validation de {best_val_acc:.2%}\")\nprint(\"\\nüìä Matrice de confusion :\")\nprint(conf_matrix)\n\nprint(\"\\nüìà Taux de bien class√©s par classe :\")\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\nprint(f\"\\nTaux de bien class√©s total : {test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nüîπ Meilleure √©poque : 96 avec une pr√©cision de validation de 84.06%\n\nüìä Matrice de confusion :\n[[1665  399    0    0   13    3   39]\n [ 239 2441   29    0   75   42    7]\n [   1   16 1302   15   13   83    0]\n [   0    0   33   71    0    6    0]\n [   2   42    6    0  328    2    0]\n [   1   22  132    4    2  533    0]\n [  55   17    0    0    0    0  749]]\n\nüìà Taux de bien class√©s par classe :\nClasse 1 : 78.57%\nClasse 2 : 86.16%\nClasse 3 : 91.05%\nClasse 4 : 64.55%\nClasse 5 : 86.32%\nClasse 6 : 76.80%\nClasse 7 : 91.23%\n\nTaux de bien class√©s total : 84.52%"
  },
  {
    "objectID": "notebooks/foret_aleatoire.html",
    "href": "notebooks/foret_aleatoire.html",
    "title": "Random Forest - For√™t Al√©atoire",
    "section": "",
    "text": "La for√™t al√©atoire est un algorithme d‚Äôapprentissage supervis√© bas√© sur un ensemble d‚Äôarbres de d√©cision. Il fonctionne en combinant plusieurs arbres pour am√©liorer la pr√©cision et r√©duire le risque de surapprentissage."
  },
  {
    "objectID": "notebooks/foret_aleatoire.html#th√©orie",
    "href": "notebooks/foret_aleatoire.html#th√©orie",
    "title": "Random Forest - For√™t Al√©atoire",
    "section": "",
    "text": "La for√™t al√©atoire est un algorithme d‚Äôapprentissage supervis√© bas√© sur un ensemble d‚Äôarbres de d√©cision. Il fonctionne en combinant plusieurs arbres pour am√©liorer la pr√©cision et r√©duire le risque de surapprentissage."
  },
  {
    "objectID": "notebooks/foret_aleatoire.html#hyperparam√®tre-utilis√©",
    "href": "notebooks/foret_aleatoire.html#hyperparam√®tre-utilis√©",
    "title": "Random Forest - For√™t Al√©atoire",
    "section": "Hyperparam√®tre utilis√©",
    "text": "Hyperparam√®tre utilis√©\nNous allons optimiser :\n\nNombre d‚Äôarbres (n_estimators) : s√©lectionn√© en fonction de la pr√©cision sur l‚Äôensemble de validation."
  },
  {
    "objectID": "notebooks/foret_aleatoire.html#m√©triques-d√©valuation",
    "href": "notebooks/foret_aleatoire.html#m√©triques-d√©valuation",
    "title": "Random Forest - For√™t Al√©atoire",
    "section": "M√©triques d‚Äô√©valuation",
    "text": "M√©triques d‚Äô√©valuation\nNous afficherons :\n\nMatrice de confusion : r√©capitulant les erreurs de classification.\nTaux de bien class√©s sur l‚Äô√©chantillon de validation avec le meilleur hyperparam√®tre.\nTaux de bien class√©s sur l‚Äô√©chantillon de test avec ce m√™me hyperparam√®tre.\nTaux de bien class√©s par classe sur l‚Äô√©chantillon de test."
  },
  {
    "objectID": "notebooks/foret_aleatoire.html#recherche-du-meilleur-n_estimators-et-√©valuation",
    "href": "notebooks/foret_aleatoire.html#recherche-du-meilleur-n_estimators-et-√©valuation",
    "title": "Random Forest - For√™t Al√©atoire",
    "section": "Recherche du meilleur n_estimators et √©valuation",
    "text": "Recherche du meilleur n_estimators et √©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport warnings\n\n# üîá Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# üîÑ Chargement des ensembles de donn√©es\ntrain_data = pd.read_csv('../data/covertype_train.csv')\nval_data = pd.read_csv('../data/covertype_val.csv')\ntest_data = pd.read_csv('../data/covertype_test.csv')\n\n# üìä Pr√©paration des donn√©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# üéØ Recherche du meilleur hyperparam√®tre n_estimators\nn_estimators_range = range(50, 1000, 50)\nval_accuracies = []\n\nfor n in n_estimators_range:\n    rf = RandomForestClassifier(n_estimators=n, random_state=42, n_jobs=-1)\n    rf.fit(X_train, y_train)\n    acc = accuracy_score(y_val, rf.predict(X_val))\n    val_accuracies.append((n, acc))\n\n# S√©lection du meilleur nombre d'arbres\nbest_n, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# üìà Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(n_estimators_range, [acc for n, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Nombre d'arbres\")\nplt.ylabel(\"Pr√©cision sur validation\")\nplt.title(\"Impact du nombre d'arbres sur la performance de Random Forest\")\nplt.legend()\nplt.show()\n\n# üèÜ Mod√®le final avec le meilleur nombre d'arbres\nfinal_model = RandomForestClassifier(n_estimators=best_n, random_state=42, n_jobs=-1)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# üìä Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# üìà Calcul des taux de bien class√©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# üìù Affichage des r√©sultats\nprint(f\"\\nüîπ Meilleur nombre d'arbres sur l‚Äô√©chantillon de validation : {best_n}\")\nprint(f\"Taux de bien class√©s sur l‚Äô√©chantillon de validation avec cet hyperparam√®tre : {best_val_acc:.2%}\")\nprint(\"\\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\")\nprint(conf_matrix)\n\nprint(\"\\nüìà Taux de bien class√©s par classe sur l‚Äô√©chantillon de test, avec le meilleur hyperparam√®tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nüîπ Taux de bien class√©s sur l‚Äô√©chantillon de test avec le meilleur hyperparam√®tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nüîπ Meilleur nombre d'arbres sur l‚Äô√©chantillon de validation : 450\nTaux de bien class√©s sur l‚Äô√©chantillon de validation avec cet hyperparam√®tre : 86.25%\n\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\n[[1753  312    0    0    5    2   47]\n [ 247 2490   40    1   20   31    4]\n [   0   15 1352   11    1   51    0]\n [   0    0   37   71    0    2    0]\n [   3   86   16    0  273    2    0]\n [   1   17  128    2    0  546    0]\n [  43    4    0    0    0    0  774]]\n\nüìà Taux de bien class√©s par classe sur l‚Äô√©chantillon de test, avec le meilleur hyperparam√®tre  :\nClasse 1 : 82.73%\nClasse 2 : 87.89%\nClasse 3 : 94.55%\nClasse 4 : 64.55%\nClasse 5 : 71.84%\nClasse 6 : 78.67%\nClasse 7 : 94.28%\n\nüîπ Taux de bien class√©s sur l‚Äô√©chantillon de test avec le meilleur hyperparam√®tre : 86.55%"
  },
  {
    "objectID": "notebooks/svm_ova.html",
    "href": "notebooks/svm_ova.html",
    "title": "Support Vector Machines (SVM) - One-Versus-All (OVA)",
    "section": "",
    "text": "Les machines √† vecteurs de support (SVM) sont des mod√®les de classification supervis√©s qui cherchent √† maximiser la marge de s√©paration entre les classes. Pour un probl√®me multiclasse, l‚Äôapproche One-Versus-All (OVA) entra√Æne un SVM pour chaque classe, la comparant √† toutes les autres classes combin√©es."
  },
  {
    "objectID": "notebooks/svm_ova.html#th√©orie",
    "href": "notebooks/svm_ova.html#th√©orie",
    "title": "Support Vector Machines (SVM) - One-Versus-All (OVA)",
    "section": "",
    "text": "Les machines √† vecteurs de support (SVM) sont des mod√®les de classification supervis√©s qui cherchent √† maximiser la marge de s√©paration entre les classes. Pour un probl√®me multiclasse, l‚Äôapproche One-Versus-All (OVA) entra√Æne un SVM pour chaque classe, la comparant √† toutes les autres classes combin√©es."
  },
  {
    "objectID": "notebooks/svm_ova.html#hyperparam√®tre-utilis√©",
    "href": "notebooks/svm_ova.html#hyperparam√®tre-utilis√©",
    "title": "Support Vector Machines (SVM) - One-Versus-All (OVA)",
    "section": "Hyperparam√®tre utilis√©",
    "text": "Hyperparam√®tre utilis√©\nNous allons optimiser :\n\nParam√®tre de r√©gularisation (C) : contr√¥le la p√©nalisation des erreurs de classification et est s√©lectionn√© en fonction de la pr√©cision sur l‚Äôensemble de validation."
  },
  {
    "objectID": "notebooks/svm_ova.html#m√©triques-d√©valuation",
    "href": "notebooks/svm_ova.html#m√©triques-d√©valuation",
    "title": "Support Vector Machines (SVM) - One-Versus-All (OVA)",
    "section": "M√©triques d‚Äô√©valuation",
    "text": "M√©triques d‚Äô√©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur l‚Äô√©chantillon de test.\nTaux de bien class√©s sur l‚Äô√©chantillon de validation avec le meilleur hyperparam√®tre.\nTaux de bien class√©s sur l‚Äô√©chantillon de test avec ce m√™me hyperparam√®tre.\nTaux de bien class√©s par classe sur l‚Äô√©chantillon de test pour observer la pr√©cision sur chaque classe."
  },
  {
    "objectID": "notebooks/svm_ova.html#recherche-du-meilleur-c-et-√©valuation",
    "href": "notebooks/svm_ova.html#recherche-du-meilleur-c-et-√©valuation",
    "title": "Support Vector Machines (SVM) - One-Versus-All (OVA)",
    "section": "Recherche du meilleur C et √©valuation",
    "text": "Recherche du meilleur C et √©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# üîá Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# üîÑ Chargement des ensembles de donn√©es\ntrain_data = pd.read_csv('../data/covertype_train.csv')\nval_data = pd.read_csv('../data/covertype_val.csv')\ntest_data = pd.read_csv('../data/covertype_test.csv')\n\n# üìä Pr√©paration des donn√©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# üî¢ Normalisation des donn√©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# üéØ Recherche du meilleur hyperparam√®tre C\nC_values = np.arange(0.1, 1.1, 0.1)\nval_accuracies = []\n\nfor C in C_values:\n    model = OneVsRestClassifier(SVC(kernel='rbf', C=C))\n    model.fit(X_train, y_train)\n    acc = accuracy_score(y_val, model.predict(X_val))\n    val_accuracies.append((C, acc))\n\n# S√©lection du meilleur hyperparam√®tre\nbest_C, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# üìà Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(C_values, [acc for C, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Param√®tre de r√©gularisation (C)\")\nplt.ylabel(\"Pr√©cision sur validation\")\nplt.title(\"Impact de la r√©gularisation sur la performance du SVM (OVA)\")\nplt.legend()\nplt.show()\n\n# üèÜ Mod√®le final avec le meilleur hyperparam√®tre\nfinal_model = OneVsRestClassifier(SVC(kernel='rbf', C=best_C))\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# üìä Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# üìà Calcul des taux de bien class√©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# üìù Affichage des r√©sultats\nprint(f\"\\nüîπ Meilleur hyperparam√®tre C sur l'√©chantillon de validation : {best_C:.2f}\")\nprint(f\"Taux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : {best_val_acc:.2%}\")\nprint(\"\\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\")\nprint(conf_matrix)\n\nprint(\"\\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nüîπ Meilleur hyperparam√®tre C sur l'√©chantillon de validation : 1.00\nTaux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : 71.88%\n\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\n[[1447  551    1    0    7    6  107]\n [ 424 2226   83    1   32   58    9]\n [   0   50 1296   18    4   62    0]\n [   0    0   81   22    0    7    0]\n [   5  202   30    0  126   17    0]\n [   0   47  378    3    0  266    0]\n [ 140    5    0    0    2    0  674]]\n\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre  :\nClasse 1 : 68.29%\nClasse 2 : 78.57%\nClasse 3 : 90.63%\nClasse 4 : 20.00%\nClasse 5 : 33.16%\nClasse 6 : 38.33%\nClasse 7 : 82.10%\n\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : 72.22%"
  },
  {
    "objectID": "notebooks/conclusions.html",
    "href": "notebooks/conclusions.html",
    "title": "Comparaison des M√©thodes de Classification",
    "section": "",
    "text": "(% de bien class√©s)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClasse (effectif)\nKNN\nLDA\nQDA\nBayesien Na√Øf\nArbre CART\nFor√™t Al√©atoire\nReg Log OVA\nReg Log OVO\nReg Multinom\nR√©seau Neurones\nSVM OVA\nSVM OVO\n\n\n\n\n1 (10592)\n78.48\n63.43\n54.88\n61.35\n74.61\n82.73\n63.10\n66.97\n66.82\n78.29\n68.29\n70.55\n\n\n2 (14165)\n80.76\n65.83\n55.10\n61.14\n76.84\n87.89\n75.89\n75.40\n75.61\n86.69\n78.57\n78.61\n\n\n3 (7151)\n86.36\n63.08\n66.29\n65.66\n85.03\n94.55\n88.81\n86.78\n87.34\n84.55\n90.63\n90.35\n\n\n4 (549)\n63.64\n48.18\n48.18\n60.00\n67.27\n64.55\n26.36\n34.55\n30.91\n70.00\n20.00\n21.82\n\n\n5 (1899)\n77.89\n47.11\n50.26\n46.32\n69.21\n71.84\n16.58\n25.79\n24.21\n83.95\n33.16\n34.47\n\n\n6 (3473)\n73.05\n52.45\n48.27\n44.81\n74.06\n78.67\n27.67\n40.06\n35.30\n86.31\n38.33\n38.62\n\n\n7 (4102)\n93.79\n80.88\n80.88\n79.29\n90.86\n94.28\n81.36\n80.39\n79.66\n92.33\n82.10\n81.49\n\n\nTotal (41931)\n81.42\n64.04\n58.60\n61.70\n78.35\n86.55\n68.07\n69.99\n69.54\n84.38\n72.22\n72.80"
  },
  {
    "objectID": "notebooks/conclusions.html#comparaison-des-performances-des-mod√®les",
    "href": "notebooks/conclusions.html#comparaison-des-performances-des-mod√®les",
    "title": "Comparaison des M√©thodes de Classification",
    "section": "",
    "text": "(% de bien class√©s)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClasse (effectif)\nKNN\nLDA\nQDA\nBayesien Na√Øf\nArbre CART\nFor√™t Al√©atoire\nReg Log OVA\nReg Log OVO\nReg Multinom\nR√©seau Neurones\nSVM OVA\nSVM OVO\n\n\n\n\n1 (10592)\n78.48\n63.43\n54.88\n61.35\n74.61\n82.73\n63.10\n66.97\n66.82\n78.29\n68.29\n70.55\n\n\n2 (14165)\n80.76\n65.83\n55.10\n61.14\n76.84\n87.89\n75.89\n75.40\n75.61\n86.69\n78.57\n78.61\n\n\n3 (7151)\n86.36\n63.08\n66.29\n65.66\n85.03\n94.55\n88.81\n86.78\n87.34\n84.55\n90.63\n90.35\n\n\n4 (549)\n63.64\n48.18\n48.18\n60.00\n67.27\n64.55\n26.36\n34.55\n30.91\n70.00\n20.00\n21.82\n\n\n5 (1899)\n77.89\n47.11\n50.26\n46.32\n69.21\n71.84\n16.58\n25.79\n24.21\n83.95\n33.16\n34.47\n\n\n6 (3473)\n73.05\n52.45\n48.27\n44.81\n74.06\n78.67\n27.67\n40.06\n35.30\n86.31\n38.33\n38.62\n\n\n7 (4102)\n93.79\n80.88\n80.88\n79.29\n90.86\n94.28\n81.36\n80.39\n79.66\n92.33\n82.10\n81.49\n\n\nTotal (41931)\n81.42\n64.04\n58.60\n61.70\n78.35\n86.55\n68.07\n69.99\n69.54\n84.38\n72.22\n72.80"
  }
]