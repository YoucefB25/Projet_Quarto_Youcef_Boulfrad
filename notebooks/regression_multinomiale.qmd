---
title: "RÃ©gression Multinomiale (Softmax Regression)"
---

## ThÃ©orie

La **rÃ©gression multinomiale**, aussi appelÃ©e **rÃ©gression logistique multinomiale**, est une extension de la rÃ©gression logistique qui permet de gÃ©rer plusieurs classes. Elle utilise une fonction **Softmax** en sortie pour assigner une probabilitÃ© Ã  chaque classe.

## HyperparamÃ¨tre utilisÃ©

Nous allons optimiser :

- **ParamÃ¨tre de rÃ©gularisation (`C`)** : contrÃ´le la pÃ©nalisation de la complexitÃ© du modÃ¨le et est sÃ©lectionnÃ© en fonction de la prÃ©cision sur l'ensemble de validation.

## MÃ©triques dâ€™Ã©valuation

Nous afficherons :

- **Matrice de confusion** : montrant les erreurs de classification sur l'Ã©chantillon de test.

- **Taux de bien classÃ©s sur l'Ã©chantillon de validation** avec le meilleur hyperparamÃ¨tre.

- **Taux de bien classÃ©s sur l'Ã©chantillon de test** avec ce mÃªme hyperparamÃ¨tre.

- **Taux de bien classÃ©s par classe sur l'Ã©chantillon de test** pour observer la prÃ©cision sur chaque classe.

## Recherche du meilleur `C` et Ã©valuation

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.preprocessing import StandardScaler
import warnings

# ğŸ”‡ Suppression des avertissements inutiles
warnings.filterwarnings("ignore", category=UserWarning)

# ğŸ”„ Chargement des ensembles de donnÃ©es
train_data = pd.read_csv('covertype_train.csv')
val_data = pd.read_csv('covertype_val.csv')
test_data = pd.read_csv('covertype_test.csv')

# ğŸ“Š PrÃ©paration des donnÃ©es
X_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']
X_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']
X_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']

# ğŸ”¢ Normalisation des donnÃ©es
scaler = StandardScaler()
X_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)

# ğŸ¯ Recherche du meilleur hyperparamÃ¨tre C
C_values = np.arange(0.1, 1.1, 0.1)
val_accuracies = []

for C in C_values:
    model = LogisticRegression(multi_class='multinomial', solver='saga', C=C, penalty='l2', max_iter=500)
    model.fit(X_train, y_train)
    acc = accuracy_score(y_val, model.predict(X_val))
    val_accuracies.append((C, acc))

# SÃ©lection du meilleur hyperparamÃ¨tre
best_C, best_val_acc = max(val_accuracies, key=lambda x: x[1])


# ğŸ“ˆ Affichage du graphique
plt.figure(figsize=(8, 6))
plt.plot(C_values, [acc for C, acc in val_accuracies], marker='o', linestyle='dashed', label="Validation")
plt.xlabel("ParamÃ¨tre de rÃ©gularisation (C)")
plt.ylabel("PrÃ©cision sur validation")
plt.title("Impact de la rÃ©gularisation sur la performance de la rÃ©gression multinomiale")
plt.legend()
plt.show()

# ğŸ† ModÃ¨le final avec le meilleur hyperparamÃ¨tre
final_model = LogisticRegression(multi_class='multinomial', solver='saga', C=best_C, penalty='l2', max_iter=500)
final_model.fit(X_train, y_train)
y_test_pred = final_model.predict(X_test)

# ğŸ“Š Matrice de confusion
conf_matrix = confusion_matrix(y_test, y_test_pred)

# ğŸ“ˆ Calcul des taux de bien classÃ©s par classe
class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)
overall_test_accuracy = accuracy_score(y_test, y_test_pred)

# ğŸ“ Affichage des rÃ©sultats
print(f"\nğŸ”¹ Meilleur hyperparamÃ¨tre C sur l'Ã©chantillon de validation : {best_C:.2f}")
print(f"Taux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : {best_val_acc:.2%}")
print("\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :")
print(conf_matrix)

print("\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :")
for i, acc in enumerate(class_accuracies, start=1):
    print(f"Classe {i} : {acc:.2%}")

print(f"\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : {overall_test_accuracy:.2%}")
```