{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"R√©gression Multinomiale (Softmax Regression)\"\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Th√©orie\n",
        "\n",
        "La **r√©gression multinomiale**, aussi appel√©e **r√©gression logistique multinomiale**, est une extension de la r√©gression logistique qui permet de g√©rer plusieurs classes. Elle utilise une fonction **Softmax** en sortie pour assigner une probabilit√© √† chaque classe.\n",
        "\n",
        "## Hyperparam√®tre utilis√©\n",
        "\n",
        "Nous allons optimiser :\n",
        "\n",
        "- **Param√®tre de r√©gularisation (`C`)** : contr√¥le la p√©nalisation de la complexit√© du mod√®le et est s√©lectionn√© en fonction de la pr√©cision sur l'ensemble de validation.\n",
        "\n",
        "## M√©triques d‚Äô√©valuation\n",
        "\n",
        "Nous afficherons :\n",
        "\n",
        "- **Matrice de confusion** : montrant les erreurs de classification sur l'√©chantillon de test.\n",
        "\n",
        "- **Taux de bien class√©s sur l'√©chantillon de validation** avec le meilleur hyperparam√®tre.\n",
        "\n",
        "- **Taux de bien class√©s sur l'√©chantillon de test** avec ce m√™me hyperparam√®tre.\n",
        "\n",
        "- **Taux de bien class√©s par classe sur l'√©chantillon de test** pour observer la pr√©cision sur chaque classe.\n",
        "\n",
        "## Recherche du meilleur `C` et √©valuation\n"
      ],
      "id": "76b5c5a3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "\n",
        "# üîá Suppression des avertissements inutiles\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# üîÑ Chargement des ensembles de donn√©es\n",
        "train_data = pd.read_csv('covertype_train.csv')\n",
        "val_data = pd.read_csv('covertype_val.csv')\n",
        "test_data = pd.read_csv('covertype_test.csv')\n",
        "\n",
        "# üìä Pr√©paration des donn√©es\n",
        "X_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\n",
        "X_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\n",
        "X_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n",
        "\n",
        "# üî¢ Normalisation des donn√©es\n",
        "scaler = StandardScaler()\n",
        "X_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n",
        "\n",
        "# üéØ Recherche du meilleur hyperparam√®tre C\n",
        "C_values = np.arange(0.1, 1.1, 0.1)\n",
        "val_accuracies = []\n",
        "\n",
        "for C in C_values:\n",
        "    model = LogisticRegression(multi_class='multinomial', solver='saga', C=C, penalty='l2', max_iter=500)\n",
        "    model.fit(X_train, y_train)\n",
        "    acc = accuracy_score(y_val, model.predict(X_val))\n",
        "    val_accuracies.append((C, acc))\n",
        "\n",
        "# S√©lection du meilleur hyperparam√®tre\n",
        "best_C, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n",
        "\n",
        "\n",
        "# üìà Affichage du graphique\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(C_values, [acc for C, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\n",
        "plt.xlabel(\"Param√®tre de r√©gularisation (C)\")\n",
        "plt.ylabel(\"Pr√©cision sur validation\")\n",
        "plt.title(\"Impact de la r√©gularisation sur la performance de la r√©gression multinomiale\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# üèÜ Mod√®le final avec le meilleur hyperparam√®tre\n",
        "final_model = LogisticRegression(multi_class='multinomial', solver='saga', C=best_C, penalty='l2', max_iter=500)\n",
        "final_model.fit(X_train, y_train)\n",
        "y_test_pred = final_model.predict(X_test)\n",
        "\n",
        "# üìä Matrice de confusion\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "# üìà Calcul des taux de bien class√©s par classe\n",
        "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "overall_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "# üìù Affichage des r√©sultats\n",
        "print(f\"\\nüîπ Meilleur hyperparam√®tre C sur l'√©chantillon de validation : {best_C:.2f}\")\n",
        "print(f\"Taux de bien class√©s sur l'√©chantillon de validation avec cet hyperparam√®tre : {best_val_acc:.2%}\")\n",
        "print(\"\\nüìä Matrice de confusion sur l'√©chantillon de test, avec le meilleur hyperparam√®tre :\")\n",
        "print(conf_matrix)\n",
        "\n",
        "print(\"\\nüìà Taux de bien class√©s par classe sur l'√©chantillon de test, avec le meilleur hyperparam√®tre  :\")\n",
        "for i, acc in enumerate(class_accuracies, start=1):\n",
        "    print(f\"Classe {i} : {acc:.2%}\")\n",
        "\n",
        "print(f\"\\nüîπ Taux de bien class√©s sur l'√©chantillon de test avec le meilleur hyperparam√®tre : {overall_test_accuracy:.2%}\")"
      ],
      "id": "60941dde",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/home/ensai/.local/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}