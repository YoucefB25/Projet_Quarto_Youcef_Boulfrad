---
title: "R√©seau de Neurones - Classification"
---

# R√©seau de Neurones (MLP) avec sortie Softmax

## Th√©orie
Un r√©seau de neurones multi-couches (**MLP - Multi-Layer Perceptron**) est un mod√®le d'apprentissage supervis√© bas√© sur des couches de neurones artificiels. Il est particuli√®rement efficace pour la classification non lin√©aire.

Dans notre cas, nous utilisons **une couche de sortie Softmax**, qui permet de normaliser les sorties du r√©seau en probabilit√©s pour une classification multiclasses.

## Hyperparam√®tres
Lors de l'entra√Ænement d'un r√©seau de neurones, plusieurs hyperparam√®tres influencent la performance :

- **Taille du pas d'apprentissage (`learning_rate`)** : D√©termin√©e automatiquement avec l'optimiseur Adam.
- **Nombre de couches cach√©es et neurones par couche** : Influence la capacit√© d'apprentissage du mod√®le.
- **Nombre d'√©poques (`epochs`)** : Nombre de fois que le mod√®le parcourt l'ensemble des donn√©es d'entra√Ænement.
- **Taille du batch (`batch_size`)** : Nombre d'exemples utilis√©s pour calculer une mise √† jour des poids.

Nous allons utiliser **Adam avec un taux d'apprentissage adaptatif**, ce qui signifie que le pas d'apprentissage s'ajustera automatiquement au fil des it√©rations.

## √âvaluation des performances
Comme pour les autres mod√®les de classification, nous utilisons :

- **Matrice de confusion** : Un tableau qui compare les classes r√©elles aux classes pr√©dites. Chaque ligne repr√©sente une classe r√©elle et chaque colonne une classe pr√©dite. Une bonne classification est indiqu√©e par des valeurs √©lev√©es sur la diagonale principale, tandis que les erreurs de classification apparaissent en dehors de cette diagonale.

- **Accuracy (Pr√©cision globale)** : Le pourcentage de pr√©dictions correctes parmi l'ensemble des donn√©es. Elle est utile lorsque les classes sont √©quilibr√©es, mais peut √™tre trompeuse si certaines classes sont largement majoritaires.

- **Precision (Pr√©cision par classe)** : Pour une classe donn√©e, la pr√©cision mesure la proportion de pr√©dictions correctes parmi toutes celles o√π le mod√®le a pr√©dit cette classe. Une haute pr√©cision signifie que lorsqu'une classe est pr√©dite, elle est souvent correcte.

- **Recall (Rappel par classe)** : Le rappel mesure la proportion de vrais exemples d'une classe qui sont correctement d√©tect√©s par le mod√®le. Une haute valeur signifie que le mod√®le d√©tecte bien les √©chantillons appartenant √† cette classe.

- **F1-score** : Moyenne harmonique entre la pr√©cision et le rappel. Il √©quilibre ces deux mesures et est particuli√®rement utile lorsque les classes sont d√©s√©quilibr√©es.

Une **moyenne macro** est utilis√©e pour donner un aper√ßu global des performances du mod√®le en attribuant un poids √©gal √† chaque classe. Une **moyenne pond√©r√©e** (weighted avg) prend en compte la fr√©quence de chaque classe afin de refl√©ter plus pr√©cis√©ment la performance globale dans un contexte de classes d√©s√©quilibr√©es.

## Exemple en Python

```{python}
import os
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# üîá D√©sactivation des logs TensorFlow et des avertissements inutiles
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"  # Supprime les logs TensorFlow
tf.get_logger().setLevel("ERROR")  # Supprime les logs internes de TensorFlow

# üîÑ Chargement des ensembles de donn√©es
train_data = pd.read_csv('covertype_train.csv')
val_data = pd.read_csv('covertype_val.csv')
test_data = pd.read_csv('covertype_test.csv')

# üìä Pr√©paration des donn√©es
X_train = train_data.drop('Cover_Type', axis=1)
y_train = train_data['Cover_Type'] - 1  # Ajustement des labels pour correspondre √† l'indexation Python

X_val = val_data.drop('Cover_Type', axis=1)
y_val = val_data['Cover_Type'] - 1

X_test = test_data.drop('Cover_Type', axis=1)
y_test = test_data['Cover_Type'] - 1

# üî¢ Normalisation des donn√©es
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# üèó D√©finition du mod√®le
model = keras.Sequential([
    keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(len(set(y_train)), activation='softmax')
])

# üöÄ Compilation du mod√®le avec Adam (sans CUDA)
optimizer = keras.optimizers.Adam()
model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# üìà Entra√Ænement du mod√®le (sans affichage de logs)
history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=32, verbose=0)

# üìä D√©termination de la meilleure √©poque
best_epoch = history.history['val_accuracy'].index(max(history.history['val_accuracy'])) + 1
best_val_acc = max(history.history['val_accuracy'])

# üìâ Affichage des courbes d'entra√Ænement
plt.figure(figsize=(8, 6))
plt.plot(range(1, 101), history.history['accuracy'], label='Train Accuracy')
plt.plot(range(1, 101), history.history['val_accuracy'], label='Validation Accuracy')
plt.axvline(best_epoch, color='r', linestyle='--', label=f'Best Epoch: {best_epoch}')
plt.xlabel("√âpoques")
plt.ylabel("Taux de bonnes pr√©dictions")
plt.title("Optimisation du mod√®le de r√©seau de neurones")
plt.legend()
plt.show()

# üîÑ R√©-entra√Æner le mod√®le avec la meilleure √©poque (sans logs)
model.fit(X_train, y_train, epochs=best_epoch, batch_size=32, verbose=0)

# üéØ √âvaluation sur l'ensemble de test (sans logs)
y_test_pred = model.predict(X_test, verbose=0)
y_test_pred_classes = y_test_pred.argmax(axis=1)

# üìå Affichage de la matrice de confusion et des m√©triques finales
conf_matrix = confusion_matrix(y_test, y_test_pred_classes)
print(f"\nüîπ Meilleure √©poque : **{best_epoch}** avec une pr√©cision de validation de **{best_val_acc:.4f}**")
print("\nüìä Matrice de confusion (les lignes = classes r√©elles, les colonnes = classes pr√©dites) :")
print(conf_matrix)

print("\nüìà √âvaluation sur l'ensemble de test")
print(classification_report(y_test, y_test_pred_classes))

```
