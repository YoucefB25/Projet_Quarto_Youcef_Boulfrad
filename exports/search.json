[
  {
    "objectID": "donnees.html",
    "href": "donnees.html",
    "title": "TÃ©lÃ©chargement et PrÃ©paration du Dataset Covertype",
    "section": "",
    "text": "La base de donnÃ©es Covertype provient de lâ€™UCI Machine Learning Repository. Elle est utilisÃ©e pour classer les types de couvert forestier Ã  partir de mesures cartographiques (sol, altitude, pente, distance aux points dâ€™eau, etc.).\n\n\n\nNombre dâ€™observations : 581 012\nNombre de variables : 54 (features continues et binaires)\nNombre de classes : 7 types de couverture forestiÃ¨re (1 Ã  7)\nProblÃ¨me Ã  rÃ©soudre : Classification supervisÃ©e\n\nLes classes ne sont pas Ã©quilibrÃ©es, ce qui peut influencer la performance des modÃ¨les de classification. Les proportions des classes dans lâ€™ensemble original sont les suivantes :\n\n\n\nClasse\nType de forÃªt\nEffectif\nProportion (%)\n\n\n\n\n1\nÃ‰picÃ©a\n211 840\n36.5\n\n\n2\nPin\n283 301\n48.8\n\n\n3\nPeuplier\n35 754\n6.2\n\n\n4\nBouleau\n2 747\n0.5\n\n\n5\nÃ‰rable\n9 493\n1.6\n\n\n6\nHÃªtre\n17 367\n3.0\n\n\n7\nMÃ©lÃ¨ze\n18 510\n3.2\n\n\n\n\n\n\n\n\n\nLe dataset Covertype est trÃ¨s grand (581 012 individus). En raison du temps de calcul important, nous avons dÃ©cidÃ© dâ€™utiliser un Ã©chantillon plus petit, tout en conservant la distribution des classes.\n\n\n\nCertaines classes sont trÃ¨s majoritaires (ex : Pin et Ã‰picÃ©a reprÃ©sentent Ã  eux seuls 85% des donnÃ©es), tandis que dâ€™autres sont trÃ¨s minoritaires (ex : Bouleau Ã  seulement 0.5%).\nNous avons appliquÃ© un Ã©chantillonnage diffÃ©renciÃ© :\n\nSous-Ã©chantillonnage des classes majoritaires (Ã‰picÃ©a et Pin) â†’ 5% de leurs effectifs dâ€™origine\nSur-Ã©chantillonnage relatif des classes minoritaires (Peuplier, Bouleau, Ã‰rable, HÃªtre, MÃ©lÃ¨ze) â†’ 20% de leurs effectifs dâ€™origine\n\nNous ne supprimons pas totalement le dÃ©sÃ©quilibre, car nous souhaitons tester nos modÃ¨les dans des conditions rÃ©alistes, oÃ¹ certaines classes restent plus rares que dâ€™autres.\nLâ€™Ã©chantillon obtenu comptera un peu plus de 40 000 individus, dont 60% seront rÃ©servÃ©s Ã  lâ€™entrainement des modÃ¨les, 20% Ã  la validation des hyperparamÃ¨tres, et 20% aux tests.\n\n\n\n\n\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# TÃ©lÃ©chargement direct des donnÃ©es depuis l'URL\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\"\ncolumn_names = [f'Feature_{i}' for i in range(1, 55)] + ['Cover_Type']\ndata = pd.read_csv(url, header=None, names=column_names)\n\n# DÃ©finition des taux d'Ã©chantillonnage (diffÃ©rent selon les classes)\nsampling_rates = {1: 0.05, 2: 0.05, 3: 0.2, 4: 0.2, 5: 0.2, 6: 0.2, 7: 0.2}\n\n# Ã‰chantillonnage diffÃ©renciÃ© par classe\nsampled_data = pd.concat([\n    data[data['Cover_Type'] == cls].sample(frac=sampling_rates[cls], random_state=42)\n    for cls in data['Cover_Type'].unique()\n])\n\n# RÃ©initialisation des index aprÃ¨s Ã©chantillonnage\nsampled_data = sampled_data.reset_index(drop=True)\n\n# Affichage des effectifs par classe aprÃ¨s Ã©chantillonnage\nprint(\"Effectifs par classe aprÃ¨s Ã©chantillonnage diffÃ©renciÃ© :\")\nprint(sampled_data['Cover_Type'].value_counts().sort_index())\n\n# Division des donnÃ©es en ensembles d'entraÃ®nement, validation et test\ntrain_data, temp_data = train_test_split(sampled_data, test_size=0.4, random_state=42, stratify=sampled_data['Cover_Type'])\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data['Cover_Type'])\n\n# Affichage des tailles des ensembles\nprint(f\"\\nTaille des ensembles :\")\nprint(f\"  - EntraÃ®nement : {len(train_data)} lignes\")\nprint(f\"  - Validation : {len(val_data)} lignes\")\nprint(f\"  - Test : {len(test_data)} lignes\")\n\n# Affichage des effectifs par classe dans chaque ensemble\nprint(\"\\nEffectifs par classe dans l'ensemble d'entraÃ®nement :\")\nprint(train_data['Cover_Type'].value_counts().sort_index())\n\nprint(\"\\nEffectifs par classe dans l'ensemble de validation :\")\nprint(val_data['Cover_Type'].value_counts().sort_index())\n\nprint(\"\\nEffectifs par classe dans l'ensemble de test :\")\nprint(test_data['Cover_Type'].value_counts().sort_index())\n\n# Sauvegarder les ensembles en fichiers CSV\ntrain_data.to_csv('covertype_train.csv', index=False)\nval_data.to_csv('covertype_val.csv', index=False)\ntest_data.to_csv('covertype_test.csv', index=False)\n\nEffectifs par classe aprÃ¨s Ã©chantillonnage diffÃ©renciÃ© :\nCover_Type\n1    10592\n2    14165\n3     7151\n4      549\n5     1899\n6     3473\n7     4102\nName: count, dtype: int64\n\nTaille des ensembles :\n  - EntraÃ®nement : 25158 lignes\n  - Validation : 8386 lignes\n  - Test : 8387 lignes\n\nEffectifs par classe dans l'ensemble d'entraÃ®nement :\nCover_Type\n1    6355\n2    8499\n3    4291\n4     329\n5    1139\n6    2084\n7    2461\nName: count, dtype: int64\n\nEffectifs par classe dans l'ensemble de validation :\nCover_Type\n1    2118\n2    2833\n3    1430\n4     110\n5     380\n6     695\n7     820\nName: count, dtype: int64\n\nEffectifs par classe dans l'ensemble de test :\nCover_Type\n1    2119\n2    2833\n3    1430\n4     110\n5     380\n6     694\n7     821\nName: count, dtype: int64"
  },
  {
    "objectID": "donnees.html#caractÃ©ristiques-du-dataset",
    "href": "donnees.html#caractÃ©ristiques-du-dataset",
    "title": "TÃ©lÃ©chargement et PrÃ©paration du Dataset Covertype",
    "section": "",
    "text": "Nombre dâ€™observations : 581 012\nNombre de variables : 54 (features continues et binaires)\nNombre de classes : 7 types de couverture forestiÃ¨re (1 Ã  7)\nProblÃ¨me Ã  rÃ©soudre : Classification supervisÃ©e\n\nLes classes ne sont pas Ã©quilibrÃ©es, ce qui peut influencer la performance des modÃ¨les de classification. Les proportions des classes dans lâ€™ensemble original sont les suivantes :\n\n\n\nClasse\nType de forÃªt\nEffectif\nProportion (%)\n\n\n\n\n1\nÃ‰picÃ©a\n211 840\n36.5\n\n\n2\nPin\n283 301\n48.8\n\n\n3\nPeuplier\n35 754\n6.2\n\n\n4\nBouleau\n2 747\n0.5\n\n\n5\nÃ‰rable\n9 493\n1.6\n\n\n6\nHÃªtre\n17 367\n3.0\n\n\n7\nMÃ©lÃ¨ze\n18 510\n3.2"
  },
  {
    "objectID": "donnees.html#objectif-de-lÃ©chantillonnage",
    "href": "donnees.html#objectif-de-lÃ©chantillonnage",
    "title": "TÃ©lÃ©chargement et PrÃ©paration du Dataset Covertype",
    "section": "",
    "text": "Le dataset Covertype est trÃ¨s grand (581 012 individus). En raison du temps de calcul important, nous avons dÃ©cidÃ© dâ€™utiliser un Ã©chantillon plus petit, tout en conservant la distribution des classes.\n\n\n\nCertaines classes sont trÃ¨s majoritaires (ex : Pin et Ã‰picÃ©a reprÃ©sentent Ã  eux seuls 85% des donnÃ©es), tandis que dâ€™autres sont trÃ¨s minoritaires (ex : Bouleau Ã  seulement 0.5%).\nNous avons appliquÃ© un Ã©chantillonnage diffÃ©renciÃ© :\n\nSous-Ã©chantillonnage des classes majoritaires (Ã‰picÃ©a et Pin) â†’ 5% de leurs effectifs dâ€™origine\nSur-Ã©chantillonnage relatif des classes minoritaires (Peuplier, Bouleau, Ã‰rable, HÃªtre, MÃ©lÃ¨ze) â†’ 20% de leurs effectifs dâ€™origine\n\nNous ne supprimons pas totalement le dÃ©sÃ©quilibre, car nous souhaitons tester nos modÃ¨les dans des conditions rÃ©alistes, oÃ¹ certaines classes restent plus rares que dâ€™autres.\nLâ€™Ã©chantillon obtenu comptera un peu plus de 40 000 individus, dont 60% seront rÃ©servÃ©s Ã  lâ€™entrainement des modÃ¨les, 20% Ã  la validation des hyperparamÃ¨tres, et 20% aux tests."
  },
  {
    "objectID": "donnees.html#tÃ©lÃ©chargement-et-prÃ©paration-des-donnÃ©es",
    "href": "donnees.html#tÃ©lÃ©chargement-et-prÃ©paration-des-donnÃ©es",
    "title": "TÃ©lÃ©chargement et PrÃ©paration du Dataset Covertype",
    "section": "",
    "text": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# TÃ©lÃ©chargement direct des donnÃ©es depuis l'URL\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\"\ncolumn_names = [f'Feature_{i}' for i in range(1, 55)] + ['Cover_Type']\ndata = pd.read_csv(url, header=None, names=column_names)\n\n# DÃ©finition des taux d'Ã©chantillonnage (diffÃ©rent selon les classes)\nsampling_rates = {1: 0.05, 2: 0.05, 3: 0.2, 4: 0.2, 5: 0.2, 6: 0.2, 7: 0.2}\n\n# Ã‰chantillonnage diffÃ©renciÃ© par classe\nsampled_data = pd.concat([\n    data[data['Cover_Type'] == cls].sample(frac=sampling_rates[cls], random_state=42)\n    for cls in data['Cover_Type'].unique()\n])\n\n# RÃ©initialisation des index aprÃ¨s Ã©chantillonnage\nsampled_data = sampled_data.reset_index(drop=True)\n\n# Affichage des effectifs par classe aprÃ¨s Ã©chantillonnage\nprint(\"Effectifs par classe aprÃ¨s Ã©chantillonnage diffÃ©renciÃ© :\")\nprint(sampled_data['Cover_Type'].value_counts().sort_index())\n\n# Division des donnÃ©es en ensembles d'entraÃ®nement, validation et test\ntrain_data, temp_data = train_test_split(sampled_data, test_size=0.4, random_state=42, stratify=sampled_data['Cover_Type'])\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data['Cover_Type'])\n\n# Affichage des tailles des ensembles\nprint(f\"\\nTaille des ensembles :\")\nprint(f\"  - EntraÃ®nement : {len(train_data)} lignes\")\nprint(f\"  - Validation : {len(val_data)} lignes\")\nprint(f\"  - Test : {len(test_data)} lignes\")\n\n# Affichage des effectifs par classe dans chaque ensemble\nprint(\"\\nEffectifs par classe dans l'ensemble d'entraÃ®nement :\")\nprint(train_data['Cover_Type'].value_counts().sort_index())\n\nprint(\"\\nEffectifs par classe dans l'ensemble de validation :\")\nprint(val_data['Cover_Type'].value_counts().sort_index())\n\nprint(\"\\nEffectifs par classe dans l'ensemble de test :\")\nprint(test_data['Cover_Type'].value_counts().sort_index())\n\n# Sauvegarder les ensembles en fichiers CSV\ntrain_data.to_csv('covertype_train.csv', index=False)\nval_data.to_csv('covertype_val.csv', index=False)\ntest_data.to_csv('covertype_test.csv', index=False)\n\nEffectifs par classe aprÃ¨s Ã©chantillonnage diffÃ©renciÃ© :\nCover_Type\n1    10592\n2    14165\n3     7151\n4      549\n5     1899\n6     3473\n7     4102\nName: count, dtype: int64\n\nTaille des ensembles :\n  - EntraÃ®nement : 25158 lignes\n  - Validation : 8386 lignes\n  - Test : 8387 lignes\n\nEffectifs par classe dans l'ensemble d'entraÃ®nement :\nCover_Type\n1    6355\n2    8499\n3    4291\n4     329\n5    1139\n6    2084\n7    2461\nName: count, dtype: int64\n\nEffectifs par classe dans l'ensemble de validation :\nCover_Type\n1    2118\n2    2833\n3    1430\n4     110\n5     380\n6     695\n7     820\nName: count, dtype: int64\n\nEffectifs par classe dans l'ensemble de test :\nCover_Type\n1    2119\n2    2833\n3    1430\n4     110\n5     380\n6     694\n7     821\nName: count, dtype: int64"
  },
  {
    "objectID": "QDA.html",
    "href": "QDA.html",
    "title": "Analyse Discriminante Quadratique (QDA) - Multiclasse",
    "section": "",
    "text": "Lâ€™Analyse Discriminante Quadratique (QDA) est une technique de classification qui, contrairement Ã  LDA, permet aux classes dâ€™avoir des matrices de covariance diffÃ©rentes. Cela le rend plus flexible mais peut aussi augmenter le risque de sur-apprentissage.\nContrairement Ã  dâ€™autres modÃ¨les initialement conÃ§us pour des problÃ¨mes binaires et adaptÃ©s aux cas multiclasse via OVA ou OVO, QDA est intrinsÃ¨quement multiclasse. Il attribue directement une observation Ã  lâ€™une des classes disponibles en estimant des distributions normales multivariÃ©es et en utilisant la rÃ¨gle de Bayes."
  },
  {
    "objectID": "QDA.html#thÃ©orie",
    "href": "QDA.html#thÃ©orie",
    "title": "Analyse Discriminante Quadratique (QDA) - Multiclasse",
    "section": "",
    "text": "Lâ€™Analyse Discriminante Quadratique (QDA) est une technique de classification qui, contrairement Ã  LDA, permet aux classes dâ€™avoir des matrices de covariance diffÃ©rentes. Cela le rend plus flexible mais peut aussi augmenter le risque de sur-apprentissage.\nContrairement Ã  dâ€™autres modÃ¨les initialement conÃ§us pour des problÃ¨mes binaires et adaptÃ©s aux cas multiclasse via OVA ou OVO, QDA est intrinsÃ¨quement multiclasse. Il attribue directement une observation Ã  lâ€™une des classes disponibles en estimant des distributions normales multivariÃ©es et en utilisant la rÃ¨gle de Bayes."
  },
  {
    "objectID": "QDA.html#hyperparamÃ¨tre-utilisÃ©",
    "href": "QDA.html#hyperparamÃ¨tre-utilisÃ©",
    "title": "Analyse Discriminante Quadratique (QDA) - Multiclasse",
    "section": "HyperparamÃ¨tre utilisÃ©",
    "text": "HyperparamÃ¨tre utilisÃ©\nNous allons optimiser :\n\nRÃ©gularisation (reg_param) : contrÃ´le la variance de la covariance estimÃ©e et est sÃ©lectionnÃ©e en fonction de la prÃ©cision sur lâ€™ensemble de validation."
  },
  {
    "objectID": "QDA.html#mÃ©triques-dÃ©valuation",
    "href": "QDA.html#mÃ©triques-dÃ©valuation",
    "title": "Analyse Discriminante Quadratique (QDA) - Multiclasse",
    "section": "MÃ©triques dâ€™Ã©valuation",
    "text": "MÃ©triques dâ€™Ã©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur lâ€™Ã©chantillon de test.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec le meilleur hyperparamÃ¨tre.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de test avec ce mÃªme hyperparamÃ¨tre.\nTaux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test pour observer la prÃ©cision sur chaque classe."
  },
  {
    "objectID": "QDA.html#recherche-du-meilleur-reg_param-et-Ã©valuation",
    "href": "QDA.html#recherche-du-meilleur-reg_param-et-Ã©valuation",
    "title": "Analyse Discriminante Quadratique (QDA) - Multiclasse",
    "section": "Recherche du meilleur reg_param et Ã©valuation",
    "text": "Recherche du meilleur reg_param et Ã©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# ğŸ”‡ Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ğŸ”„ Chargement des ensembles de donnÃ©es\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# ğŸ“Š PrÃ©paration des donnÃ©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# ğŸ”¢ Normalisation des donnÃ©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# ğŸ¯ Recherche du meilleur hyperparamÃ¨tre reg_param\nreg_params = np.linspace(0, 1, 10)\nval_accuracies = []\n\nfor reg_param in reg_params:\n    qda = QuadraticDiscriminantAnalysis(reg_param=reg_param)\n    qda.fit(X_train, y_train)\n    acc = accuracy_score(y_val, qda.predict(X_val))\n    val_accuracies.append((reg_param, acc))\n\n# SÃ©lection du meilleur hyperparamÃ¨tre\nbest_reg_param, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n# ğŸ“ˆ Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(reg_params, [acc for reg_param, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"RÃ©gularisation (reg_param)\")\nplt.ylabel(\"PrÃ©cision sur validation\")\nplt.title(\"Impact de la rÃ©gularisation sur la performance de QDA\")\nplt.legend()\nplt.show()\n\n# ğŸ† ModÃ¨le final avec le meilleur hyperparamÃ¨tre\nfinal_model = QuadraticDiscriminantAnalysis(reg_param=best_reg_param)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# ğŸ“Š Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# ğŸ“ˆ Calcul des taux de bien classÃ©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# ğŸ“ Affichage des rÃ©sultats\nprint(f\"\\nğŸ”¹ Meilleur hyperparamÃ¨tre reg_param sur l'Ã©chantillon de validation : {best_reg_param:.2f}\")\nprint(f\"Taux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : {best_val_acc:.2%}\")\nprint(\"\\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nprint(conf_matrix)\n\nprint(\"\\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nğŸ”¹ Meilleur hyperparamÃ¨tre reg_param sur l'Ã©chantillon de validation : 0.89\nTaux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : 58.73%\n\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\n[[1163  626    1    1   89   14  225]\n [ 650 1561   51   27  402  125   17]\n [   0    7  948  136   50  289    0]\n [   0    0   45   53    0   12    0]\n [  28  103   27   19  191   12    0]\n [  11   34  230   53   31  335    0]\n [ 103   35    3    0   16    0  664]]\n\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\nClasse 1 : 54.88%\nClasse 2 : 55.10%\nClasse 3 : 66.29%\nClasse 4 : 48.18%\nClasse 5 : 50.26%\nClasse 6 : 48.27%\nClasse 7 : 80.88%\n\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : 58.60%"
  },
  {
    "objectID": "svm_ovo.html",
    "href": "svm_ovo.html",
    "title": "Support Vector Machines (SVM) - One-Versus-One (OVO)",
    "section": "",
    "text": "Les machines Ã  vecteurs de support (SVM) sont des modÃ¨les de classification supervisÃ©s qui cherchent Ã  maximiser la marge de sÃ©paration entre les classes. Pour un problÃ¨me multiclasse, lâ€™approche One-Versus-One (OVO) entraÃ®ne un SVM pour chaque paire de classes, ce qui permet une meilleure sÃ©paration lorsque les classes sont bien distinctes."
  },
  {
    "objectID": "svm_ovo.html#thÃ©orie",
    "href": "svm_ovo.html#thÃ©orie",
    "title": "Support Vector Machines (SVM) - One-Versus-One (OVO)",
    "section": "",
    "text": "Les machines Ã  vecteurs de support (SVM) sont des modÃ¨les de classification supervisÃ©s qui cherchent Ã  maximiser la marge de sÃ©paration entre les classes. Pour un problÃ¨me multiclasse, lâ€™approche One-Versus-One (OVO) entraÃ®ne un SVM pour chaque paire de classes, ce qui permet une meilleure sÃ©paration lorsque les classes sont bien distinctes."
  },
  {
    "objectID": "svm_ovo.html#hyperparamÃ¨tre-utilisÃ©",
    "href": "svm_ovo.html#hyperparamÃ¨tre-utilisÃ©",
    "title": "Support Vector Machines (SVM) - One-Versus-One (OVO)",
    "section": "HyperparamÃ¨tre utilisÃ©",
    "text": "HyperparamÃ¨tre utilisÃ©\nNous allons optimiser :\n\nParamÃ¨tre de rÃ©gularisation (C) : contrÃ´le la pÃ©nalisation des erreurs de classification et est sÃ©lectionnÃ© en fonction de la prÃ©cision sur lâ€™ensemble de validation."
  },
  {
    "objectID": "svm_ovo.html#mÃ©triques-dÃ©valuation",
    "href": "svm_ovo.html#mÃ©triques-dÃ©valuation",
    "title": "Support Vector Machines (SVM) - One-Versus-One (OVO)",
    "section": "MÃ©triques dâ€™Ã©valuation",
    "text": "MÃ©triques dâ€™Ã©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur lâ€™Ã©chantillon de test.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec le meilleur hyperparamÃ¨tre.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de test avec ce mÃªme hyperparamÃ¨tre.\nTaux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test pour observer la prÃ©cision sur chaque classe."
  },
  {
    "objectID": "svm_ovo.html#recherche-du-meilleur-c-et-Ã©valuation",
    "href": "svm_ovo.html#recherche-du-meilleur-c-et-Ã©valuation",
    "title": "Support Vector Machines (SVM) - One-Versus-One (OVO)",
    "section": "Recherche du meilleur C et Ã©valuation",
    "text": "Recherche du meilleur C et Ã©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# ğŸ”‡ Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ğŸ”„ Chargement des ensembles de donnÃ©es\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# ğŸ“Š PrÃ©paration des donnÃ©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# ğŸ”¢ Normalisation des donnÃ©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# ğŸ¯ Recherche du meilleur hyperparamÃ¨tre C\nC_values = np.arange(0.1, 1.1, 0.1)\nval_accuracies = []\n\nfor C in C_values:\n    model = OneVsOneClassifier(SVC(kernel='rbf', C=C))\n    model.fit(X_train, y_train)\n    acc = accuracy_score(y_val, model.predict(X_val))\n    val_accuracies.append((C, acc))\n\n# SÃ©lection du meilleur hyperparamÃ¨tre\nbest_C, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# ğŸ“ˆ Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(C_values, [acc for C, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"ParamÃ¨tre de rÃ©gularisation (C)\")\nplt.ylabel(\"PrÃ©cision sur validation\")\nplt.title(\"Impact de la rÃ©gularisation sur la performance du SVM (OVO)\")\nplt.legend()\nplt.show()\n\n# ğŸ† ModÃ¨le final avec le meilleur hyperparamÃ¨tre\nfinal_model = OneVsOneClassifier(SVC(kernel='rbf', C=best_C))\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# ğŸ“Š Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# ğŸ“ˆ Calcul des taux de bien classÃ©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# ğŸ“ Affichage des rÃ©sultats\nprint(f\"\\nğŸ”¹ Meilleur hyperparamÃ¨tre C sur l'Ã©chantillon de validation : {best_C:.2f}\")\nprint(f\"Taux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : {best_val_acc:.2%}\")\nprint(\"\\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nprint(conf_matrix)\n\nprint(\"\\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nğŸ”¹ Meilleur hyperparamÃ¨tre C sur l'Ã©chantillon de validation : 1.00\nTaux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : 72.54%\n\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\n[[1495  519    1    0    5    5   94]\n [ 433 2227   85    1   36   47    4]\n [   0   53 1292   18    4   63    0]\n [   0    0   79   24    0    7    0]\n [   1  212   25    0  131   11    0]\n [   0   45  377    3    1  268    0]\n [ 144    8    0    0    0    0  669]]\n\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\nClasse 1 : 70.55%\nClasse 2 : 78.61%\nClasse 3 : 90.35%\nClasse 4 : 21.82%\nClasse 5 : 34.47%\nClasse 6 : 38.62%\nClasse 7 : 81.49%\n\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : 72.80%"
  },
  {
    "objectID": "arbre_decision.html",
    "href": "arbre_decision.html",
    "title": "Arbre de DÃ©cision - CART",
    "section": "",
    "text": "Lâ€™algorithme CART (Classification and Regression Trees) est un modÃ¨le dâ€™apprentissage supervisÃ© qui construit un arbre de dÃ©cision en divisant lâ€™espace des caractÃ©ristiques en sous-ensembles homogÃ¨nes."
  },
  {
    "objectID": "arbre_decision.html#thÃ©orie",
    "href": "arbre_decision.html#thÃ©orie",
    "title": "Arbre de DÃ©cision - CART",
    "section": "",
    "text": "Lâ€™algorithme CART (Classification and Regression Trees) est un modÃ¨le dâ€™apprentissage supervisÃ© qui construit un arbre de dÃ©cision en divisant lâ€™espace des caractÃ©ristiques en sous-ensembles homogÃ¨nes."
  },
  {
    "objectID": "arbre_decision.html#hyperparamÃ¨tre-utilisÃ©",
    "href": "arbre_decision.html#hyperparamÃ¨tre-utilisÃ©",
    "title": "Arbre de DÃ©cision - CART",
    "section": "HyperparamÃ¨tre utilisÃ©",
    "text": "HyperparamÃ¨tre utilisÃ©\nNous allons optimiser :\n\nProfondeur maximale de lâ€™arbre (max_depth) : sÃ©lectionnÃ©e en fonction de la prÃ©cision sur lâ€™ensemble de validation."
  },
  {
    "objectID": "arbre_decision.html#mÃ©triques-dÃ©valuation",
    "href": "arbre_decision.html#mÃ©triques-dÃ©valuation",
    "title": "Arbre de DÃ©cision - CART",
    "section": "MÃ©triques dâ€™Ã©valuation",
    "text": "MÃ©triques dâ€™Ã©valuation\nNous afficherons :\n\nMatrice de confusion : rÃ©capitulant les erreurs de classification.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec le meilleur hyperparamÃ¨tre.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de test avec ce mÃªme hyperparamÃ¨tre.\nTaux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test."
  },
  {
    "objectID": "arbre_decision.html#recherche-de-la-meilleure-max_depth-et-Ã©valuation",
    "href": "arbre_decision.html#recherche-de-la-meilleure-max_depth-et-Ã©valuation",
    "title": "Arbre de DÃ©cision - CART",
    "section": "Recherche de la meilleure max_depth et Ã©valuation",
    "text": "Recherche de la meilleure max_depth et Ã©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport warnings\n\n# ğŸ”‡ Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ğŸ”„ Chargement des ensembles de donnÃ©es\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# ğŸ“Š PrÃ©paration des donnÃ©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# ğŸ¯ Recherche du meilleur hyperparamÃ¨tre max_depth\ndepth_range = range(1, 30)\nval_accuracies = []\n\nfor depth in depth_range:\n    tree = DecisionTreeClassifier(max_depth=depth, random_state=42)\n    tree.fit(X_train, y_train)\n    acc = accuracy_score(y_val, tree.predict(X_val))\n    val_accuracies.append((depth, acc))\n\n# SÃ©lection de la meilleure profondeur d'arbre\nbest_depth, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# ğŸ“ˆ Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(depth_range, [acc for depth, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Profondeur de l'arbre\")\nplt.ylabel(\"PrÃ©cision sur validation\")\nplt.title(\"Impact de la profondeur de l'arbre sur la performance de CART\")\nplt.legend()\nplt.show()\n\n# ğŸ† ModÃ¨le final avec la meilleure profondeur\nfinal_model = DecisionTreeClassifier(max_depth=best_depth, random_state=42)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# ğŸ“Š Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# ğŸ“ˆ Calcul des taux de bien classÃ©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# ğŸ“ Affichage des rÃ©sultats\nprint(f\"\\nğŸ”¹ Meilleure profondeur de l'arbre sur lâ€™Ã©chantillon de validation : {best_depth}\")\nprint(f\"Taux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec cet hyperparamÃ¨tre : {best_val_acc:.2%}\")\nprint(\"\\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nprint(conf_matrix)\n\nprint(\"\\nğŸ“ˆ Taux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nğŸ”¹ Taux de bien classÃ©s sur lâ€™Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nğŸ”¹ Meilleure profondeur de l'arbre sur lâ€™Ã©chantillon de validation : 25\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec cet hyperparamÃ¨tre : 78.43%\n\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\n[[1581  449    1    0   11    1   76]\n [ 459 2177   43    1   93   52    8]\n [   2   46 1216   24   13  129    0]\n [   0    0   23   74    0   13    0]\n [  10   83   13    0  263   11    0]\n [   4   40  128    4    4  514    0]\n [  61   14    0    0    0    0  746]]\n\nğŸ“ˆ Taux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\nClasse 1 : 74.61%\nClasse 2 : 76.84%\nClasse 3 : 85.03%\nClasse 4 : 67.27%\nClasse 5 : 69.21%\nClasse 6 : 74.06%\nClasse 7 : 90.86%\n\nğŸ”¹ Taux de bien classÃ©s sur lâ€™Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : 78.35%"
  },
  {
    "objectID": "svm_ova.html",
    "href": "svm_ova.html",
    "title": "Support Vector Machines (SVM) - One-Versus-All (OVA)",
    "section": "",
    "text": "Les machines Ã  vecteurs de support (SVM) sont des modÃ¨les de classification supervisÃ©s qui cherchent Ã  maximiser la marge de sÃ©paration entre les classes. Pour un problÃ¨me multiclasse, lâ€™approche One-Versus-All (OVA) entraÃ®ne un SVM pour chaque classe, la comparant Ã  toutes les autres classes combinÃ©es."
  },
  {
    "objectID": "svm_ova.html#thÃ©orie",
    "href": "svm_ova.html#thÃ©orie",
    "title": "Support Vector Machines (SVM) - One-Versus-All (OVA)",
    "section": "",
    "text": "Les machines Ã  vecteurs de support (SVM) sont des modÃ¨les de classification supervisÃ©s qui cherchent Ã  maximiser la marge de sÃ©paration entre les classes. Pour un problÃ¨me multiclasse, lâ€™approche One-Versus-All (OVA) entraÃ®ne un SVM pour chaque classe, la comparant Ã  toutes les autres classes combinÃ©es."
  },
  {
    "objectID": "svm_ova.html#hyperparamÃ¨tre-utilisÃ©",
    "href": "svm_ova.html#hyperparamÃ¨tre-utilisÃ©",
    "title": "Support Vector Machines (SVM) - One-Versus-All (OVA)",
    "section": "HyperparamÃ¨tre utilisÃ©",
    "text": "HyperparamÃ¨tre utilisÃ©\nNous allons optimiser :\n\nParamÃ¨tre de rÃ©gularisation (C) : contrÃ´le la pÃ©nalisation des erreurs de classification et est sÃ©lectionnÃ© en fonction de la prÃ©cision sur lâ€™ensemble de validation."
  },
  {
    "objectID": "svm_ova.html#mÃ©triques-dÃ©valuation",
    "href": "svm_ova.html#mÃ©triques-dÃ©valuation",
    "title": "Support Vector Machines (SVM) - One-Versus-All (OVA)",
    "section": "MÃ©triques dâ€™Ã©valuation",
    "text": "MÃ©triques dâ€™Ã©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur lâ€™Ã©chantillon de test.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec le meilleur hyperparamÃ¨tre.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de test avec ce mÃªme hyperparamÃ¨tre.\nTaux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test pour observer la prÃ©cision sur chaque classe."
  },
  {
    "objectID": "svm_ova.html#recherche-du-meilleur-c-et-Ã©valuation",
    "href": "svm_ova.html#recherche-du-meilleur-c-et-Ã©valuation",
    "title": "Support Vector Machines (SVM) - One-Versus-All (OVA)",
    "section": "Recherche du meilleur C et Ã©valuation",
    "text": "Recherche du meilleur C et Ã©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# ğŸ”‡ Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ğŸ”„ Chargement des ensembles de donnÃ©es\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# ğŸ“Š PrÃ©paration des donnÃ©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# ğŸ”¢ Normalisation des donnÃ©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# ğŸ¯ Recherche du meilleur hyperparamÃ¨tre C\nC_values = np.arange(0.1, 1.1, 0.1)\nval_accuracies = []\n\nfor C in C_values:\n    model = OneVsRestClassifier(SVC(kernel='rbf', C=C))\n    model.fit(X_train, y_train)\n    acc = accuracy_score(y_val, model.predict(X_val))\n    val_accuracies.append((C, acc))\n\n# SÃ©lection du meilleur hyperparamÃ¨tre\nbest_C, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# ğŸ“ˆ Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(C_values, [acc for C, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"ParamÃ¨tre de rÃ©gularisation (C)\")\nplt.ylabel(\"PrÃ©cision sur validation\")\nplt.title(\"Impact de la rÃ©gularisation sur la performance du SVM (OVA)\")\nplt.legend()\nplt.show()\n\n# ğŸ† ModÃ¨le final avec le meilleur hyperparamÃ¨tre\nfinal_model = OneVsRestClassifier(SVC(kernel='rbf', C=best_C))\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# ğŸ“Š Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# ğŸ“ˆ Calcul des taux de bien classÃ©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# ğŸ“ Affichage des rÃ©sultats\nprint(f\"\\nğŸ”¹ Meilleur hyperparamÃ¨tre C sur l'Ã©chantillon de validation : {best_C:.2f}\")\nprint(f\"Taux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : {best_val_acc:.2%}\")\nprint(\"\\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nprint(conf_matrix)\n\nprint(\"\\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nğŸ”¹ Meilleur hyperparamÃ¨tre C sur l'Ã©chantillon de validation : 1.00\nTaux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : 71.88%\n\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\n[[1447  551    1    0    7    6  107]\n [ 424 2226   83    1   32   58    9]\n [   0   50 1296   18    4   62    0]\n [   0    0   81   22    0    7    0]\n [   5  202   30    0  126   17    0]\n [   0   47  378    3    0  266    0]\n [ 140    5    0    0    2    0  674]]\n\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\nClasse 1 : 68.29%\nClasse 2 : 78.57%\nClasse 3 : 90.63%\nClasse 4 : 20.00%\nClasse 5 : 33.16%\nClasse 6 : 38.33%\nClasse 7 : 82.10%\n\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : 72.22%"
  },
  {
    "objectID": "bayesien_naif.html",
    "href": "bayesien_naif.html",
    "title": "Classifieur BayÃ©sien NaÃ¯f",
    "section": "",
    "text": "Le classificateur BayÃ©sien NaÃ¯f repose sur le thÃ©orÃ¨me de Bayes et lâ€™hypothÃ¨se dâ€™indÃ©pendance conditionnelle entre les variables explicatives. Il est particuliÃ¨rement efficace pour les problÃ¨mes de classification textuelle et fonctionne bien mÃªme avec peu de donnÃ©es dâ€™entraÃ®nement."
  },
  {
    "objectID": "bayesien_naif.html#thÃ©orie",
    "href": "bayesien_naif.html#thÃ©orie",
    "title": "Classifieur BayÃ©sien NaÃ¯f",
    "section": "",
    "text": "Le classificateur BayÃ©sien NaÃ¯f repose sur le thÃ©orÃ¨me de Bayes et lâ€™hypothÃ¨se dâ€™indÃ©pendance conditionnelle entre les variables explicatives. Il est particuliÃ¨rement efficace pour les problÃ¨mes de classification textuelle et fonctionne bien mÃªme avec peu de donnÃ©es dâ€™entraÃ®nement."
  },
  {
    "objectID": "bayesien_naif.html#hyperparamÃ¨tre-utilisÃ©",
    "href": "bayesien_naif.html#hyperparamÃ¨tre-utilisÃ©",
    "title": "Classifieur BayÃ©sien NaÃ¯f",
    "section": "HyperparamÃ¨tre utilisÃ©",
    "text": "HyperparamÃ¨tre utilisÃ©\nNous allons optimiser :\n\nvar_smoothing : Ce paramÃ¨tre permet dâ€™ajouter un lissage aux variances estimÃ©es pour Ã©viter les divisions par zÃ©ro. Il est sÃ©lectionnÃ© en fonction de la prÃ©cision sur lâ€™ensemble de validation."
  },
  {
    "objectID": "bayesien_naif.html#mÃ©triques-dÃ©valuation",
    "href": "bayesien_naif.html#mÃ©triques-dÃ©valuation",
    "title": "Classifieur BayÃ©sien NaÃ¯f",
    "section": "MÃ©triques dâ€™Ã©valuation",
    "text": "MÃ©triques dâ€™Ã©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur lâ€™Ã©chantillon de test.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec le meilleur hyperparamÃ¨tre.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de test avec ce mÃªme hyperparamÃ¨tre.\nTaux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test pour observer la prÃ©cision sur chaque classe."
  },
  {
    "objectID": "bayesien_naif.html#recherche-du-meilleur-var_smoothing-et-Ã©valuation",
    "href": "bayesien_naif.html#recherche-du-meilleur-var_smoothing-et-Ã©valuation",
    "title": "Classifieur BayÃ©sien NaÃ¯f",
    "section": "Recherche du meilleur var_smoothing et Ã©valuation",
    "text": "Recherche du meilleur var_smoothing et Ã©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport warnings\n\n# ğŸ”‡ Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ğŸ”„ Chargement des ensembles de donnÃ©es\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# ğŸ“Š PrÃ©paration des donnÃ©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# ğŸ¯ Recherche du meilleur hyperparamÃ¨tre var_smoothing\nvar_smoothing_values = np.logspace(-9, 0, 10)\nval_accuracies = []\n\nfor smoothing in var_smoothing_values:\n    gnb = GaussianNB(var_smoothing=smoothing)\n    gnb.fit(X_train, y_train)\n    acc = accuracy_score(y_val, gnb.predict(X_val))\n    val_accuracies.append((smoothing, acc))\n\n# SÃ©lection du meilleur hyperparamÃ¨tre\nbest_smoothing, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# ğŸ“ˆ Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(var_smoothing_values, [acc for smoothing, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xscale('log')\nplt.xlabel(\"Valeur de var_smoothing\")\nplt.ylabel(\"PrÃ©cision sur validation\")\nplt.title(\"Optimisation du paramÃ¨tre var_smoothing pour GaussianNB\")\nplt.legend()\nplt.show()\n\n# ğŸ† ModÃ¨le final avec le meilleur hyperparamÃ¨tre\nfinal_model = GaussianNB(var_smoothing=best_smoothing)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# ğŸ“Š Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# ğŸ“ˆ Calcul des taux de bien classÃ©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# ğŸ“ Affichage des rÃ©sultats\nprint(f\"\\nğŸ”¹ Meilleur var_smoothing sur l'Ã©chantillon de validation : {best_smoothing:.1e}\")\nprint(f\"Taux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : {best_val_acc:.2%}\")\nprint(\"\\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nprint(conf_matrix)\n\nprint(\"\\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nğŸ”¹ Meilleur var_smoothing sur l'Ã©chantillon de validation : 1.0e-07\nTaux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : 61.23%\n\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\n[[1300  475   12    0   57    9  266]\n [ 615 1732  101    1  222   89   73]\n [   0   72  939  151   72  196    0]\n [   0    0   33   66    0   11    0]\n [   2  179    4    0  176   19    0]\n [   0   66  271   34   12  311    0]\n [ 162    2    3    0    3    0  651]]\n\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\nClasse 1 : 61.35%\nClasse 2 : 61.14%\nClasse 3 : 65.66%\nClasse 4 : 60.00%\nClasse 5 : 46.32%\nClasse 6 : 44.81%\nClasse 7 : 79.29%\n\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : 61.70%"
  },
  {
    "objectID": "LDA.html",
    "href": "LDA.html",
    "title": "Analyse Discriminante LinÃ©aire (LDA) - Multiclasse",
    "section": "",
    "text": "Lâ€™Analyse Discriminante LinÃ©aire (LDA) est une technique de classification qui cherche Ã  trouver une combinaison linÃ©aire de caractÃ©ristiques maximisant la sÃ©paration entre plusieurs classes.\nContrairement Ã  dâ€™autres modÃ¨les initialement conÃ§us pour des problÃ¨mes binaires et adaptÃ©s aux cas multiclasse via OVA ou OVO, LDA est intrinsÃ¨quement multiclasse. Il attribue directement une observation Ã  lâ€™une des classes disponibles en estimant des distributions normales multivariÃ©es et en utilisant la rÃ¨gle de Bayes."
  },
  {
    "objectID": "LDA.html#thÃ©orie",
    "href": "LDA.html#thÃ©orie",
    "title": "Analyse Discriminante LinÃ©aire (LDA) - Multiclasse",
    "section": "",
    "text": "Lâ€™Analyse Discriminante LinÃ©aire (LDA) est une technique de classification qui cherche Ã  trouver une combinaison linÃ©aire de caractÃ©ristiques maximisant la sÃ©paration entre plusieurs classes.\nContrairement Ã  dâ€™autres modÃ¨les initialement conÃ§us pour des problÃ¨mes binaires et adaptÃ©s aux cas multiclasse via OVA ou OVO, LDA est intrinsÃ¨quement multiclasse. Il attribue directement une observation Ã  lâ€™une des classes disponibles en estimant des distributions normales multivariÃ©es et en utilisant la rÃ¨gle de Bayes."
  },
  {
    "objectID": "LDA.html#hyperparamÃ¨tre-utilisÃ©",
    "href": "LDA.html#hyperparamÃ¨tre-utilisÃ©",
    "title": "Analyse Discriminante LinÃ©aire (LDA) - Multiclasse",
    "section": "HyperparamÃ¨tre utilisÃ©",
    "text": "HyperparamÃ¨tre utilisÃ©\nNous allons optimiser :\n\nRÃ©gularisation (shrinkage) : contrÃ´le la variance de la covariance estimÃ©e et est sÃ©lectionnÃ©e en fonction de la prÃ©cision sur lâ€™ensemble de validation."
  },
  {
    "objectID": "LDA.html#mÃ©triques-dÃ©valuation",
    "href": "LDA.html#mÃ©triques-dÃ©valuation",
    "title": "Analyse Discriminante LinÃ©aire (LDA) - Multiclasse",
    "section": "MÃ©triques dâ€™Ã©valuation",
    "text": "MÃ©triques dâ€™Ã©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur lâ€™Ã©chantillon de test.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec le meilleur hyperparamÃ¨tre.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de test avec ce mÃªme hyperparamÃ¨tre.\nTaux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test pour observer la prÃ©cision sur chaque classe."
  },
  {
    "objectID": "LDA.html#recherche-du-meilleur-shrinkage-et-Ã©valuation",
    "href": "LDA.html#recherche-du-meilleur-shrinkage-et-Ã©valuation",
    "title": "Analyse Discriminante LinÃ©aire (LDA) - Multiclasse",
    "section": "Recherche du meilleur shrinkage et Ã©valuation",
    "text": "Recherche du meilleur shrinkage et Ã©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# ğŸ”‡ Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ğŸ”„ Chargement des ensembles de donnÃ©es\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# ğŸ“Š PrÃ©paration des donnÃ©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# ğŸ”¢ Normalisation des donnÃ©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# ğŸ¯ Recherche du meilleur hyperparamÃ¨tre shrinkage\nshrinkage_values = np.linspace(0, 1, 10)\nval_accuracies = []\n\nfor shrinkage in shrinkage_values:\n    lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage=shrinkage)\n    lda.fit(X_train, y_train)\n    acc = accuracy_score(y_val, lda.predict(X_val))\n    val_accuracies.append((shrinkage, acc))\n\n# SÃ©lection du meilleur hyperparamÃ¨tre\nbest_shrinkage, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n# ğŸ“ˆ Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(shrinkage_values, [acc for shrinkage, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Shrinkage\")\nplt.ylabel(\"PrÃ©cision sur validation\")\nplt.title(\"Impact du shrinkage sur la performance de LDA\")\nplt.legend()\nplt.show()\n\n# ğŸ† ModÃ¨le final avec le meilleur hyperparamÃ¨tre\nfinal_model = LinearDiscriminantAnalysis(solver='lsqr', shrinkage=best_shrinkage)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# ğŸ“Š Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# ğŸ“ˆ Calcul des taux de bien classÃ©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# ğŸ“ Affichage des rÃ©sultats\nprint(f\"\\nğŸ”¹ Meilleur hyperparamÃ¨tre shrinkage sur l'Ã©chantillon de validation : {best_shrinkage:.2f}\")\nprint(f\"Taux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : {best_val_acc:.2%}\")\nprint(\"\\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nprint(conf_matrix)\n\nprint(\"\\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nğŸ”¹ Meilleur hyperparamÃ¨tre shrinkage sur l'Ã©chantillon de validation : 0.00\nTaux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : 63.37%\n\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\n[[1344  520    1    0   27    2  225]\n [ 548 1865   48   17  218  124   13]\n [   0   29  902  130   32  337    0]\n [   0    0   44   53    0   13    0]\n [   2  160   27    0  179   12    0]\n [   0   53  210   25   42  364    0]\n [ 154    0    3    0    0    0  664]]\n\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\nClasse 1 : 63.43%\nClasse 2 : 65.83%\nClasse 3 : 63.08%\nClasse 4 : 48.18%\nClasse 5 : 47.11%\nClasse 6 : 52.45%\nClasse 7 : 80.88%\n\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : 64.04%"
  },
  {
    "objectID": "foret_aleatoire.html",
    "href": "foret_aleatoire.html",
    "title": "Random Forest - ForÃªt AlÃ©atoire",
    "section": "",
    "text": "La forÃªt alÃ©atoire est un algorithme dâ€™apprentissage supervisÃ© basÃ© sur un ensemble dâ€™arbres de dÃ©cision. Il fonctionne en combinant plusieurs arbres pour amÃ©liorer la prÃ©cision et rÃ©duire le risque de surapprentissage."
  },
  {
    "objectID": "foret_aleatoire.html#thÃ©orie",
    "href": "foret_aleatoire.html#thÃ©orie",
    "title": "Random Forest - ForÃªt AlÃ©atoire",
    "section": "",
    "text": "La forÃªt alÃ©atoire est un algorithme dâ€™apprentissage supervisÃ© basÃ© sur un ensemble dâ€™arbres de dÃ©cision. Il fonctionne en combinant plusieurs arbres pour amÃ©liorer la prÃ©cision et rÃ©duire le risque de surapprentissage."
  },
  {
    "objectID": "foret_aleatoire.html#hyperparamÃ¨tre-utilisÃ©",
    "href": "foret_aleatoire.html#hyperparamÃ¨tre-utilisÃ©",
    "title": "Random Forest - ForÃªt AlÃ©atoire",
    "section": "HyperparamÃ¨tre utilisÃ©",
    "text": "HyperparamÃ¨tre utilisÃ©\nNous allons optimiser :\n\nNombre dâ€™arbres (n_estimators) : sÃ©lectionnÃ© en fonction de la prÃ©cision sur lâ€™ensemble de validation."
  },
  {
    "objectID": "foret_aleatoire.html#mÃ©triques-dÃ©valuation",
    "href": "foret_aleatoire.html#mÃ©triques-dÃ©valuation",
    "title": "Random Forest - ForÃªt AlÃ©atoire",
    "section": "MÃ©triques dâ€™Ã©valuation",
    "text": "MÃ©triques dâ€™Ã©valuation\nNous afficherons :\n\nMatrice de confusion : rÃ©capitulant les erreurs de classification.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec le meilleur hyperparamÃ¨tre.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de test avec ce mÃªme hyperparamÃ¨tre.\nTaux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test."
  },
  {
    "objectID": "foret_aleatoire.html#recherche-du-meilleur-n_estimators-et-Ã©valuation",
    "href": "foret_aleatoire.html#recherche-du-meilleur-n_estimators-et-Ã©valuation",
    "title": "Random Forest - ForÃªt AlÃ©atoire",
    "section": "Recherche du meilleur n_estimators et Ã©valuation",
    "text": "Recherche du meilleur n_estimators et Ã©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport warnings\n\n# ğŸ”‡ Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ğŸ”„ Chargement des ensembles de donnÃ©es\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# ğŸ“Š PrÃ©paration des donnÃ©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# ğŸ¯ Recherche du meilleur hyperparamÃ¨tre n_estimators\nn_estimators_range = range(50, 1000, 50)\nval_accuracies = []\n\nfor n in n_estimators_range:\n    rf = RandomForestClassifier(n_estimators=n, random_state=42, n_jobs=-1)\n    rf.fit(X_train, y_train)\n    acc = accuracy_score(y_val, rf.predict(X_val))\n    val_accuracies.append((n, acc))\n\n# SÃ©lection du meilleur nombre d'arbres\nbest_n, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# ğŸ“ˆ Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(n_estimators_range, [acc for n, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Nombre d'arbres\")\nplt.ylabel(\"PrÃ©cision sur validation\")\nplt.title(\"Impact du nombre d'arbres sur la performance de Random Forest\")\nplt.legend()\nplt.show()\n\n# ğŸ† ModÃ¨le final avec le meilleur nombre d'arbres\nfinal_model = RandomForestClassifier(n_estimators=best_n, random_state=42, n_jobs=-1)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# ğŸ“Š Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# ğŸ“ˆ Calcul des taux de bien classÃ©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# ğŸ“ Affichage des rÃ©sultats\nprint(f\"\\nğŸ”¹ Meilleur nombre d'arbres sur lâ€™Ã©chantillon de validation : {best_n}\")\nprint(f\"Taux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec cet hyperparamÃ¨tre : {best_val_acc:.2%}\")\nprint(\"\\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nprint(conf_matrix)\n\nprint(\"\\nğŸ“ˆ Taux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nğŸ”¹ Taux de bien classÃ©s sur lâ€™Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nğŸ”¹ Meilleur nombre d'arbres sur lâ€™Ã©chantillon de validation : 450\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec cet hyperparamÃ¨tre : 86.25%\n\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\n[[1753  312    0    0    5    2   47]\n [ 247 2490   40    1   20   31    4]\n [   0   15 1352   11    1   51    0]\n [   0    0   37   71    0    2    0]\n [   3   86   16    0  273    2    0]\n [   1   17  128    2    0  546    0]\n [  43    4    0    0    0    0  774]]\n\nğŸ“ˆ Taux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\nClasse 1 : 82.73%\nClasse 2 : 87.89%\nClasse 3 : 94.55%\nClasse 4 : 64.55%\nClasse 5 : 71.84%\nClasse 6 : 78.67%\nClasse 7 : 94.28%\n\nğŸ”¹ Taux de bien classÃ©s sur lâ€™Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : 86.55%"
  },
  {
    "objectID": "presentation.html",
    "href": "presentation.html",
    "title": "PrÃ©sentation des techniques de classification supervisÃ©e utilisÃ©es",
    "section": "",
    "text": "En classification supervisÃ©e, les algorithmes peuvent Ãªtre divisÃ©s en mÃ©thodes paramÃ©triques et mÃ©thodes non-paramÃ©triques. Cette distinction repose sur la maniÃ¨re dont les modÃ¨les apprennent et gÃ©nÃ©ralisent les donnÃ©es.\n\n\nLes modÃ¨les paramÃ©triques supposent lâ€™existence dâ€™une distribution sous-jacente aux donnÃ©es et estiment ses paramÃ¨tres Ã  partir des donnÃ©es dâ€™entrainement.\n\n\n\nRÃ©gression Logistique (OVA et OVO)\nRÃ©gression Multinomiale (Softmax Regression)\nAnalyse Discriminante LinÃ©aire (LDA)\nAnalyse Discriminante Quadratique (QDA)\nClassifieur BayÃ©sien NaÃ¯f\n\n\n\n\n\nLes modÃ¨les non-paramÃ©triques ne supposent pas lâ€™existence dâ€™une distribution sous-jacente aux donnÃ©es. Ils estiment les limites entre les classes de faÃ§on â€œgloutonneâ€ en maximisant les diffÃ©rences inter-classes et minisant les diffÃ©rences intra-classes sur les donnÃ©es dâ€™entrainement.\n\n\n\nArbre de DÃ©cision (CART)\nForÃªt AlÃ©atoire (Random Forest)\nK-Nearest Neighbors (KNN)\nMachines Ã  Vecteurs de Support (SVM - OVA et OVO)\nRÃ©seau de Neurones (MLP avec sortie Softmax)"
  },
  {
    "objectID": "presentation.html#classification-paramÃ©trique-vs-non-paramÃ©trique",
    "href": "presentation.html#classification-paramÃ©trique-vs-non-paramÃ©trique",
    "title": "PrÃ©sentation des techniques de classification supervisÃ©e utilisÃ©es",
    "section": "",
    "text": "En classification supervisÃ©e, les algorithmes peuvent Ãªtre divisÃ©s en mÃ©thodes paramÃ©triques et mÃ©thodes non-paramÃ©triques. Cette distinction repose sur la maniÃ¨re dont les modÃ¨les apprennent et gÃ©nÃ©ralisent les donnÃ©es.\n\n\nLes modÃ¨les paramÃ©triques supposent lâ€™existence dâ€™une distribution sous-jacente aux donnÃ©es et estiment ses paramÃ¨tres Ã  partir des donnÃ©es dâ€™entrainement.\n\n\n\nRÃ©gression Logistique (OVA et OVO)\nRÃ©gression Multinomiale (Softmax Regression)\nAnalyse Discriminante LinÃ©aire (LDA)\nAnalyse Discriminante Quadratique (QDA)\nClassifieur BayÃ©sien NaÃ¯f\n\n\n\n\n\nLes modÃ¨les non-paramÃ©triques ne supposent pas lâ€™existence dâ€™une distribution sous-jacente aux donnÃ©es. Ils estiment les limites entre les classes de faÃ§on â€œgloutonneâ€ en maximisant les diffÃ©rences inter-classes et minisant les diffÃ©rences intra-classes sur les donnÃ©es dâ€™entrainement.\n\n\n\nArbre de DÃ©cision (CART)\nForÃªt AlÃ©atoire (Random Forest)\nK-Nearest Neighbors (KNN)\nMachines Ã  Vecteurs de Support (SVM - OVA et OVO)\nRÃ©seau de Neurones (MLP avec sortie Softmax)"
  },
  {
    "objectID": "presentation.html#classifieurs-multiclasses-natifs-vs-classifieurs-binaires-adaptÃ©s",
    "href": "presentation.html#classifieurs-multiclasses-natifs-vs-classifieurs-binaires-adaptÃ©s",
    "title": "PrÃ©sentation des techniques de classification supervisÃ©e utilisÃ©es",
    "section": "Classifieurs Multiclasses Natifs vs Classifieurs Binaires AdaptÃ©s",
    "text": "Classifieurs Multiclasses Natifs vs Classifieurs Binaires AdaptÃ©s\nCertains classifieurs sont conÃ§us pour gÃ©rer directement plusieurs classes (classifieurs multiclasses natifs), tandis que dâ€™autres sont conÃ§us pour distinguer uniquement deux classes et doivent Ãªtre adaptÃ©s pour des problÃ¨mes multiclasses.\n\n1. Classifieurs Multiclasses Natifs\nCes classifieurs peuvent traiter directement un problÃ¨me Ã  plusieurs classes sans nÃ©cessiter de transformation :\n\nRÃ©gression Multinomiale (Softmax Regression)\nAnalyse Discriminante LinÃ©aire (LDA)\nAnalyse Discriminante Quadratique (QDA)\nClassifieur BayÃ©sien NaÃ¯f\nArbre de DÃ©cision (CART)\nForÃªt AlÃ©atoire (Random Forest)\nRÃ©seau de Neurones (MLP avec sortie Softmax)\nK-Nearest Neighbors (KNN)\n\n\n\n2. Classifieurs Binaires AdaptÃ©s\nLes classifieurs binaires doivent Ãªtre transformÃ©s pour gÃ©rer plusieurs classes en utilisant des approches comme One-Versus-All (OVA) ou One-Versus-One (OVO) :\n\nRÃ©gression Logistique (adaptÃ©e en OVA et OVO)\nSupport Vector Machines (SVM) (adaptÃ©es en OVA et OVO)"
  },
  {
    "objectID": "presentation.html#one-versus-all-ova-vs-one-versus-one-ovo",
    "href": "presentation.html#one-versus-all-ova-vs-one-versus-one-ovo",
    "title": "PrÃ©sentation des techniques de classification supervisÃ©e utilisÃ©es",
    "section": "One-Versus-All (OVA) vs One-Versus-One (OVO)",
    "text": "One-Versus-All (OVA) vs One-Versus-One (OVO)\nLes approches OVA et OVO permettent dâ€™adapter des classifieurs binaires aux problÃ¨mes multiclasses.\n\n1. One-Versus-All (OVA)\nAvec cette approche, un modÃ¨le binaire est entraÃ®nÃ© pour chaque classe en la comparant Ã  toutes les autres classes regroupÃ©es. Pour une classification Ã  N classes, N modÃ¨les binaires sont entraÃ®nÃ©s.\nAvantages : - Moins de modÃ¨les Ã  entraÃ®ner (N contre N(N-1)/2 en OVO), soit 7 modÃ¨les pour 7 classes. - Plus efficace pour les jeux de donnÃ©es avec un grand nombre de classes.\nInconvÃ©nients : - Les classes dÃ©sÃ©quilibrÃ©es peuvent poser problÃ¨me car le modÃ¨le doit distinguer une classe contre un ensemble de classes plus nombreuses. - Peut gÃ©nÃ©rer des scores de confiance biaisÃ©s si les classes sont trÃ¨s dÃ©sÃ©quilibrÃ©es.\nExemples de classifieurs utilisant OVA :\n\nRÃ©gression Logistique (OVA)\nSVM (OVA)\n\n\n\n2. One-Versus-One (OVO)\nAvec lâ€™approche OVO, un modÃ¨le est entraÃ®nÃ© pour chaque paire de classes. Pour une classification Ã  N classes, N(N-1)/2 modÃ¨les binaires sont entraÃ®nÃ©s, soit 21 modÃ¨les pour 7 classes.\nAvantages : - Meilleure sÃ©paration entre classes si elles sont bien distinctes. - Moins sensible aux classes dÃ©sÃ©quilibrÃ©es car chaque modÃ¨le compare seulement deux classes Ã  la fois.\nInconvÃ©nients : - Temps dâ€™entraÃ®nement plus long Ã  cause du grand nombre de modÃ¨les. - Peut nÃ©cessiter plus de ressources pour lâ€™infÃ©rence.\nExemples de classifieurs utilisant OVO :\n\nRÃ©gression Logistique (OVO)\nSVM (OVO)"
  },
  {
    "objectID": "regression_logistique_ovo.html",
    "href": "regression_logistique_ovo.html",
    "title": "RÃ©gression Logistique Binomiale - One-Versus-One (OVO)",
    "section": "",
    "text": "La rÃ©gression logistique binomiale est utilisÃ©e pour la classification binaire, mais elle peut Ãªtre adaptÃ©e aux problÃ¨mes multiclasse via lâ€™approche One-Versus-One (OVO). Ici, un modÃ¨le est entraÃ®nÃ© pour chaque paire de classes, ce qui peut amÃ©liorer la prÃ©cision lorsque les classes sont bien sÃ©parÃ©es."
  },
  {
    "objectID": "regression_logistique_ovo.html#thÃ©orie",
    "href": "regression_logistique_ovo.html#thÃ©orie",
    "title": "RÃ©gression Logistique Binomiale - One-Versus-One (OVO)",
    "section": "",
    "text": "La rÃ©gression logistique binomiale est utilisÃ©e pour la classification binaire, mais elle peut Ãªtre adaptÃ©e aux problÃ¨mes multiclasse via lâ€™approche One-Versus-One (OVO). Ici, un modÃ¨le est entraÃ®nÃ© pour chaque paire de classes, ce qui peut amÃ©liorer la prÃ©cision lorsque les classes sont bien sÃ©parÃ©es."
  },
  {
    "objectID": "regression_logistique_ovo.html#hyperparamÃ¨tre-utilisÃ©",
    "href": "regression_logistique_ovo.html#hyperparamÃ¨tre-utilisÃ©",
    "title": "RÃ©gression Logistique Binomiale - One-Versus-One (OVO)",
    "section": "HyperparamÃ¨tre utilisÃ©",
    "text": "HyperparamÃ¨tre utilisÃ©\nNous allons optimiser :\n\nParamÃ¨tre de rÃ©gularisation (C) : qui contrÃ´le la complexitÃ© du modÃ¨le et est sÃ©lectionnÃ© en fonction de la prÃ©cision sur lâ€™ensemble de validation."
  },
  {
    "objectID": "regression_logistique_ovo.html#mÃ©triques-dÃ©valuation",
    "href": "regression_logistique_ovo.html#mÃ©triques-dÃ©valuation",
    "title": "RÃ©gression Logistique Binomiale - One-Versus-One (OVO)",
    "section": "MÃ©triques dâ€™Ã©valuation",
    "text": "MÃ©triques dâ€™Ã©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur lâ€™Ã©chantillon de test.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec le meilleur hyperparamÃ¨tre.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de test avec ce mÃªme hyperparamÃ¨tre.\nTaux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test pour observer la prÃ©cision sur chaque classe."
  },
  {
    "objectID": "regression_logistique_ovo.html#recherche-du-meilleur-c-et-Ã©valuation",
    "href": "regression_logistique_ovo.html#recherche-du-meilleur-c-et-Ã©valuation",
    "title": "RÃ©gression Logistique Binomiale - One-Versus-One (OVO)",
    "section": "Recherche du meilleur C et Ã©valuation",
    "text": "Recherche du meilleur C et Ã©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# ğŸ”‡ Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ğŸ”„ Chargement des ensembles de donnÃ©es\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# ğŸ“Š PrÃ©paration des donnÃ©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# ğŸ”¢ Normalisation des donnÃ©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# ğŸ¯ Recherche du meilleur hyperparamÃ¨tre C\nC_values = np.arange(0.1, 1.1, 0.1)\nval_accuracies = []\n\nfor C in C_values:\n    model = OneVsOneClassifier(LogisticRegression(solver='saga', C=C, penalty='l2', max_iter=500))\n    model.fit(X_train, y_train)\n    acc = accuracy_score(y_val, model.predict(X_val))\n    val_accuracies.append((C, acc))\n\n# SÃ©lection du meilleur hyperparamÃ¨tre\nbest_C, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# ğŸ“ˆ Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(C_values, [acc for C, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"ParamÃ¨tre de rÃ©gularisation (C)\")\nplt.ylabel(\"PrÃ©cision sur validation\")\nplt.title(\"Impact de la rÃ©gularisation sur la performance de la rÃ©gression logistique (OVO)\")\nplt.legend()\nplt.show()\n\n# ğŸ† ModÃ¨le final avec le meilleur hyperparamÃ¨tre\nfinal_model = OneVsOneClassifier(LogisticRegression(solver='saga', C=best_C, penalty='l2', max_iter=500))\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# ğŸ“Š Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# ğŸ“ˆ Calcul des taux de bien classÃ©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# ğŸ“ Affichage des rÃ©sultats\nprint(f\"\\nğŸ”¹ Meilleur hyperparamÃ¨tre C sur l'Ã©chantillon de validation : {best_C:.2f}\")\nprint(f\"Taux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : {best_val_acc:.2%}\")\nprint(\"\\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nprint(conf_matrix)\n\nprint(\"\\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nğŸ”¹ Meilleur hyperparamÃ¨tre C sur l'Ã©chantillon de validation : 0.30\nTaux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : 69.53%\n\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\n[[1419  584    1    0    6    1  108]\n [ 517 2136   85    1   36   50    8]\n [   0   44 1241   35    4  106    0]\n [   0    0   56   38    0   16    0]\n [   2  254   21    0   98    5    0]\n [   0   53  359    2    2  278    0]\n [ 158    1    2    0    0    0  660]]\n\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\nClasse 1 : 66.97%\nClasse 2 : 75.40%\nClasse 3 : 86.78%\nClasse 4 : 34.55%\nClasse 5 : 25.79%\nClasse 6 : 40.06%\nClasse 7 : 80.39%\n\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : 69.99%"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bienvenue !",
    "section": "",
    "text": "Ce cours explore diffÃ©rentes mÃ©thodes de Machine Learning pour la classification supervisÃ©e, câ€™est-Ã -dire lâ€™affectation dâ€™individus Ã  des catÃ©gories discrÃ¨tes (targets) en fonction de variables explicatives (features), quâ€™elles soient continues ou catÃ©gorielles.\nLâ€™objectif est de comparer les performances de ces mÃ©thodes en Ã©valuant :"
  },
  {
    "objectID": "index.html#le-dataset-utilisÃ©-covertype",
    "href": "index.html#le-dataset-utilisÃ©-covertype",
    "title": "Bienvenue !",
    "section": "Le dataset utilisÃ© : Covertype",
    "text": "Le dataset utilisÃ© : Covertype\nNous utilisons le dataset Covertype, issu de lâ€™UCI Machine Learning Repository. Ce jeu de donnÃ©es comprend :\n- 581 012 observations\n- 54 variables explicatives\n- 7 classes diffÃ©rentes reprÃ©sentant des types de couvertures forestiÃ¨res\nLes classes sont fortement dÃ©sÃ©quilibrÃ©es numÃ©riquement, ce qui constitue un dÃ©fi supplÃ©mentaire pour les modÃ¨les de classification."
  },
  {
    "objectID": "index.html#objectifs-du-cours",
    "href": "index.html#objectifs-du-cours",
    "title": "Bienvenue !",
    "section": "Objectifs du cours",
    "text": "Objectifs du cours\nNous expÃ©rimenterons plusieurs approches, notamment :\n- MÃ©thodes paramÃ©triques : rÃ©gression logistique, LDA, QDAâ€¦\n- MÃ©thodes non-paramÃ©triques : KNN, arbres de dÃ©cision, forÃªts alÃ©atoiresâ€¦\n- ModÃ¨les Ã  base de rÃ©seaux de neurones\n- StratÃ©gies One-Versus-All (OVA) et One-Versus-One (OVO) pour les modÃ¨les binaires\nCe cours vise ainsi Ã  comparer lâ€™efficacitÃ© de ces diffÃ©rentes mÃ©thodes et Ã  identifier celles qui offrent les meilleurs compromis en termes de prÃ©cision, robustesse et adaptation aux dÃ©sÃ©quilibres de classe."
  },
  {
    "objectID": "KNN.html",
    "href": "KNN.html",
    "title": "KNN - K-Nearest Neighbors",
    "section": "",
    "text": "Le K-Nearest Neighbors (KNN) est un algorithme de classification basÃ© sur la proximitÃ© des donnÃ©es dans un espace multidimensionnel. Il attribue une classe Ã  un point en fonction des K voisins les plus proches."
  },
  {
    "objectID": "KNN.html#thÃ©orie",
    "href": "KNN.html#thÃ©orie",
    "title": "KNN - K-Nearest Neighbors",
    "section": "",
    "text": "Le K-Nearest Neighbors (KNN) est un algorithme de classification basÃ© sur la proximitÃ© des donnÃ©es dans un espace multidimensionnel. Il attribue une classe Ã  un point en fonction des K voisins les plus proches."
  },
  {
    "objectID": "KNN.html#hyperparamÃ¨tre-utilisÃ©",
    "href": "KNN.html#hyperparamÃ¨tre-utilisÃ©",
    "title": "KNN - K-Nearest Neighbors",
    "section": "HyperparamÃ¨tre utilisÃ©",
    "text": "HyperparamÃ¨tre utilisÃ©\nNous allons optimiser :\n\nNombre de voisins (k) : dÃ©terminÃ© en fonction de la prÃ©cision sur lâ€™ensemble de validation."
  },
  {
    "objectID": "KNN.html#mÃ©triques-dÃ©valuation",
    "href": "KNN.html#mÃ©triques-dÃ©valuation",
    "title": "KNN - K-Nearest Neighbors",
    "section": "MÃ©triques dâ€™Ã©valuation",
    "text": "MÃ©triques dâ€™Ã©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur lâ€™Ã©chantillon de test.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec le meilleur hyperparamÃ¨tre.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de test avec ce mÃªme hyperparamÃ¨tre.\nTaux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test pour observer la prÃ©cision sur chaque classe."
  },
  {
    "objectID": "KNN.html#recherche-du-meilleur-k-et-Ã©valuation",
    "href": "KNN.html#recherche-du-meilleur-k-et-Ã©valuation",
    "title": "KNN - K-Nearest Neighbors",
    "section": "Recherche du meilleur k et Ã©valuation",
    "text": "Recherche du meilleur k et Ã©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# ğŸ”‡ Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ğŸ”„ Chargement des ensembles de donnÃ©es\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# ğŸ“Š PrÃ©paration des donnÃ©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# ğŸ”¢ Normalisation des donnÃ©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# ğŸ¯ Recherche du meilleur hyperparamÃ¨tre k\nk_values = range(1, 51, 2)\nval_accuracies = []\n\nfor k in k_values:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    acc = accuracy_score(y_val, knn.predict(X_val))\n    val_accuracies.append((k, acc))\n\n# SÃ©lection du meilleur hyperparamÃ¨tre\nbest_k, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# ğŸ“ˆ Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(k_values, [acc for k, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Nombre de voisins (k)\")\nplt.ylabel(\"PrÃ©cision sur validation\")\nplt.title(\"Impact du nombre de voisins sur la performance de KNN\")\nplt.legend()\nplt.show()\n\n# ğŸ† ModÃ¨le final avec le meilleur hyperparamÃ¨tre\nfinal_model = KNeighborsClassifier(n_neighbors=best_k)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# ğŸ“Š Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# ğŸ“ˆ Calcul des taux de bien classÃ©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# ğŸ“ Affichage des rÃ©sultats\nprint(f\"\\nğŸ”¹ Meilleur nombre de voisins (k) sur l'Ã©chantillon de validation : {best_k}\")\nprint(f\"Taux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : {best_val_acc:.2%}\")\nprint(\"\\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nprint(conf_matrix)\n\nprint(\"\\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nğŸ”¹ Meilleur nombre de voisins (k) sur l'Ã©chantillon de validation : 1\nTaux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : 81.40%\n\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\n[[1663  352    1    0   14    5   84]\n [ 370 2288   37    0   80   49    9]\n [   1   29 1235   20    4  141    0]\n [   0    3   29   70    0    8    0]\n [  13   53   10    0  296    8    0]\n [   3   31  142   11    0  507    0]\n [  40   10    0    0    1    0  770]]\n\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\nClasse 1 : 78.48%\nClasse 2 : 80.76%\nClasse 3 : 86.36%\nClasse 4 : 63.64%\nClasse 5 : 77.89%\nClasse 6 : 73.05%\nClasse 7 : 93.79%\n\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : 81.42%"
  },
  {
    "objectID": "regression_multinomiale.html",
    "href": "regression_multinomiale.html",
    "title": "RÃ©gression Multinomiale (Softmax Regression)",
    "section": "",
    "text": "La rÃ©gression multinomiale, aussi appelÃ©e rÃ©gression logistique multinomiale, est une extension de la rÃ©gression logistique qui permet de gÃ©rer plusieurs classes. Elle utilise une fonction Softmax en sortie pour assigner une probabilitÃ© Ã  chaque classe."
  },
  {
    "objectID": "regression_multinomiale.html#thÃ©orie",
    "href": "regression_multinomiale.html#thÃ©orie",
    "title": "RÃ©gression Multinomiale (Softmax Regression)",
    "section": "",
    "text": "La rÃ©gression multinomiale, aussi appelÃ©e rÃ©gression logistique multinomiale, est une extension de la rÃ©gression logistique qui permet de gÃ©rer plusieurs classes. Elle utilise une fonction Softmax en sortie pour assigner une probabilitÃ© Ã  chaque classe."
  },
  {
    "objectID": "regression_multinomiale.html#hyperparamÃ¨tre-utilisÃ©",
    "href": "regression_multinomiale.html#hyperparamÃ¨tre-utilisÃ©",
    "title": "RÃ©gression Multinomiale (Softmax Regression)",
    "section": "HyperparamÃ¨tre utilisÃ©",
    "text": "HyperparamÃ¨tre utilisÃ©\nNous allons optimiser :\n\nParamÃ¨tre de rÃ©gularisation (C) : contrÃ´le la pÃ©nalisation de la complexitÃ© du modÃ¨le et est sÃ©lectionnÃ© en fonction de la prÃ©cision sur lâ€™ensemble de validation."
  },
  {
    "objectID": "regression_multinomiale.html#mÃ©triques-dÃ©valuation",
    "href": "regression_multinomiale.html#mÃ©triques-dÃ©valuation",
    "title": "RÃ©gression Multinomiale (Softmax Regression)",
    "section": "MÃ©triques dâ€™Ã©valuation",
    "text": "MÃ©triques dâ€™Ã©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur lâ€™Ã©chantillon de test.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec le meilleur hyperparamÃ¨tre.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de test avec ce mÃªme hyperparamÃ¨tre.\nTaux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test pour observer la prÃ©cision sur chaque classe."
  },
  {
    "objectID": "regression_multinomiale.html#recherche-du-meilleur-c-et-Ã©valuation",
    "href": "regression_multinomiale.html#recherche-du-meilleur-c-et-Ã©valuation",
    "title": "RÃ©gression Multinomiale (Softmax Regression)",
    "section": "Recherche du meilleur C et Ã©valuation",
    "text": "Recherche du meilleur C et Ã©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# ğŸ”‡ Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ğŸ”„ Chargement des ensembles de donnÃ©es\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# ğŸ“Š PrÃ©paration des donnÃ©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# ğŸ”¢ Normalisation des donnÃ©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# ğŸ¯ Recherche du meilleur hyperparamÃ¨tre C\nC_values = np.arange(0.1, 1.1, 0.1)\nval_accuracies = []\n\nfor C in C_values:\n    model = LogisticRegression(multi_class='multinomial', solver='saga', C=C, penalty='l2', max_iter=500)\n    model.fit(X_train, y_train)\n    acc = accuracy_score(y_val, model.predict(X_val))\n    val_accuracies.append((C, acc))\n\n# SÃ©lection du meilleur hyperparamÃ¨tre\nbest_C, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# ğŸ“ˆ Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(C_values, [acc for C, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"ParamÃ¨tre de rÃ©gularisation (C)\")\nplt.ylabel(\"PrÃ©cision sur validation\")\nplt.title(\"Impact de la rÃ©gularisation sur la performance de la rÃ©gression multinomiale\")\nplt.legend()\nplt.show()\n\n# ğŸ† ModÃ¨le final avec le meilleur hyperparamÃ¨tre\nfinal_model = LogisticRegression(multi_class='multinomial', solver='saga', C=best_C, penalty='l2', max_iter=500)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# ğŸ“Š Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# ğŸ“ˆ Calcul des taux de bien classÃ©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# ğŸ“ Affichage des rÃ©sultats\nprint(f\"\\nğŸ”¹ Meilleur hyperparamÃ¨tre C sur l'Ã©chantillon de validation : {best_C:.2f}\")\nprint(f\"Taux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : {best_val_acc:.2%}\")\nprint(\"\\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nprint(conf_matrix)\n\nprint(\"\\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : {overall_test_accuracy:.2%}\")\n\n/home/ensai/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n/home/ensai/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\n/home/ensai/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n\n\n\nğŸ”¹ Meilleur hyperparamÃ¨tre C sur l'Ã©chantillon de validation : 0.10\nTaux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : 69.14%\n\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\n[[1416  583    1    0    6    1  112]\n [ 511 2142   87    1   40   44    8]\n [   0   48 1249   38    8   87    0]\n [   0    0   61   34    0   15    0]\n [   2  257   24    0   92    5    0]\n [   0   64  374    3    8  245    0]\n [ 163    1    3    0    0    0  654]]\n\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\nClasse 1 : 66.82%\nClasse 2 : 75.61%\nClasse 3 : 87.34%\nClasse 4 : 30.91%\nClasse 5 : 24.21%\nClasse 6 : 35.30%\nClasse 7 : 79.66%\n\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : 69.54%"
  },
  {
    "objectID": "reseau_neurones.html",
    "href": "reseau_neurones.html",
    "title": "RÃ©seau de Neurones (MLP) avec sortie Softmax",
    "section": "",
    "text": "Un rÃ©seau de neurones multi-couches (MLP - Multi-Layer Perceptron) est un modÃ¨le dâ€™apprentissage supervisÃ© basÃ© sur des couches de neurones artificiels. Il est particuliÃ¨rement efficace pour la classification non linÃ©aire.\nDans notre cas, nous utilisons une couche de sortie Softmax, qui permet de normaliser les sorties du rÃ©seau en probabilitÃ©s pour une classification multiclasses."
  },
  {
    "objectID": "reseau_neurones.html#thÃ©orie",
    "href": "reseau_neurones.html#thÃ©orie",
    "title": "RÃ©seau de Neurones (MLP) avec sortie Softmax",
    "section": "",
    "text": "Un rÃ©seau de neurones multi-couches (MLP - Multi-Layer Perceptron) est un modÃ¨le dâ€™apprentissage supervisÃ© basÃ© sur des couches de neurones artificiels. Il est particuliÃ¨rement efficace pour la classification non linÃ©aire.\nDans notre cas, nous utilisons une couche de sortie Softmax, qui permet de normaliser les sorties du rÃ©seau en probabilitÃ©s pour une classification multiclasses."
  },
  {
    "objectID": "reseau_neurones.html#hyperparamÃ¨tre-utilisÃ©",
    "href": "reseau_neurones.html#hyperparamÃ¨tre-utilisÃ©",
    "title": "RÃ©seau de Neurones (MLP) avec sortie Softmax",
    "section": "HyperparamÃ¨tre utilisÃ©",
    "text": "HyperparamÃ¨tre utilisÃ©\nNous allons optimiser :\n\nNombre dâ€™Ã©poques (epochs) : sÃ©lectionnÃ© en fonction de la prÃ©cision sur lâ€™ensemble de validation.\n\nNous utilisons Ã©galement : - Optimiseur Adam avec un taux dâ€™apprentissage adaptatif. - Taille du batch (batch_size) fixÃ© Ã  32."
  },
  {
    "objectID": "reseau_neurones.html#mÃ©triques-dÃ©valuation",
    "href": "reseau_neurones.html#mÃ©triques-dÃ©valuation",
    "title": "RÃ©seau de Neurones (MLP) avec sortie Softmax",
    "section": "MÃ©triques dâ€™Ã©valuation",
    "text": "MÃ©triques dâ€™Ã©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur lâ€™Ã©chantillon de test.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec le meilleur nombre dâ€™Ã©poques.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de test avec ce mÃªme hyperparamÃ¨tre.\nTaux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test pour observer la prÃ©cision sur chaque classe."
  },
  {
    "objectID": "reseau_neurones.html#recherche-du-meilleur-nombre-dÃ©poques-et-Ã©valuation",
    "href": "reseau_neurones.html#recherche-du-meilleur-nombre-dÃ©poques-et-Ã©valuation",
    "title": "RÃ©seau de Neurones (MLP) avec sortie Softmax",
    "section": "Recherche du meilleur nombre dâ€™Ã©poques et Ã©valuation",
    "text": "Recherche du meilleur nombre dâ€™Ã©poques et Ã©valuation\n\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# ğŸ”‡ Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ğŸ”Œ Utilisation du CPU uniquement (dÃ©sactivation GPU)\ndevice = torch.device(\"cpu\")\ntorch.backends.cudnn.enabled = False\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n\n# ğŸ”„ Chargement des ensembles de donnÃ©es\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# ğŸ“Š PrÃ©paration des donnÃ©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1).values, train_data['Cover_Type'].values - 1\nX_val, y_val = val_data.drop('Cover_Type', axis=1).values, val_data['Cover_Type'].values - 1\nX_test, y_test = test_data.drop('Cover_Type', axis=1).values, test_data['Cover_Type'].values - 1\n\n# ğŸ”¢ Normalisation des donnÃ©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# ğŸ“¦ Conversion en tenseurs PyTorch\nX_train_torch = torch.tensor(X_train, dtype=torch.float32, device=device)\ny_train_torch = torch.tensor(y_train, dtype=torch.long, device=device)\nX_val_torch = torch.tensor(X_val, dtype=torch.float32, device=device)\ny_val_torch = torch.tensor(y_val, dtype=torch.long, device=device)\nX_test_torch = torch.tensor(X_test, dtype=torch.float32, device=device)\ny_test_torch = torch.tensor(y_test, dtype=torch.long, device=device)\n\n# ğŸ“š CrÃ©ation des DataLoaders\nbatch_size = 32\ntrain_loader = DataLoader(TensorDataset(X_train_torch, y_train_torch), batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(TensorDataset(X_val_torch, y_val_torch), batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(TensorDataset(X_test_torch, y_test_torch), batch_size=batch_size, shuffle=False)\n\n# ğŸ— DÃ©finition du modÃ¨le PyTorch (MLP)\nclass MLP(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super(MLP, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 128)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(128, 64)\n        self.relu2 = nn.ReLU()\n        self.fc3 = nn.Linear(64, num_classes)\n\n    def forward(self, x):\n        x = self.relu1(self.fc1(x))\n        x = self.relu2(self.fc2(x))\n        return self.fc3(x)  # Pas de softmax ici (inclus dans CrossEntropyLoss)\n\n# ğŸ¯ Initialisation du modÃ¨le\nnum_features, num_classes = X_train.shape[1], len(set(y_train))\nmodel = MLP(num_features, num_classes).to(device)\n\n# ğŸš€ Optimiseur et fonction de perte\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters())\n\n# ğŸ“ˆ EntraÃ®nement du modÃ¨le avec sÃ©lection du meilleur nombre d'Ã©poques\nnum_epochs = 100\ntrain_acc_list, val_acc_list = [], []\nbest_val_acc, best_epoch = 0, 0\n\nfor epoch in range(num_epochs):\n    # ğŸ”„ Mode entraÃ®nement\n    model.train()\n    correct_train, total_train = 0, 0\n\n    for X_batch, y_batch in train_loader:\n        optimizer.zero_grad()\n        outputs = model(X_batch)\n        loss = criterion(outputs, y_batch)\n        loss.backward()\n        optimizer.step()\n\n        # ğŸ¯ Calcul de l'accuracy sur l'entraÃ®nement\n        _, predicted = torch.max(outputs, 1)\n        correct_train += (predicted == y_batch).sum().item()\n        total_train += y_batch.size(0)\n\n    train_acc_list.append(correct_train / total_train)\n\n    # ğŸ”„ Mode validation\n    model.eval()\n    correct_val, total_val = 0, 0\n\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            outputs = model(X_batch)\n            _, predicted = torch.max(outputs, 1)\n            correct_val += (predicted == y_batch).sum().item()\n            total_val += y_batch.size(0)\n\n    val_accuracy = correct_val / total_val\n    val_acc_list.append(val_accuracy)\n\n    # ğŸ¯ Sauvegarde de la meilleure Ã©poque\n    if val_accuracy &gt; best_val_acc:\n        best_val_acc, best_epoch = val_accuracy, epoch + 1\n\n# ğŸ“‰ Affichage des courbes d'entraÃ®nement\nplt.figure(figsize=(8, 6))\nplt.plot(range(1, num_epochs + 1), train_acc_list, label='Train Accuracy')\nplt.plot(range(1, num_epochs + 1), val_acc_list, label='Validation Accuracy')\nplt.axvline(best_epoch, color='r', linestyle='--', label=f'Best Epoch: {best_epoch}')\nplt.xlabel(\"Ã‰poques\")\nplt.ylabel(\"Taux de bonnes prÃ©dictions\")\nplt.title(\"Optimisation du modÃ¨le de rÃ©seau de neurones (PyTorch)\")\nplt.legend()\nplt.show()\n\n# ğŸ”„ RÃ©-entraÃ®ner le modÃ¨le avec le meilleur nombre d'Ã©poques\nmodel.train()\nfor epoch in range(best_epoch):\n    for X_batch, y_batch in train_loader:\n        optimizer.zero_grad()\n        outputs = model(X_batch)\n        loss = criterion(outputs, y_batch)\n        loss.backward()\n        optimizer.step()\n\n# ğŸ¯ Ã‰valuation sur l'ensemble de test\nmodel.eval()\ncorrect_test, total_test = 0, 0\ny_test_pred_classes = []\n\nwith torch.no_grad():\n    for X_batch, y_batch in test_loader:\n        outputs = model(X_batch)\n        _, predicted = torch.max(outputs, 1)\n        y_test_pred_classes.extend(predicted.cpu().numpy())\n        correct_test += (predicted == y_batch).sum().item()\n        total_test += y_batch.size(0)\n\ntest_accuracy = correct_test / total_test\n\n# ğŸ“Œ Affichage de la matrice de confusion et des mÃ©triques finales\nconf_matrix = confusion_matrix(y_test, y_test_pred_classes)\nprint(f\"\\nğŸ”¹ Meilleure Ã©poque : {best_epoch} avec une prÃ©cision de validation de {best_val_acc:.2%}\")\nprint(\"\\nğŸ“Š Matrice de confusion :\")\nprint(conf_matrix)\n\nprint(\"\\nğŸ“ˆ Taux de bien classÃ©s par classe :\")\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\nprint(f\"\\nTaux de bien classÃ©s total : {test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nğŸ”¹ Meilleure Ã©poque : 99 avec une prÃ©cision de validation de 84.40%\n\nğŸ“Š Matrice de confusion :\n[[1804  247    0    0    6    1   61]\n [ 429 2296   20    1   42   35   10]\n [   0   30 1265   15    6  114    0]\n [   0    0   31   71    0    8    0]\n [   4   76    4    0  292    4    0]\n [   2   16   90    6    0  580    0]\n [  28    5    0    0    0    0  788]]\n\nğŸ“ˆ Taux de bien classÃ©s par classe :\nClasse 1 : 85.13%\nClasse 2 : 81.04%\nClasse 3 : 88.46%\nClasse 4 : 64.55%\nClasse 5 : 76.84%\nClasse 6 : 83.57%\nClasse 7 : 95.98%\n\nTaux de bien classÃ©s total : 84.61%"
  },
  {
    "objectID": "regression_logistique_ova.html",
    "href": "regression_logistique_ova.html",
    "title": "RÃ©gression Logistique Binomiale - One-Versus-All (OVA)",
    "section": "",
    "text": "La rÃ©gression logistique binomiale est utilisÃ©e pour la classification binaire, mais elle peut Ãªtre adaptÃ©e aux problÃ¨mes multiclasse via lâ€™approche One-Versus-All (OVA). Ici, un modÃ¨le est entraÃ®nÃ© pour chaque classe contre toutes les autres combinÃ©es."
  },
  {
    "objectID": "regression_logistique_ova.html#thÃ©orie",
    "href": "regression_logistique_ova.html#thÃ©orie",
    "title": "RÃ©gression Logistique Binomiale - One-Versus-All (OVA)",
    "section": "",
    "text": "La rÃ©gression logistique binomiale est utilisÃ©e pour la classification binaire, mais elle peut Ãªtre adaptÃ©e aux problÃ¨mes multiclasse via lâ€™approche One-Versus-All (OVA). Ici, un modÃ¨le est entraÃ®nÃ© pour chaque classe contre toutes les autres combinÃ©es."
  },
  {
    "objectID": "regression_logistique_ova.html#hyperparamÃ¨tre-utilisÃ©",
    "href": "regression_logistique_ova.html#hyperparamÃ¨tre-utilisÃ©",
    "title": "RÃ©gression Logistique Binomiale - One-Versus-All (OVA)",
    "section": "HyperparamÃ¨tre utilisÃ©",
    "text": "HyperparamÃ¨tre utilisÃ©\nNous allons optimiser :\n\nParamÃ¨tre de rÃ©gularisation (C) : qui contrÃ´le la complexitÃ© du modÃ¨le et est sÃ©lectionnÃ© en fonction de la prÃ©cision sur lâ€™ensemble de validation."
  },
  {
    "objectID": "regression_logistique_ova.html#mÃ©triques-dÃ©valuation",
    "href": "regression_logistique_ova.html#mÃ©triques-dÃ©valuation",
    "title": "RÃ©gression Logistique Binomiale - One-Versus-All (OVA)",
    "section": "MÃ©triques dâ€™Ã©valuation",
    "text": "MÃ©triques dâ€™Ã©valuation\nNous afficherons :\n\nMatrice de confusion : montrant les erreurs de classification sur lâ€™Ã©chantillon de test.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec le meilleur hyperparamÃ¨tre.\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de test avec ce mÃªme hyperparamÃ¨tre.\nTaux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test pour observer la prÃ©cision sur chaque classe."
  },
  {
    "objectID": "regression_logistique_ova.html#recherche-du-meilleur-c-et-Ã©valuation",
    "href": "regression_logistique_ova.html#recherche-du-meilleur-c-et-Ã©valuation",
    "title": "RÃ©gression Logistique Binomiale - One-Versus-All (OVA)",
    "section": "Recherche du meilleur C et Ã©valuation",
    "text": "Recherche du meilleur C et Ã©valuation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# ğŸ”‡ Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ğŸ”„ Chargement des ensembles de donnÃ©es\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# ğŸ“Š PrÃ©paration des donnÃ©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# ğŸ”¢ Normalisation des donnÃ©es\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# ğŸ¯ Recherche du meilleur hyperparamÃ¨tre C\nC_values = np.arange(0.1, 1.1, 0.1)\nval_accuracies = []\n\nfor C in C_values:\n    model = OneVsRestClassifier(LogisticRegression(solver='saga', C=C, penalty='l2', max_iter=500))\n    model.fit(X_train, y_train)\n    acc = accuracy_score(y_val, model.predict(X_val))\n    val_accuracies.append((C, acc))\n\n# SÃ©lection du meilleur hyperparamÃ¨tre\nbest_C, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# ğŸ“ˆ Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(C_values, [acc for C, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"ParamÃ¨tre de rÃ©gularisation (C)\")\nplt.ylabel(\"PrÃ©cision sur validation\")\nplt.title(\"Impact de la rÃ©gularisation sur la performance de la rÃ©gression logistique (OVA)\")\nplt.legend()\nplt.show()\n\n# ğŸ† ModÃ¨le final avec le meilleur hyperparamÃ¨tre\nfinal_model = OneVsRestClassifier(LogisticRegression(solver='saga', C=best_C, penalty='l2', max_iter=500))\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# ğŸ“Š Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# ğŸ“ˆ Calcul des taux de bien classÃ©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# ğŸ“ Affichage des rÃ©sultats\nprint(f\"\\nğŸ”¹ Meilleur hyperparamÃ¨tre C sur l'Ã©chantillon de validation : {best_C:.2f}\")\nprint(f\"Taux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : {best_val_acc:.2%}\")\nprint(\"\\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nprint(conf_matrix)\n\nprint(\"\\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : {overall_test_accuracy:.2%}\")\n\n\n\n\n\n\n\n\n\nğŸ”¹ Meilleur hyperparamÃ¨tre C sur l'Ã©chantillon de validation : 0.80\nTaux de bien classÃ©s sur l'Ã©chantillon de validation avec cet hyperparamÃ¨tre : 67.71%\n\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\n[[1337  610    1    0    5    1  165]\n [ 495 2150  107    1   21   51    8]\n [   0   65 1270   20    8   67    0]\n [   0    0   70   29    0   11    0]\n [   2  273   27    0   63   15    0]\n [   0   92  386    3   21  192    0]\n [ 143    7    3    0    0    0  668]]\n\nğŸ“ˆ Taux de bien classÃ©s par classe sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\nClasse 1 : 63.10%\nClasse 2 : 75.89%\nClasse 3 : 88.81%\nClasse 4 : 26.36%\nClasse 5 : 16.58%\nClasse 6 : 27.67%\nClasse 7 : 81.36%\n\nğŸ”¹ Taux de bien classÃ©s sur l'Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : 68.07%"
  },
  {
    "objectID": "conclusions.html",
    "href": "conclusions.html",
    "title": "Comparaison des MÃ©thodes de Classification",
    "section": "",
    "text": "(% de bien classÃ©s)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClasse (effectif)\nKNN\nLDA\nQDA\nBayesien NaÃ¯f\nArbre CART\nForÃªt AlÃ©atoire\nReg Log OVA\nReg Log OVO\nReg Multinom\nRÃ©seau Neurones\nSVM OVA\nSVM OVO\n\n\n\n\n1 (10592)\n78.48\n63.43\n54.88\n61.35\n74.61\n82.73\n63.10\n66.97\n66.82\n78.29\n68.29\n70.55\n\n\n2 (14165)\n80.76\n65.83\n55.10\n61.14\n76.84\n87.89\n75.89\n75.40\n75.61\n86.69\n78.57\n78.61\n\n\n3 (7151)\n86.36\n63.08\n66.29\n65.66\n85.03\n94.55\n88.81\n86.78\n87.34\n84.55\n90.63\n90.35\n\n\n4 (549)\n63.64\n48.18\n48.18\n60.00\n67.27\n64.55\n26.36\n34.55\n30.91\n70.00\n20.00\n21.82\n\n\n5 (1899)\n77.89\n47.11\n50.26\n46.32\n69.21\n71.84\n16.58\n25.79\n24.21\n83.95\n33.16\n34.47\n\n\n6 (3473)\n73.05\n52.45\n48.27\n44.81\n74.06\n78.67\n27.67\n40.06\n35.30\n86.31\n38.33\n38.62\n\n\n7 (4102)\n93.79\n80.88\n80.88\n79.29\n90.86\n94.28\n81.36\n80.39\n79.66\n92.33\n82.10\n81.49\n\n\nTotal (41931)\n81.42\n64.04\n58.60\n61.70\n78.35\n86.55\n68.07\n69.99\n69.54\n84.38\n72.22\n72.80"
  },
  {
    "objectID": "conclusions.html#comparaison-des-performances-des-modÃ¨les",
    "href": "conclusions.html#comparaison-des-performances-des-modÃ¨les",
    "title": "Comparaison des MÃ©thodes de Classification",
    "section": "",
    "text": "(% de bien classÃ©s)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClasse (effectif)\nKNN\nLDA\nQDA\nBayesien NaÃ¯f\nArbre CART\nForÃªt AlÃ©atoire\nReg Log OVA\nReg Log OVO\nReg Multinom\nRÃ©seau Neurones\nSVM OVA\nSVM OVO\n\n\n\n\n1 (10592)\n78.48\n63.43\n54.88\n61.35\n74.61\n82.73\n63.10\n66.97\n66.82\n78.29\n68.29\n70.55\n\n\n2 (14165)\n80.76\n65.83\n55.10\n61.14\n76.84\n87.89\n75.89\n75.40\n75.61\n86.69\n78.57\n78.61\n\n\n3 (7151)\n86.36\n63.08\n66.29\n65.66\n85.03\n94.55\n88.81\n86.78\n87.34\n84.55\n90.63\n90.35\n\n\n4 (549)\n63.64\n48.18\n48.18\n60.00\n67.27\n64.55\n26.36\n34.55\n30.91\n70.00\n20.00\n21.82\n\n\n5 (1899)\n77.89\n47.11\n50.26\n46.32\n69.21\n71.84\n16.58\n25.79\n24.21\n83.95\n33.16\n34.47\n\n\n6 (3473)\n73.05\n52.45\n48.27\n44.81\n74.06\n78.67\n27.67\n40.06\n35.30\n86.31\n38.33\n38.62\n\n\n7 (4102)\n93.79\n80.88\n80.88\n79.29\n90.86\n94.28\n81.36\n80.39\n79.66\n92.33\n82.10\n81.49\n\n\nTotal (41931)\n81.42\n64.04\n58.60\n61.70\n78.35\n86.55\n68.07\n69.99\n69.54\n84.38\n72.22\n72.80"
  },
  {
    "objectID": "conclusions.html#explication",
    "href": "conclusions.html#explication",
    "title": "Comparaison des MÃ©thodes de Classification",
    "section": "Explication :",
    "text": "Explication :\n\nOVA force une classe unique Ã  se dÃ©marquer contre toutes les autres.\nOVO compare les classes deux Ã  deux, ce qui est sous-optimal pour des classes dÃ©sÃ©quilibrÃ©es."
  },
  {
    "objectID": "conclusions.html#comparaison-des-performances-des-modÃ¨les-de-bien-classÃ©s",
    "href": "conclusions.html#comparaison-des-performances-des-modÃ¨les-de-bien-classÃ©s",
    "title": "Comparaison des MÃ©thodes de Classification",
    "section": "",
    "text": "Classe (effectif)\nKNN\nLDA\nQDA\nBayesien NaÃ¯f\nArbre CART\nForÃªt AlÃ©atoire\nReg Log OVA\nReg Log OVO\nReg Multinom\nRÃ©seau Neurones\nSVM OVA\nSVM OVO\n\n\n\n\n1 (10592)\n78.48\n63.43\n54.88\n61.35\n74.61\n82.73\n63.10\n66.97\n66.82\n78.29\n68.29\n70.55\n\n\n2 (14165)\n80.76\n65.83\n55.10\n61.14\n76.84\n87.89\n75.89\n75.40\n75.61\n86.69\n78.57\n78.61\n\n\n3 (7151)\n86.36\n63.08\n66.29\n65.66\n85.03\n94.55\n88.81\n86.78\n87.34\n84.55\n90.63\n90.35\n\n\n4 (549)\n63.64\n48.18\n48.18\n60.00\n67.27\n64.55\n26.36\n34.55\n30.91\n70.00\n20.00\n21.82\n\n\n5 (1899)\n77.89\n47.11\n50.26\n46.32\n69.21\n71.84\n16.58\n25.79\n24.21\n83.95\n33.16\n34.47\n\n\n6 (3473)\n73.05\n52.45\n48.27\n44.81\n74.06\n78.67\n27.67\n40.06\n35.30\n86.31\n38.33\n38.62\n\n\n7 (4102)\n93.79\n80.88\n80.88\n79.29\n90.86\n94.28\n81.36\n80.39\n79.66\n92.33\n82.10\n81.49\n\n\nTotal (41931)\n81.42\n64.04\n58.60\n61.70\n78.35\n86.55\n68.07\n69.99\n69.54\n84.38\n72.22\n72.80"
  }
]