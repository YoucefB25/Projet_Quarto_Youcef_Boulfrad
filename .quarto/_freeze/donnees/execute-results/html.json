{
  "hash": "80282851a38ac019b40d4b7f277b207d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Téléchargement et Préparation du Dataset Covertype\"\nformat: html\n---\n\n\n\n# Présentation de la Base de Données Covertype\n\nLa base de données **Covertype** provient de l'[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Covertype). Elle est utilisée pour **classer les types de couvert forestier** à partir de mesures cartographiques (sol, altitude, pente, distance aux points d'eau, etc.).\n\n## Caractéristiques du Dataset\n\n- **Nombre d'observations** : 581 012\n- **Nombre de variables** : 54 (features continues et binaires)\n- **Nombre de classes** : 7 types de couverture forestière (1 à 7)\n- **Problème à résoudre** : Classification supervisée\n\nLes classes ne sont **pas équilibrées**, ce qui peut influencer la performance des modèles de classification. Les proportions des classes dans l’ensemble original sont les suivantes :\n\n| Classe | Type de forêt                   | Effectif | Proportion (%) |\n|--------|---------------------------------|-----------|---------------|\n| 1      | Épicéa                          | 211 840   | 36.5          |\n| 2      | Pin                             | 283 301   | 48.8          |\n| 3      | Peuplier                        | 35 754    | 6.2           |\n| 4      | Bouleau                         | 2 747     | 0.5           |\n| 5      | Érable                          | 9 493     | 1.6           |\n| 6      | Hêtre                           | 17 367    | 3.0           |\n| 7      | Mélèze                          | 18 510    | 3.2           |\n\n---\n\n## Objectif de l'Échantillonnage\n\n### Pourquoi réduire la taille du dataset ?\nLe dataset **Covertype est très grand** (581 012 individus). En raison du **temps de calcul important**, nous avons décidé d'utiliser un **échantillon plus petit**, tout en conservant la distribution des classes.\n\n### Comment gérer le déséquilibre des classes ?\nCertaines classes sont **très majoritaires** (ex : **Pin et Épicéa** représentent à eux seuls **85% des données**), tandis que d'autres sont **très minoritaires** (ex : **Bouleau** à seulement **0.5%**).  \nNous avons appliqué un **échantillonnage différencié** :\n\n- **Sous-échantillonnage des classes majoritaires** (Épicéa et Pin) → **5% de leurs effectifs d'origine**\n- **Sur-échantillonnage relatif des classes minoritaires** (Peuplier, Bouleau, Érable, Hêtre, Mélèze) → **20% de leurs effectifs d'origine**\n\n**Nous ne supprimons pas totalement le déséquilibre**, car nous souhaitons **tester nos modèles dans des conditions réalistes**, où certaines classes restent plus rares que d'autres.\n\nL'échantillon obtenu comptera un peu plus de 40 000 individus, dont 60% seront réservés à l'entrainement des modèles, 20% à la validation des hyperparamètres, et 20% aux tests.\n\n---\n\n## Téléchargement et Préparation des Données\n\n::: {#7bc413da .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Téléchargement direct des données depuis l'URL\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\"\ncolumn_names = [f'Feature_{i}' for i in range(1, 55)] + ['Cover_Type']\ndata = pd.read_csv(url, header=None, names=column_names)\n\n# Définition des taux d'échantillonnage (différent selon les classes)\nsampling_rates = {1: 0.05, 2: 0.05, 3: 0.2, 4: 0.2, 5: 0.2, 6: 0.2, 7: 0.2}\n\n# Échantillonnage différencié par classe\nsampled_data = pd.concat([\n    data[data['Cover_Type'] == cls].sample(frac=sampling_rates[cls], random_state=42)\n    for cls in data['Cover_Type'].unique()\n])\n\n# Réinitialisation des index après échantillonnage\nsampled_data = sampled_data.reset_index(drop=True)\n\n# Affichage des effectifs par classe après échantillonnage\nprint(\"Effectifs par classe après échantillonnage différencié :\")\nprint(sampled_data['Cover_Type'].value_counts().sort_index())\n\n# Division des données en ensembles d'entraînement, validation et test\ntrain_data, temp_data = train_test_split(sampled_data, test_size=0.4, random_state=42, stratify=sampled_data['Cover_Type'])\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data['Cover_Type'])\n\n# Affichage des tailles des ensembles\nprint(f\"\\nTaille des ensembles :\")\nprint(f\"  - Entraînement : {len(train_data)} lignes\")\nprint(f\"  - Validation : {len(val_data)} lignes\")\nprint(f\"  - Test : {len(test_data)} lignes\")\n\n# Affichage des effectifs par classe dans chaque ensemble\nprint(\"\\nEffectifs par classe dans l'ensemble d'entraînement :\")\nprint(train_data['Cover_Type'].value_counts().sort_index())\n\nprint(\"\\nEffectifs par classe dans l'ensemble de validation :\")\nprint(val_data['Cover_Type'].value_counts().sort_index())\n\nprint(\"\\nEffectifs par classe dans l'ensemble de test :\")\nprint(test_data['Cover_Type'].value_counts().sort_index())\n\n# Sauvegarder les ensembles en fichiers CSV\ntrain_data.to_csv('covertype_train.csv', index=False)\nval_data.to_csv('covertype_val.csv', index=False)\ntest_data.to_csv('covertype_test.csv', index=False)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEffectifs par classe après échantillonnage différencié :\nCover_Type\n1    10592\n2    14165\n3     7151\n4      549\n5     1899\n6     3473\n7     4102\nName: count, dtype: int64\n\nTaille des ensembles :\n  - Entraînement : 25158 lignes\n  - Validation : 8386 lignes\n  - Test : 8387 lignes\n\nEffectifs par classe dans l'ensemble d'entraînement :\nCover_Type\n1    6355\n2    8499\n3    4291\n4     329\n5    1139\n6    2084\n7    2461\nName: count, dtype: int64\n\nEffectifs par classe dans l'ensemble de validation :\nCover_Type\n1    2118\n2    2833\n3    1430\n4     110\n5     380\n6     695\n7     820\nName: count, dtype: int64\n\nEffectifs par classe dans l'ensemble de test :\nCover_Type\n1    2119\n2    2833\n3    1430\n4     110\n5     380\n6     694\n7     821\nName: count, dtype: int64\n```\n:::\n:::\n\n\n",
    "supporting": [
      "donnees_files"
    ],
    "filters": [],
    "includes": {}
  }
}