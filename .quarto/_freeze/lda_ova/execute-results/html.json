{
  "hash": "0935b9b3fa1bc57fa97e42167765821d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Analyse Discriminante Linéaire (LDA) - One-Versus-All (OVA)\"\n---\n\n\n\n\n\n\n\n## Théorie\nL'**Analyse Discriminante Linéaire (LDA)** est une technique de classification qui cherche à trouver une combinaison linéaire de caractéristiques maximisant la séparation entre les classes.\n\nL'approche **One-Versus-All (OVA)** consiste à entraîner un modèle pour chaque classe, en distinguant chaque classe des autres combinées.\n\n## Hyperparamètres\nNous allons tester les hyperparamètres suivants :\n- **Régularisation (`shrinkage`)** : contrôle la variance de la covariance estimée (valeurs entre `0` et `1`).\n- **Standardisation des données** : normalisation des features avant l'entraînement.\n\n## Exemple en Python\n\n::: {#c5e2c862 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Chargement des ensembles de données\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# Préparation des données\nX_train = train_data.drop('Cover_Type', axis=1)\ny_train = train_data['Cover_Type']\n\nX_val = val_data.drop('Cover_Type', axis=1)\ny_val = val_data['Cover_Type']\n\nX_test = test_data.drop('Cover_Type', axis=1)\ny_test = test_data['Cover_Type']\n\n# Standardisation des données\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)\n\n# Recherche des meilleurs hyperparamètres\nshrinkage_values = np.linspace(0, 1, 10)\ntrain_accuracies = []\nval_accuracies = []\n\nfor shrinkage in shrinkage_values:\n    lda_ova = OneVsRestClassifier(LinearDiscriminantAnalysis(solver='lsqr', shrinkage=shrinkage))\n    lda_ova.fit(X_train, y_train)\n    \n    y_train_pred = lda_ova.predict(X_train)\n    y_val_pred = lda_ova.predict(X_val)\n    \n    train_accuracies.append(accuracy_score(y_train, y_train_pred))\n    val_accuracies.append(accuracy_score(y_val, y_val_pred))\n\n# Sélection du meilleur shrinkage\nbest_shrinkage = shrinkage_values[val_accuracies.index(max(val_accuracies))]\nprint(f\"Meilleur shrinkage LDA (OVA): {best_shrinkage}\")\n\n# Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(shrinkage_values, train_accuracies, marker='o', linestyle='dashed', label='Train Accuracy')\nplt.plot(shrinkage_values, val_accuracies, marker='s', linestyle='dashed', label='Validation Accuracy')\nplt.xlabel(\"Shrinkage\")\nplt.ylabel(\"Précision\")\nplt.title(\"Impact du shrinkage sur la performance de LDA (OVA)\")\nplt.legend()\nplt.show()\n\n# Modèle final avec le meilleur shrinkage\nlda_ova = OneVsRestClassifier(LinearDiscriminantAnalysis(solver='lsqr', shrinkage=best_shrinkage))\nlda_ova.fit(X_train, y_train)\ny_test_pred = lda_ova.predict(X_test)\n\n# Affichage de la matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\nprint(\"\\nMatrice de confusion (OVA) :\")\nprint(conf_matrix)\n\nprint(\"\\nÉvaluation sur l'ensemble de test\")\nprint(classification_report(y_test, y_test_pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMeilleur shrinkage LDA (OVA): 0.0\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](lda_ova_files/figure-html/cell-2-output-2.png){width=672 height=523}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nMatrice de confusion (OVA) :\n[[1230  632    1    0   29    2  225]\n [ 472 2041   65   14  121  107   13]\n [   0   56 1123  122    9  120    0]\n [   0    2   49   53    0    6    0]\n [   5  172   27    0  165   11    0]\n [   0   70  341   25   40  218    0]\n [ 140   11    3    0    3    0  664]]\n\nÉvaluation sur l'ensemble de test\n              precision    recall  f1-score   support\n\n           1       0.67      0.58      0.62      2119\n           2       0.68      0.72      0.70      2833\n           3       0.70      0.79      0.74      1430\n           4       0.25      0.48      0.33       110\n           5       0.45      0.43      0.44       380\n           6       0.47      0.31      0.38       694\n           7       0.74      0.81      0.77       821\n\n    accuracy                           0.66      8387\n   macro avg       0.56      0.59      0.57      8387\nweighted avg       0.65      0.66      0.65      8387\n\n```\n:::\n:::\n\n\n",
    "supporting": [
      "lda_ova_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}