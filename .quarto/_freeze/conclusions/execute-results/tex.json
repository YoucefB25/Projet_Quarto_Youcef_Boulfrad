{
  "hash": "5238908db5aa5950680ace6ca2d5d06c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Meilleures Performances Globales\n---\n\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# 📊 Données des performances des modèles\ndata = {\n    \"Classe\": [\"1 (10592)\", \"2 (14165)\", \"3 (7151)\", \"4 (549)\", \"5 (1899)\", \"6 (3473)\", \"7 (4102)\", \"Total (41931)\"],\n    \"KNN\": [78.48, 80.76, 86.36, 63.64, 77.89, 73.05, 93.79, 81.42],\n    \"LDA\": [63.43, 65.83, 63.08, 48.18, 47.11, 52.45, 80.88, 64.04],\n    \"QDA\": [54.88, 55.10, 66.29, 48.18, 50.26, 48.27, 80.88, 58.60],\n    \"Bayesien Naïf\": [61.35, 61.14, 65.66, 60.00, 46.32, 44.81, 79.29, 61.70],\n    \"Arbre CART\": [74.61, 76.84, 85.03, 67.27, 69.21, 74.06, 90.86, 78.35],\n    \"Forêt Aléatoire\": [82.73, 87.89, 94.55, 64.55, 71.84, 78.67, 94.28, 86.55],\n    \"Reg Log OVA\": [63.10, 75.89, 88.81, 26.36, 16.58, 27.67, 81.36, 68.07],\n    \"Reg Log OVO\": [66.97, 75.40, 86.78, 34.55, 25.79, 40.06, 80.39, 69.99],\n    \"Reg Multinom\": [66.82, 75.61, 87.34, 30.91, 24.21, 35.30, 79.66, 69.54],\n    \"Réseau Neurones\": [78.29, 86.69, 84.55, 70.00, 83.95, 86.31, 92.33, 84.38],\n    \"SVM OVA\": [68.29, 78.57, 90.63, 20.00, 33.16, 38.33, 82.10, 72.22],\n    \"SVM OVO\": [70.55, 78.61, 90.35, 21.82, 34.47, 38.62, 81.49, 72.80]\n}\n\n# 📋 Création du DataFrame et arrondi à 2 décimales\ndf = pd.DataFrame(data).set_index(\"Classe\").round(2)\n\n# 📊 Création du tableau avec `matplotlib`\nfig, ax = plt.subplots(figsize=(5, 2))  # 🔍 Ajustement de la taille\nax.axis(\"tight\")\nax.axis(\"off\")\n\n# 🖌 Création du tableau\ntable = ax.table(cellText=df.values, colLabels=df.columns, rowLabels=df.index,\n                 cellLoc=\"center\", loc=\"center\", colWidths=[0.15] + [0.08]*len(df.columns))\n\n# 🎨 Application des couleurs conditionnelles sur les cellules de données\nfor i in range(len(df.index)):  # 🔢 Parcours des lignes (les classes)\n    for j in range(len(df.columns)):  # 🔢 Parcours des colonnes (modèles)\n        value = df.iloc[i, j]  # 📌 Récupération de la valeur\n        cell = table.get_celld().get((i+1, j))  # 📌 +1 pour éviter la ligne d'en-tête\n        if cell:  # ✅ Vérification que la cellule existe bien\n            if value >= 50:\n                cell.set_facecolor(\"#c2f0c2\")  # ✅ Vert clair pour valeurs ≥ 50%\n            else:\n                cell.set_facecolor(\"#f4cccc\")  # ✅ Rouge clair pour valeurs < 50%\n\n# 📊 Affichage du tableau formaté\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-display}\n![](conclusions_files/figure-pdf/cell-2-output-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n- La Forêt Aléatoire est le meilleur modèle global avec 86.55% de précision moyenne.\n- Le Réseau de Neurones suit de près avec 84.38%, prouvant l'efficacité des méthodes d'apprentissage profond.\n- Le KNN (81.42%) et l'Arbre CART (78.35%) sont également compétitifs.\n\n# Analyse des Classes Minoritaires (4, 5, 6)\n\n- Les classes peu représentées (4, 5, 6) sont souvent mal classées.\n- La Forêt Aléatoire (64.55%, 71.84%, 78.67%) offre la meilleure robustesse.\n- Le Réseau de Neurones (70.00%, 83.95%, 86.31%) s’adapte bien aux déséquilibres.\n- L'Arbre CART (67.27%, 69.21%, 74.06%) est un compromis intéressant.\n\n## Méthodes les Plus Faibles :\n\n- SVM et Régressions Logistiques (OVA et OVO) sous-performent sur les classes minoritaires (moins de 40% pour certaines).\n- QDA et Bayésien Naïf sont globalement moins efficaces avec 58.60% et 61.70% respectivement.\n\n# Méthodes Paramétriques vs Non-Paramétriques\n\nLes modèles non-paramétriques surpassent largement les modèles paramétriques.\n- Forêt Aléatoire (86.55%), Réseau de Neurones (84.38%), KNN (81.42%) et Arbre CART (78.35%) dominent le classement.\n- À l’inverse, LDA (64.04%), QDA (58.60%) et Bayésien Naïf (61.70%) sont nettement moins performants.\n\nLes modèles non-paramétriques sont plus flexibles et capables de capturer des structures complexes dans les données,\nalors que les modèles paramétriques reposent sur des hypothèses restrictives qui limitent leur efficacité.\n\n# Multiclasse Natif vs Adapté (OVA/OVO)\n\nLes méthodes natives multiclasses (comme la Forêt Aléatoire, Arbre CART, Réseau de Neurones)\nont des performances globalement meilleures que les modèles binaires adaptés OVA et OVO.\n\n- La Forêt Aléatoire (86.55%) et Réseau de Neurones (84.38%), qui sont naturellement adaptés au multiclass,\nsurpassent les modèles SVM OVA (72.22%) et SVM OVO (72.80%), ainsi que les régressions logistiques OVA et OVO.\n\n- Les méthodes binaires adaptées (OVA et OVO) peinent surtout sur les classes minoritaires,\navec des scores très faibles (ex. SVM OVA : 20.00% sur la classe 4 !).\n\n## Explication : L'OVA force une classe unique à se démarquer contre toutes les autres,\ntandis que l'OVO compare les classes deux à deux, ce qui est sous-optimal pour des classes déséquilibrées.\n\n# Résumé Final\n\n- Les modèles non-paramétriques sont les meilleurs grâce à leur flexibilité et capacité d’adaptation aux classes déséquilibrées.\n- Les méthodes multiclasses natives (Forêt Aléatoire, Réseau de Neurones, Arbre CART) dominent les modèles binaires adaptés.\n- Si les classes minoritaires sont importantes, privilégiez Forêt Aléatoire, Réseau de Neurones ou Arbre CART.\n- Les modèles OVA/OVO ne sont pas adaptés aux jeux de données avec des classes déséquilibrées.\n\n\n",
    "supporting": [
      "conclusions_files"
    ],
    "filters": []
  }
}