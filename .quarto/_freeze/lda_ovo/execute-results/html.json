{
  "hash": "7f1f8215308c654670396ad0f38849d2",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Analyse Discriminante Linéaire - OVO\"\n---\n\n\n\n\n# Analyse Discriminante Linéaire (LDA) - One-Versus-One (OVO)\n\n## Théorie\nL'**Analyse Discriminante Linéaire (LDA)** est une technique de classification qui cherche à trouver une combinaison linéaire de caractéristiques maximisant la séparation entre les classes.\n\nL'approche **One-Versus-One (OVO)** consiste à entraîner un modèle pour chaque paire de classes, ce qui est utile lorsque les classes sont bien séparées.\n\n## Hyperparamètres\nNous allons tester les hyperparamètres suivants :\n- **Régularisation (`shrinkage`)** : contrôle la variance de la covariance estimée (valeurs entre `0` et `1`).\n- **Standardisation des données** : normalisation des features avant l'entraînement.\n\n## Exemple en Python\n\n::: {#21267c4f .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Chargement des ensembles de données\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# Préparation des données\nX_train = train_data.drop('Cover_Type', axis=1)\ny_train = train_data['Cover_Type']\n\nX_val = val_data.drop('Cover_Type', axis=1)\ny_val = val_data['Cover_Type']\n\nX_test = test_data.drop('Cover_Type', axis=1)\ny_test = test_data['Cover_Type']\n\n# Standardisation des données\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)\n\n# Recherche des meilleurs hyperparamètres\nshrinkage_values = np.linspace(0, 1, 10)\ntrain_accuracies = []\nval_accuracies = []\n\nfor shrinkage in shrinkage_values:\n    lda_ovo = OneVsOneClassifier(LinearDiscriminantAnalysis(solver='lsqr', shrinkage=shrinkage))\n    lda_ovo.fit(X_train, y_train)\n    \n    y_train_pred = lda_ovo.predict(X_train)\n    y_val_pred = lda_ovo.predict(X_val)\n    \n    train_accuracies.append(accuracy_score(y_train, y_train_pred))\n    val_accuracies.append(accuracy_score(y_val, y_val_pred))\n\n# Sélection du meilleur shrinkage\nbest_shrinkage = shrinkage_values[val_accuracies.index(max(val_accuracies))]\nprint(f\"Meilleur shrinkage LDA (OVO): {best_shrinkage}\")\n\n# Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(shrinkage_values, train_accuracies, marker='o', linestyle='dashed', label='Train Accuracy')\nplt.plot(shrinkage_values, val_accuracies, marker='s', linestyle='dashed', label='Validation Accuracy')\nplt.xlabel(\"Shrinkage\")\nplt.ylabel(\"Précision\")\nplt.title(\"Impact du shrinkage sur la performance de LDA (OVO)\")\nplt.legend()\nplt.show()\n\n# Modèle final avec le meilleur shrinkage\nlda_ovo = OneVsOneClassifier(LinearDiscriminantAnalysis(solver='lsqr', shrinkage=best_shrinkage))\nlda_ovo.fit(X_train, y_train)\ny_test_pred = lda_ovo.predict(X_test)\n\n# Affichage de la matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\nprint(\"\\nMatrice de confusion (OVO) :\")\nprint(conf_matrix)\n\nprint(\"\\nÉvaluation sur l'ensemble de test\")\nprint(classification_report(y_test, y_test_pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMeilleur shrinkage LDA (OVO): 0.1111111111111111\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](lda_ovo_files/figure-html/cell-2-output-2.png){width=672 height=523}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nMatrice de confusion (OVO) :\n[[1085  501    2    0    3    3  114]\n [ 388 1777   62    0   10   14   10]\n [   0   23  229   13    0   16    0]\n [   0    0    4   12    0    5    0]\n [   2   59   12    0    1    0    0]\n [   0   39   89    1    0   15    0]\n [  30    0    0    0    0    0  129]]\n\nÉvaluation sur l'ensemble de test\n              precision    recall  f1-score   support\n\n           1       0.72      0.64      0.68      1708\n           2       0.74      0.79      0.76      2261\n           3       0.58      0.81      0.67       281\n           4       0.46      0.57      0.51        21\n           5       0.07      0.01      0.02        74\n           6       0.28      0.10      0.15       144\n           7       0.51      0.81      0.63       159\n\n    accuracy                           0.70      4648\n   macro avg       0.48      0.53      0.49      4648\nweighted avg       0.69      0.70      0.69      4648\n\n```\n:::\n:::\n\n\n",
    "supporting": [
      "lda_ovo_files"
    ],
    "filters": [],
    "includes": {}
  }
}