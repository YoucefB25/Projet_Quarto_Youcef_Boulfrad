{
  "hash": "83631d62bbe14e44f2a9ae6eb203a2ea",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Analyse Discriminante Linéaire (LDA) - One-Versus-One (OVO)\"\n---\n\n\n\n\n\n\n## Théorie\nL'**Analyse Discriminante Linéaire (LDA)** est une technique de classification qui cherche à trouver une combinaison linéaire de caractéristiques maximisant la séparation entre les classes.\n\nL'approche **One-Versus-One (OVO)** consiste à entraîner un modèle pour chaque paire de classes, ce qui est utile lorsque les classes sont bien séparées.\n\n## Hyperparamètres\nNous allons tester les hyperparamètres suivants :\n- **Régularisation (`shrinkage`)** : contrôle la variance de la covariance estimée (valeurs entre `0` et `1`).\n- **Standardisation des données** : normalisation des features avant l'entraînement.\n\n## Exemple en Python\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Chargement des ensembles de données\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# Préparation des données\nX_train = train_data.drop('Cover_Type', axis=1)\ny_train = train_data['Cover_Type']\n\nX_val = val_data.drop('Cover_Type', axis=1)\ny_val = val_data['Cover_Type']\n\nX_test = test_data.drop('Cover_Type', axis=1)\ny_test = test_data['Cover_Type']\n\n# Standardisation des données\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)\n\n# Recherche des meilleurs hyperparamètres\nshrinkage_values = np.linspace(0, 1, 10)\ntrain_accuracies = []\nval_accuracies = []\n\nfor shrinkage in shrinkage_values:\n    lda_ovo = OneVsOneClassifier(LinearDiscriminantAnalysis(solver='lsqr', shrinkage=shrinkage))\n    lda_ovo.fit(X_train, y_train)\n    \n    y_train_pred = lda_ovo.predict(X_train)\n    y_val_pred = lda_ovo.predict(X_val)\n    \n    train_accuracies.append(accuracy_score(y_train, y_train_pred))\n    val_accuracies.append(accuracy_score(y_val, y_val_pred))\n\n# Sélection du meilleur shrinkage\nbest_shrinkage = shrinkage_values[val_accuracies.index(max(val_accuracies))]\nprint(f\"Meilleur shrinkage LDA (OVO): {best_shrinkage}\")\n\n# Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(shrinkage_values, train_accuracies, marker='o', linestyle='dashed', label='Train Accuracy')\nplt.plot(shrinkage_values, val_accuracies, marker='s', linestyle='dashed', label='Validation Accuracy')\nplt.xlabel(\"Shrinkage\")\nplt.ylabel(\"Précision\")\nplt.title(\"Impact du shrinkage sur la performance de LDA (OVO)\")\nplt.legend()\nplt.show()\n\n# Modèle final avec le meilleur shrinkage\nlda_ovo = OneVsOneClassifier(LinearDiscriminantAnalysis(solver='lsqr', shrinkage=best_shrinkage))\nlda_ovo.fit(X_train, y_train)\ny_test_pred = lda_ovo.predict(X_test)\n\n# Affichage de la matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\nprint(\"\\nMatrice de confusion (OVO) :\")\nprint(conf_matrix)\n\nprint(\"\\nÉvaluation sur l'ensemble de test\")\nprint(classification_report(y_test, y_test_pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMeilleur shrinkage LDA (OVO): 0.1111111111111111\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](lda_ovo_files/figure-pdf/cell-2-output-2.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nMatrice de confusion (OVO) :\n[[1198  687    1    0    7    2  224]\n [ 448 2160   82    1   59   70   13]\n [   0   66 1197   75    5   87    0]\n [   0    0   48   50    0   12    0]\n [   7  205   26    0  124   18    0]\n [   0   82  366    4    2  240    0]\n [ 139   13    3    0    2    0  664]]\n\nÉvaluation sur l'ensemble de test\n              precision    recall  f1-score   support\n\n           1       0.67      0.57      0.61      2119\n           2       0.67      0.76      0.71      2833\n           3       0.69      0.84      0.76      1430\n           4       0.38      0.45      0.42       110\n           5       0.62      0.33      0.43       380\n           6       0.56      0.35      0.43       694\n           7       0.74      0.81      0.77       821\n\n    accuracy                           0.67      8387\n   macro avg       0.62      0.59      0.59      8387\nweighted avg       0.67      0.67      0.66      8387\n\n```\n:::\n:::\n\n\n",
    "supporting": [
      "lda_ovo_files"
    ],
    "filters": []
  }
}