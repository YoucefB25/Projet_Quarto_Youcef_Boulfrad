{
  "hash": "18d3ebc0ff47b3100001f94e63b75ae9",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Régression Logistique Binomiale - One-Versus-One (OVO)\"\n---\n\n\n\n\n\n\n## Théorie\n\nLa **régression logistique binomiale** est utilisée pour la classification binaire, mais elle peut être adaptée aux problèmes **multiclasse** via l'approche **One-Versus-One (OVO)**. Ici, un modèle est entraîné pour chaque paire de classes, ce qui peut améliorer la précision lorsque les classes sont bien séparées.\n\n## Hyperparamètre utilisé\n\nNous allons optimiser :\n\n- **Paramètre de régularisation (`C`)** : qui contrôle la complexité du modèle et est sélectionné en fonction de la précision sur l'ensemble de validation.\n\n## Métriques d’évaluation\n\nNous afficherons :\n\n- **Matrice de confusion** : montrant les erreurs de classification sur l'échantillon de test.\n\n- **Taux de bien classés sur l'échantillon de validation** avec le meilleur hyperparamètre.\n\n- **Taux de bien classés sur l'échantillon de test** avec ce même hyperparamètre.\n\n- **Taux de bien classés par classe sur l'échantillon de test** pour observer la précision sur chaque classe.\n\n## Recherche du meilleur `C` et évaluation\n\n::: {#663547be .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\n\n# 🔇 Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# 🔄 Chargement des ensembles de données\ntrain_data = pd.read_csv('../data/covertype_train.csv')\nval_data = pd.read_csv('../data/covertype_val.csv')\ntest_data = pd.read_csv('../data/covertype_test.csv')\n\n# 📊 Préparation des données\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# 🔢 Normalisation des données\nscaler = StandardScaler()\nX_train, X_val, X_test = scaler.fit_transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n\n# 🎯 Recherche du meilleur hyperparamètre C\nC_values = np.arange(0.1, 1.1, 0.1)\nval_accuracies = []\n\nfor C in C_values:\n    model = OneVsOneClassifier(LogisticRegression(solver='saga', C=C, penalty='l2', max_iter=500))\n    model.fit(X_train, y_train)\n    acc = accuracy_score(y_val, model.predict(X_val))\n    val_accuracies.append((C, acc))\n\n# Sélection du meilleur hyperparamètre\nbest_C, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# 📈 Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(C_values, [acc for C, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Paramètre de régularisation (C)\")\nplt.ylabel(\"Précision sur validation\")\nplt.title(\"Impact de la régularisation sur la performance de la régression logistique (OVO)\")\nplt.legend()\nplt.show()\n\n# 🏆 Modèle final avec le meilleur hyperparamètre\nfinal_model = OneVsOneClassifier(LogisticRegression(solver='saga', C=best_C, penalty='l2', max_iter=500))\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# 📊 Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# 📈 Calcul des taux de bien classés par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# 📝 Affichage des résultats\nprint(f\"\\n🔹 Meilleur hyperparamètre C sur l'échantillon de validation : {best_C:.2f}\")\nprint(f\"Taux de bien classés sur l'échantillon de validation avec cet hyperparamètre : {best_val_acc:.2%}\")\nprint(\"\\n📊 Matrice de confusion sur l'échantillon de test, avec le meilleur hyperparamètre :\")\nprint(conf_matrix)\n\nprint(\"\\n📈 Taux de bien classés par classe sur l'échantillon de test, avec le meilleur hyperparamètre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\n🔹 Taux de bien classés sur l'échantillon de test avec le meilleur hyperparamètre : {overall_test_accuracy:.2%}\")\n```\n\n::: {.cell-output .cell-output-display}\n![](regression_logistique_ovo_files/figure-html/cell-2-output-1.png){width=720 height=525}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n🔹 Meilleur hyperparamètre C sur l'échantillon de validation : 0.30\nTaux de bien classés sur l'échantillon de validation avec cet hyperparamètre : 69.53%\n\n📊 Matrice de confusion sur l'échantillon de test, avec le meilleur hyperparamètre :\n[[1419  584    1    0    6    1  108]\n [ 517 2136   85    1   36   50    8]\n [   0   44 1241   35    4  106    0]\n [   0    0   56   38    0   16    0]\n [   2  254   21    0   98    5    0]\n [   0   53  359    2    2  278    0]\n [ 158    1    2    0    0    0  660]]\n\n📈 Taux de bien classés par classe sur l'échantillon de test, avec le meilleur hyperparamètre  :\nClasse 1 : 66.97%\nClasse 2 : 75.40%\nClasse 3 : 86.78%\nClasse 4 : 34.55%\nClasse 5 : 25.79%\nClasse 6 : 40.06%\nClasse 7 : 80.39%\n\n🔹 Taux de bien classés sur l'échantillon de test avec le meilleur hyperparamètre : 69.99%\n```\n:::\n:::\n\n\n",
    "supporting": [
      "regression_logistique_ovo_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}