{
  "hash": "1e3a294a43a50e9d9a48a34f52241ad8",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Random Forest - Forêt Aléatoire\"\n---\n\n\n\n\n\n\n## Théorie\n\nLa **forêt aléatoire** est un algorithme d'apprentissage supervisé basé sur un **ensemble d'arbres de décision**. Il fonctionne en combinant plusieurs arbres pour **améliorer la précision** et **réduire le risque de surapprentissage**.\n\n## Hyperparamètre utilisé\n\nNous allons optimiser :\n\n- **Nombre d'arbres (`n_estimators`)** : sélectionné en fonction de la précision sur l’ensemble de validation.\n\n## Métriques d’évaluation\n\nNous afficherons :\n\n- **Matrice de confusion** : récapitulant les erreurs de classification.\n- **Taux de bien classés sur l’échantillon de validation** avec le meilleur hyperparamètre.\n- **Taux de bien classés sur l’échantillon de test** avec ce même hyperparamètre.\n- **Taux de bien classés par classe sur l’échantillon de test**.\n\n## Recherche du meilleur `n_estimators` et évaluation\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport warnings\n\n# 🔇 Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# 🔄 Chargement des ensembles de données\ntrain_data = pd.read_csv('../data/covertype_train.csv')\nval_data = pd.read_csv('../data/covertype_val.csv')\ntest_data = pd.read_csv('../data/covertype_test.csv')\n\n# 📊 Préparation des données\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# 🎯 Recherche du meilleur hyperparamètre n_estimators\nn_estimators_range = range(50, 1000, 50)\nval_accuracies = []\n\nfor n in n_estimators_range:\n    rf = RandomForestClassifier(n_estimators=n, random_state=42, n_jobs=-1)\n    rf.fit(X_train, y_train)\n    acc = accuracy_score(y_val, rf.predict(X_val))\n    val_accuracies.append((n, acc))\n\n# Sélection du meilleur nombre d'arbres\nbest_n, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# 📈 Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(n_estimators_range, [acc for n, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Nombre d'arbres\")\nplt.ylabel(\"Précision sur validation\")\nplt.title(\"Impact du nombre d'arbres sur la performance de Random Forest\")\nplt.legend()\nplt.show()\n\n# 🏆 Modèle final avec le meilleur nombre d'arbres\nfinal_model = RandomForestClassifier(n_estimators=best_n, random_state=42, n_jobs=-1)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# 📊 Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# 📈 Calcul des taux de bien classés par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# 📝 Affichage des résultats\nprint(f\"\\n🔹 Meilleur nombre d'arbres sur l’échantillon de validation : {best_n}\")\nprint(f\"Taux de bien classés sur l’échantillon de validation avec cet hyperparamètre : {best_val_acc:.2%}\")\nprint(\"\\n📊 Matrice de confusion sur l'échantillon de test, avec le meilleur hyperparamètre :\")\nprint(conf_matrix)\n\nprint(\"\\n📈 Taux de bien classés par classe sur l’échantillon de test, avec le meilleur hyperparamètre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\n🔹 Taux de bien classés sur l’échantillon de test avec le meilleur hyperparamètre : {overall_test_accuracy:.2%}\")\n```\n\n::: {.cell-output .cell-output-display}\n![](foret_aleatoire_files/figure-pdf/cell-2-output-1.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n🔹 Meilleur nombre d'arbres sur l’échantillon de validation : 450\nTaux de bien classés sur l’échantillon de validation avec cet hyperparamètre : 86.25%\n\n📊 Matrice de confusion sur l'échantillon de test, avec le meilleur hyperparamètre :\n[[1753  312    0    0    5    2   47]\n [ 247 2490   40    1   20   31    4]\n [   0   15 1352   11    1   51    0]\n [   0    0   37   71    0    2    0]\n [   3   86   16    0  273    2    0]\n [   1   17  128    2    0  546    0]\n [  43    4    0    0    0    0  774]]\n\n📈 Taux de bien classés par classe sur l’échantillon de test, avec le meilleur hyperparamètre  :\nClasse 1 : 82.73%\nClasse 2 : 87.89%\nClasse 3 : 94.55%\nClasse 4 : 64.55%\nClasse 5 : 71.84%\nClasse 6 : 78.67%\nClasse 7 : 94.28%\n\n🔹 Taux de bien classés sur l’échantillon de test avec le meilleur hyperparamètre : 86.55%\n```\n:::\n:::\n\n\n",
    "supporting": [
      "foret_aleatoire_files/figure-pdf"
    ],
    "filters": []
  }
}