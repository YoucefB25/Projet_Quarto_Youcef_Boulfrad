{
  "hash": "6a6443a8a4291dbde1fb8dfee211b520",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"KNN - K-Nearest Neighbors\"\n---\n\n\n\n\n\n\n# KNN (K-Nearest Neighbors)\n\n## Théorie\nLe KNN est un algorithme de classification basé sur la proximité des données dans un espace multidimensionnel.\n\n## Exemple en Python\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n# Chargement des ensembles de données déjà préparés\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# Préparation des données\nX_train = train_data.drop('Cover_Type', axis=1)\ny_train = train_data['Cover_Type']\n\nX_val = val_data.drop('Cover_Type', axis=1)\ny_val = val_data['Cover_Type']\n\nX_test = test_data.drop('Cover_Type', axis=1)\ny_test = test_data['Cover_Type']\n\n# Recherche du meilleur nombre de voisins en utilisant uniquement l'ensemble d'entraînement\nneighbors = range(1, 51, 2)\ntrain_accuracies = []\nval_accuracies = []\n\nfor k in neighbors:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    \n    # Évaluation sur l'ensemble d'entraînement\n    y_train_pred = knn.predict(X_train)\n    train_accuracies.append(accuracy_score(y_train, y_train_pred))\n    \n    # Évaluation sur l'ensemble de validation\n    y_val_pred = knn.predict(X_val)\n    val_accuracies.append(accuracy_score(y_val, y_val_pred))\n\n# Sélection du meilleur hyperparamètre basé sur l'ensemble de validation\nbest_k = neighbors[val_accuracies.index(max(val_accuracies))]\nprint(f\"Meilleur nombre de voisins: {best_k}\")\n\n# Affichage du graphique comparant l'entraînement et la validation\nplt.figure(figsize=(8, 6))\nplt.plot(neighbors, train_accuracies, marker='o', linestyle='dashed', label='Train Accuracy')\nplt.plot(neighbors, val_accuracies, marker='s', linestyle='dashed', label='Validation Accuracy')\nplt.xlabel(\"Nombre de voisins\")\nplt.ylabel(\"Taux de bonnes prédictions\")\nplt.title(\"Optimisation du nombre de voisins pour KNN\")\nplt.legend()\nplt.show()\n\n# Modèle final avec le meilleur k\nknn = KNeighborsClassifier(n_neighbors=best_k)\nknn.fit(X_train, y_train)\n\n# Évaluation sur l'ensemble de test\ny_test_pred = knn.predict(X_test)\nprint(\"\\nÉvaluation sur l'ensemble de test\")\nprint(confusion_matrix(y_test, y_test_pred))\nprint(classification_report(y_test, y_test_pred))\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMeilleur nombre de voisins: 1\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](knn_files/figure-pdf/cell-2-output-2.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nÉvaluation sur l'ensemble de test\n[[1413  263    0    0    6    2   24]\n [ 267 1914   39    0   20   16    5]\n [   0   44  210    3    0   24    0]\n [   0    1    8    8    0    4    0]\n [   8   23    2    0   41    0    0]\n [   1   14   28    1    0  100    0]\n [  27    4    0    0    0    0  128]]\n              precision    recall  f1-score   support\n\n           1       0.82      0.83      0.83      1708\n           2       0.85      0.85      0.85      2261\n           3       0.73      0.75      0.74       281\n           4       0.67      0.38      0.48        21\n           5       0.61      0.55      0.58        74\n           6       0.68      0.69      0.69       144\n           7       0.82      0.81      0.81       159\n\n    accuracy                           0.82      4648\n   macro avg       0.74      0.69      0.71      4648\nweighted avg       0.82      0.82      0.82      4648\n\n```\n:::\n:::\n\n\n",
    "supporting": [
      "knn_files"
    ],
    "filters": []
  }
}