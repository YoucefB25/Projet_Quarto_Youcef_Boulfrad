{
  "hash": "deffd37183c49fe88330f87be5d19cf3",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Téléchargement et Préparation du Dataset Covertype\"\nformat: html\n---\n\n\n\n\n\n\n# Téléchargement de la base de données Covertype\n\nLa base de données **Covertype** provient de l'[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Covertype).\n\nVous pouvez la télécharger directement via le lien ci-dessous :\n\n- [Télécharger le dataset Covertype (CSV)](https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz)\n\n## Chargement et Réduction des Données\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Téléchargement direct des données depuis l'URL\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\"\ncolumn_names = [f'Feature_{i}' for i in range(1, 55)] + ['Cover_Type']\ndata = pd.read_csv(url, header=None, names=column_names)\n\n# Définition des taux d'échantillonnage\nsampling_rates = {1: 0.05, 2: 0.05, 3: 0.2, 4: 0.2, 5: 0.2, 6: 0.2, 7: 0.2}\n\n# Échantillonnage différencié par classe\nsampled_data = pd.concat([\n    data[data['Cover_Type'] == cls].sample(frac=sampling_rates[cls], random_state=42)\n    for cls in data['Cover_Type'].unique()\n])\n\n# Réinitialiser les index après échantillonnage\nsampled_data = sampled_data.reset_index(drop=True)\n\n# Affichage des effectifs par classe avant la division\nprint(\"Effectifs par classe après échantillonnage différencié :\")\nprint(sampled_data['Cover_Type'].value_counts().sort_index())\n\n# Division des données en ensembles d'entraînement, validation et test\ntrain_data, temp_data = train_test_split(sampled_data, test_size=0.4, random_state=42, stratify=sampled_data['Cover_Type'])\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data['Cover_Type'])\n\n# Affichage des tailles des ensembles\nprint(f\"\\nTaille des ensembles :\")\nprint(f\"  - Entraînement : {len(train_data)} lignes\")\nprint(f\"  - Validation : {len(val_data)} lignes\")\nprint(f\"  - Test : {len(test_data)} lignes\")\n\n# Affichage des effectifs par classe dans chaque ensemble\nprint(\"\\nEffectifs par classe dans l'ensemble d'entraînement :\")\nprint(train_data['Cover_Type'].value_counts().sort_index())\n\nprint(\"\\nEffectifs par classe dans l'ensemble de validation :\")\nprint(val_data['Cover_Type'].value_counts().sort_index())\n\nprint(\"\\nEffectifs par classe dans l'ensemble de test :\")\nprint(test_data['Cover_Type'].value_counts().sort_index())\n\n# Sauvegarder les ensembles en fichiers CSV\ntrain_data.to_csv('covertype_train.csv', index=False)\nval_data.to_csv('covertype_val.csv', index=False)\ntest_data.to_csv('covertype_test.csv', index=False)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEffectifs par classe après échantillonnage différencié :\nCover_Type\n1    10592\n2    14165\n3     7151\n4      549\n5     1899\n6     3473\n7     4102\nName: count, dtype: int64\n\nTaille des ensembles :\n  - Entraînement : 25158 lignes\n  - Validation : 8386 lignes\n  - Test : 8387 lignes\n\nEffectifs par classe dans l'ensemble d'entraînement :\nCover_Type\n1    6355\n2    8499\n3    4291\n4     329\n5    1139\n6    2084\n7    2461\nName: count, dtype: int64\n\nEffectifs par classe dans l'ensemble de validation :\nCover_Type\n1    2118\n2    2833\n3    1430\n4     110\n5     380\n6     695\n7     820\nName: count, dtype: int64\n\nEffectifs par classe dans l'ensemble de test :\nCover_Type\n1    2119\n2    2833\n3    1430\n4     110\n5     380\n6     694\n7     821\nName: count, dtype: int64\n```\n:::\n:::\n\n\n",
    "supporting": [
      "preparation_donnees_covertype_files"
    ],
    "filters": []
  }
}