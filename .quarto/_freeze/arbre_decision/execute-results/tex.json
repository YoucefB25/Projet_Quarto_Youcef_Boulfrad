{
  "hash": "c842f6c9acf42ca698f74953a90ccaa5",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Arbre de DÃ©cision - CART\"\n---\n\n\n\n\n\n\n## ThÃ©orie\n\nL'algorithme **CART** (**Classification and Regression Trees**) est un modÃ¨le d'apprentissage supervisÃ© qui construit un **arbre de dÃ©cision** en divisant l'espace des caractÃ©ristiques en sous-ensembles homogÃ¨nes.\n\n## HyperparamÃ¨tre utilisÃ©\n\nNous allons optimiser :\n\n- **Profondeur maximale de lâ€™arbre (`max_depth`)** : sÃ©lectionnÃ©e en fonction de la prÃ©cision sur lâ€™ensemble de validation.\n\n## MÃ©triques dâ€™Ã©valuation\n\nNous afficherons :\n\n- **Matrice de confusion** : rÃ©capitulant les erreurs de classification.\n- **Taux de bien classÃ©s sur lâ€™Ã©chantillon de validation** avec le meilleur hyperparamÃ¨tre.\n- **Taux de bien classÃ©s sur lâ€™Ã©chantillon de test** avec ce mÃªme hyperparamÃ¨tre.\n- **Taux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test**.\n\n## Recherche de la meilleure `max_depth` et Ã©valuation\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport warnings\n\n# ğŸ”‡ Suppression des avertissements inutiles\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ğŸ”„ Chargement des ensembles de donnÃ©es\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# ğŸ“Š PrÃ©paration des donnÃ©es\nX_train, y_train = train_data.drop('Cover_Type', axis=1), train_data['Cover_Type']\nX_val, y_val = val_data.drop('Cover_Type', axis=1), val_data['Cover_Type']\nX_test, y_test = test_data.drop('Cover_Type', axis=1), test_data['Cover_Type']\n\n# ğŸ¯ Recherche du meilleur hyperparamÃ¨tre max_depth\ndepth_range = range(1, 30)\nval_accuracies = []\n\nfor depth in depth_range:\n    tree = DecisionTreeClassifier(max_depth=depth, random_state=42)\n    tree.fit(X_train, y_train)\n    acc = accuracy_score(y_val, tree.predict(X_val))\n    val_accuracies.append((depth, acc))\n\n# SÃ©lection de la meilleure profondeur d'arbre\nbest_depth, best_val_acc = max(val_accuracies, key=lambda x: x[1])\n\n\n# ğŸ“ˆ Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(depth_range, [acc for depth, acc in val_accuracies], marker='o', linestyle='dashed', label=\"Validation\")\nplt.xlabel(\"Profondeur de l'arbre\")\nplt.ylabel(\"PrÃ©cision sur validation\")\nplt.title(\"Impact de la profondeur de l'arbre sur la performance de CART\")\nplt.legend()\nplt.show()\n\n# ğŸ† ModÃ¨le final avec la meilleure profondeur\nfinal_model = DecisionTreeClassifier(max_depth=best_depth, random_state=42)\nfinal_model.fit(X_train, y_train)\ny_test_pred = final_model.predict(X_test)\n\n# ğŸ“Š Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\n\n# ğŸ“ˆ Calcul des taux de bien classÃ©s par classe\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\noverall_test_accuracy = accuracy_score(y_test, y_test_pred)\n\n# ğŸ“ Affichage des rÃ©sultats\nprint(f\"\\nğŸ”¹ Meilleure profondeur de l'arbre sur lâ€™Ã©chantillon de validation : {best_depth}\")\nprint(f\"Taux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec cet hyperparamÃ¨tre : {best_val_acc:.2%}\")\nprint(\"\\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\")\nprint(conf_matrix)\n\nprint(\"\\nğŸ“ˆ Taux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\")\nfor i, acc in enumerate(class_accuracies, start=1):\n    print(f\"Classe {i} : {acc:.2%}\")\n\nprint(f\"\\nğŸ”¹ Taux de bien classÃ©s sur lâ€™Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : {overall_test_accuracy:.2%}\")\n```\n\n::: {.cell-output .cell-output-display}\n![](arbre_decision_files/figure-pdf/cell-2-output-1.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nğŸ”¹ Meilleure profondeur de l'arbre sur lâ€™Ã©chantillon de validation : 25\nTaux de bien classÃ©s sur lâ€™Ã©chantillon de validation avec cet hyperparamÃ¨tre : 78.43%\n\nğŸ“Š Matrice de confusion sur l'Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre :\n[[1581  449    1    0   11    1   76]\n [ 459 2177   43    1   93   52    8]\n [   2   46 1216   24   13  129    0]\n [   0    0   23   74    0   13    0]\n [  10   83   13    0  263   11    0]\n [   4   40  128    4    4  514    0]\n [  61   14    0    0    0    0  746]]\n\nğŸ“ˆ Taux de bien classÃ©s par classe sur lâ€™Ã©chantillon de test, avec le meilleur hyperparamÃ¨tre  :\nClasse 1 : 74.61%\nClasse 2 : 76.84%\nClasse 3 : 85.03%\nClasse 4 : 67.27%\nClasse 5 : 69.21%\nClasse 6 : 74.06%\nClasse 7 : 90.86%\n\nğŸ”¹ Taux de bien classÃ©s sur lâ€™Ã©chantillon de test avec le meilleur hyperparamÃ¨tre : 78.35%\n```\n:::\n:::\n\n\n",
    "supporting": [
      "arbre_decision_files"
    ],
    "filters": []
  }
}