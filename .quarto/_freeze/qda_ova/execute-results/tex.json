{
  "hash": "ffcfc1e333131548afc7800bc768e818",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Analyse Discriminante Quadratique (QDA) - One-Versus-All (OVA)\"\n---\n\n\n\n\n\n\n## Th√©orie\nL'**Analyse Discriminante Quadratique (QDA)** est une technique de classification qui, contrairement √† LDA, permet aux classes d'avoir des **matrices de covariance diff√©rentes**. Cela le rend plus flexible mais peut aussi augmenter le risque de sur-apprentissage.\n\nL'approche **One-Versus-All (OVA)** consiste √† entra√Æner un mod√®le pour chaque classe, en distinguant chaque classe des autres combin√©es.\n\n## Hyperparam√®tres\nNous allons tester les hyperparam√®tres suivants :\n- **R√©gularisation (`reg_param`)** : contr√¥le la variance de la covariance estim√©e (valeurs entre `0` et `1`).\n- **Standardisation des donn√©es** : normalisation des features avant l'entra√Ænement.\n\n## Exemple en Python\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport os\nimport warnings\n\n# üîá D√©sactiver les avertissements de scikit-learn et Python\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\n# Chargement des ensembles de donn√©es\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# Pr√©paration des donn√©es\nX_train = train_data.drop('Cover_Type', axis=1)\ny_train = train_data['Cover_Type']\n\nX_val = val_data.drop('Cover_Type', axis=1)\ny_val = val_data['Cover_Type']\n\nX_test = test_data.drop('Cover_Type', axis=1)\ny_test = test_data['Cover_Type']\n\n# Standardisation des donn√©es\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)\n\n# Recherche des meilleurs hyperparam√®tres\nreg_params = np.linspace(0, 1, 10)\ntrain_accuracies = []\nval_accuracies = []\n\nfor reg_param in reg_params:\n    qda_ova = OneVsRestClassifier(QuadraticDiscriminantAnalysis(reg_param=reg_param))\n    qda_ova.fit(X_train, y_train)\n    \n    y_train_pred = qda_ova.predict(X_train)\n    y_val_pred = qda_ova.predict(X_val)\n    \n    train_accuracies.append(accuracy_score(y_train, y_train_pred))\n    val_accuracies.append(accuracy_score(y_val, y_val_pred))\n\n# S√©lection du meilleur reg_param\nbest_reg_param = reg_params[val_accuracies.index(max(val_accuracies))]\nprint(f\"Meilleur reg_param QDA (OVA): {best_reg_param}\")\n\n# Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(reg_params, train_accuracies, marker='o', linestyle='dashed', label='Train Accuracy')\nplt.plot(reg_params, val_accuracies, marker='s', linestyle='dashed', label='Validation Accuracy')\nplt.xlabel(\"R√©gularisation (reg_param)\")\nplt.ylabel(\"Pr√©cision\")\nplt.title(\"Impact de la r√©gularisation sur la performance de QDA (OVA)\")\nplt.legend()\nplt.show()\n\n# Mod√®le final avec le meilleur reg_param\nqda_ova = OneVsRestClassifier(QuadraticDiscriminantAnalysis(reg_param=best_reg_param))\nqda_ova.fit(X_train, y_train)\ny_test_pred = qda_ova.predict(X_test)\n\n# Affichage de la matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\nprint(\"\\nMatrice de confusion (OVA) :\")\nprint(conf_matrix)\n\nprint(\"\\n√âvaluation sur l'ensemble de test\")\nprint(classification_report(y_test, y_test_pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMeilleur reg_param QDA (OVA): 0.7777777777777777\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](qda_ova_files/figure-pdf/cell-2-output-2.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nMatrice de confusion (OVA) :\n[[1323  479    1    1   78   12  225]\n [ 832 1409   99    8  364  104   17]\n [   0    3 1219  104   52   52    0]\n [   0    0   54   53    0    3    0]\n [  45   86   28   12  197   12    0]\n [  21   27  416   51   31  148    0]\n [ 106   32    3    0   16    0  664]]\n\n√âvaluation sur l'ensemble de test\n              precision    recall  f1-score   support\n\n           1       0.57      0.62      0.60      2119\n           2       0.69      0.50      0.58      2833\n           3       0.67      0.85      0.75      1430\n           4       0.23      0.48      0.31       110\n           5       0.27      0.52      0.35       380\n           6       0.45      0.21      0.29       694\n           7       0.73      0.81      0.77       821\n\n    accuracy                           0.60      8387\n   macro avg       0.52      0.57      0.52      8387\nweighted avg       0.62      0.60      0.59      8387\n\n```\n:::\n:::\n\n\n",
    "supporting": [
      "qda_ova_files"
    ],
    "filters": []
  }
}