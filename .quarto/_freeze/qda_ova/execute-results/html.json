{
  "hash": "ffcfc1e333131548afc7800bc768e818",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Analyse Discriminante Quadratique (QDA) - One-Versus-All (OVA)\"\n---\n\n\n\n\n## Th√©orie\nL'**Analyse Discriminante Quadratique (QDA)** est une technique de classification qui, contrairement √† LDA, permet aux classes d'avoir des **matrices de covariance diff√©rentes**. Cela le rend plus flexible mais peut aussi augmenter le risque de sur-apprentissage.\n\nL'approche **One-Versus-All (OVA)** consiste √† entra√Æner un mod√®le pour chaque classe, en distinguant chaque classe des autres combin√©es.\n\n## Hyperparam√®tres\nNous allons tester les hyperparam√®tres suivants :\n- **R√©gularisation (`reg_param`)** : contr√¥le la variance de la covariance estim√©e (valeurs entre `0` et `1`).\n- **Standardisation des donn√©es** : normalisation des features avant l'entra√Ænement.\n\n## Exemple en Python\n\n::: {#ee84bae9 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport os\nimport warnings\n\n# üîá D√©sactiver les avertissements de scikit-learn et Python\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\n# Chargement des ensembles de donn√©es\ntrain_data = pd.read_csv('covertype_train.csv')\nval_data = pd.read_csv('covertype_val.csv')\ntest_data = pd.read_csv('covertype_test.csv')\n\n# Pr√©paration des donn√©es\nX_train = train_data.drop('Cover_Type', axis=1)\ny_train = train_data['Cover_Type']\n\nX_val = val_data.drop('Cover_Type', axis=1)\ny_val = val_data['Cover_Type']\n\nX_test = test_data.drop('Cover_Type', axis=1)\ny_test = test_data['Cover_Type']\n\n# Standardisation des donn√©es\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)\n\n# Recherche des meilleurs hyperparam√®tres\nreg_params = np.linspace(0, 1, 10)\ntrain_accuracies = []\nval_accuracies = []\n\nfor reg_param in reg_params:\n    qda_ova = OneVsRestClassifier(QuadraticDiscriminantAnalysis(reg_param=reg_param))\n    qda_ova.fit(X_train, y_train)\n    \n    y_train_pred = qda_ova.predict(X_train)\n    y_val_pred = qda_ova.predict(X_val)\n    \n    train_accuracies.append(accuracy_score(y_train, y_train_pred))\n    val_accuracies.append(accuracy_score(y_val, y_val_pred))\n\n# S√©lection du meilleur reg_param\nbest_reg_param = reg_params[val_accuracies.index(max(val_accuracies))]\nprint(f\"Meilleur reg_param QDA (OVA): {best_reg_param}\")\n\n# Affichage du graphique\nplt.figure(figsize=(8, 6))\nplt.plot(reg_params, train_accuracies, marker='o', linestyle='dashed', label='Train Accuracy')\nplt.plot(reg_params, val_accuracies, marker='s', linestyle='dashed', label='Validation Accuracy')\nplt.xlabel(\"R√©gularisation (reg_param)\")\nplt.ylabel(\"Pr√©cision\")\nplt.title(\"Impact de la r√©gularisation sur la performance de QDA (OVA)\")\nplt.legend()\nplt.show()\n\n# Mod√®le final avec le meilleur reg_param\nqda_ova = OneVsRestClassifier(QuadraticDiscriminantAnalysis(reg_param=best_reg_param))\nqda_ova.fit(X_train, y_train)\ny_test_pred = qda_ova.predict(X_test)\n\n# Affichage de la matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_test_pred)\nprint(\"\\nMatrice de confusion (OVA) :\")\nprint(conf_matrix)\n\nprint(\"\\n√âvaluation sur l'ensemble de test\")\nprint(classification_report(y_test, y_test_pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMeilleur reg_param QDA (OVA): 1.0\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](qda_ova_files/figure-html/cell-2-output-2.png){width=663 height=525}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nMatrice de confusion (OVA) :\n[[2041 1747    3    0   12    9  448]\n [ 861 4428   79   25   78  143   36]\n [   0   46  378   68   13  217    0]\n [   0    0   11   32    0    9    0]\n [   8  121   11    0   44    2    0]\n [   0   59   92   11    8  171    0]\n [  65   16    1    0    0    0  328]]\n\n√âvaluation sur l'ensemble de test\n              precision    recall  f1-score   support\n\n           1       0.69      0.48      0.56      4260\n           2       0.69      0.78      0.73      5650\n           3       0.66      0.52      0.58       722\n           4       0.24      0.62      0.34        52\n           5       0.28      0.24      0.26       186\n           6       0.31      0.50      0.38       341\n           7       0.40      0.80      0.54       410\n\n    accuracy                           0.64     11621\n   macro avg       0.47      0.56      0.49     11621\nweighted avg       0.66      0.64      0.64     11621\n\n```\n:::\n:::\n\n\n",
    "supporting": [
      "qda_ova_files"
    ],
    "filters": [],
    "includes": {}
  }
}