% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\usepackage{fvextra}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines=true,breakanywhere=true,commandchars=\\\{\}}
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Présentation des techniques de classification supervisée utilisées},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Présentation des techniques de classification supervisée
utilisées}
\author{}
\date{}

\begin{document}
\maketitle


\subsection{Classification Paramétrique vs
Non-Paramétrique}\label{classification-paramuxe9trique-vs-non-paramuxe9trique}

En classification supervisée, les algorithmes peuvent être divisés en
\textbf{méthodes paramétriques} et \textbf{méthodes non-paramétriques}.
Cette distinction repose sur la manière dont les modèles apprennent et
généralisent les données.

\subsubsection{1. Méthodes
Paramétriques}\label{muxe9thodes-paramuxe9triques}

Les modèles paramétriques supposent l'existence d'une distribution
sous-jacente aux données et estiment ses paramètres à partir des données
d'entrainement.

\paragraph{Classifieurs paramétriques utilisés
:}\label{classifieurs-paramuxe9triques-utilisuxe9s}

\begin{itemize}
\tightlist
\item
  \textbf{Régression Logistique (OVA et OVO)}
\item
  \textbf{Régression Multinomiale (Softmax Regression)}
\item
  \textbf{Analyse Discriminante Linéaire (LDA)}
\item
  \textbf{Analyse Discriminante Quadratique (QDA)}
\item
  \textbf{Classifieur Bayésien Naïf}
\end{itemize}

\subsubsection{2. Méthodes
Non-Paramétriques}\label{muxe9thodes-non-paramuxe9triques}

Les modèles non-paramétriques ne supposent pas l'existence d'une
distribution sous-jacente aux données. Ils estiment les limites entre
les classes de façon ``gloutonne'' en maximisant les différences
inter-classes et minisant les différences intra-classes sur les données
d'entrainement.

\paragraph{Classifieurs non-paramétriques utilisés
:}\label{classifieurs-non-paramuxe9triques-utilisuxe9s}

\begin{itemize}
\tightlist
\item
  \textbf{Arbre de Décision (CART)}
\item
  \textbf{Forêt Aléatoire (Random Forest)}
\item
  \textbf{K-Nearest Neighbors (KNN)}
\item
  \textbf{Machines à Vecteurs de Support (SVM - OVA et OVO)}
\item
  \textbf{Réseau de Neurones (MLP avec sortie Softmax)}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Classifieurs Multiclasses Natifs vs Classifieurs Binaires
Adaptés}\label{classifieurs-multiclasses-natifs-vs-classifieurs-binaires-adaptuxe9s}

Certains classifieurs sont conçus pour gérer directement plusieurs
classes (\textbf{classifieurs multiclasses natifs}), tandis que d'autres
sont conçus pour distinguer uniquement deux classes et doivent être
adaptés pour des problèmes multiclasses.

\subsubsection{1. Classifieurs Multiclasses
Natifs}\label{classifieurs-multiclasses-natifs}

Ces classifieurs peuvent traiter directement un problème à plusieurs
classes sans nécessiter de transformation :

\begin{itemize}
\tightlist
\item
  \textbf{Régression Multinomiale (Softmax Regression)}
\item
  \textbf{Analyse Discriminante Linéaire (LDA)}
\item
  \textbf{Analyse Discriminante Quadratique (QDA)}
\item
  \textbf{Classifieur Bayésien Naïf}
\item
  \textbf{Arbre de Décision (CART)}
\item
  \textbf{Forêt Aléatoire (Random Forest)}
\item
  \textbf{Réseau de Neurones (MLP avec sortie Softmax)}
\item
  \textbf{K-Nearest Neighbors (KNN)}
\end{itemize}

\subsubsection{2. Classifieurs Binaires
Adaptés}\label{classifieurs-binaires-adaptuxe9s}

Les classifieurs binaires doivent être transformés pour gérer plusieurs
classes en utilisant des approches comme \textbf{One-Versus-All (OVA)}
ou \textbf{One-Versus-One (OVO)} :

\begin{itemize}
\tightlist
\item
  \textbf{Régression Logistique} (adaptée en OVA et OVO)
\item
  \textbf{Support Vector Machines (SVM)} (adaptées en OVA et OVO)
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{One-Versus-All (OVA) vs One-Versus-One
(OVO)}\label{one-versus-all-ova-vs-one-versus-one-ovo}

Les approches \textbf{OVA} et \textbf{OVO} permettent d'adapter des
classifieurs binaires aux problèmes multiclasses.

\subsubsection{1. One-Versus-All (OVA)}\label{one-versus-all-ova}

Avec cette approche, un modèle binaire est entraîné pour chaque classe
en la comparant à toutes les autres classes regroupées. Pour une
classification à \textbf{N classes}, \textbf{N modèles binaires} sont
entraînés.

\textbf{Avantages :} - Moins de modèles à entraîner (\textbf{N} contre
\textbf{N(N-1)/2} en OVO), soit 7 modèles pour 7 classes. - Plus
efficace pour les jeux de données avec un grand nombre de classes.

\textbf{Inconvénients :} - Les classes déséquilibrées peuvent poser
problème car le modèle doit distinguer une classe contre un ensemble de
classes plus nombreuses. - Peut générer des scores de confiance biaisés
si les classes sont très déséquilibrées.

\textbf{Exemples de classifieurs utilisant OVA :}

\begin{itemize}
\tightlist
\item
  \textbf{Régression Logistique (OVA)}
\item
  \textbf{SVM (OVA)}
\end{itemize}

\subsubsection{2. One-Versus-One (OVO)}\label{one-versus-one-ovo}

Avec l'approche OVO, un modèle est entraîné pour chaque paire de
classes. Pour une classification à \textbf{N classes}, \textbf{N(N-1)/2}
modèles binaires sont entraînés, soit 21 modèles pour 7 classes.

\textbf{Avantages :} - Meilleure séparation entre classes si elles sont
bien distinctes. - Moins sensible aux classes déséquilibrées car chaque
modèle compare seulement deux classes à la fois.

\textbf{Inconvénients :} - Temps d'entraînement plus long à cause du
grand nombre de modèles. - Peut nécessiter plus de ressources pour
l'inférence.

\textbf{Exemples de classifieurs utilisant OVO :}

\begin{itemize}
\tightlist
\item
  \textbf{Régression Logistique (OVO)}
\item
  \textbf{SVM (OVO)}
\end{itemize}




\end{document}
